nohup: ignoring input
I1007 05:14:55.674422 13601 caffe.cpp:217] Using GPUs 1
I1007 05:14:55.767349 13601 caffe.cpp:222] GPU 1: TITAN X (Pascal)
I1007 05:14:56.447299 13601 solver.cpp:49] Initializing solver from parameters: 
test_iter: 2817
test_interval: 500
base_lr: 0.001
display: 500
max_iter: 30000
lr_policy: "inv"
gamma: 0.001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 60000
snapshot_prefix: "models/JAN/alexnet/trained_model"
solver_mode: GPU
device_id: 1
net: "models/JAN/alexnet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: false
I1007 05:14:56.447518 13601 solver.cpp:92] Creating training net from net file: models/JAN/alexnet/train_val.prototxt
I1007 05:14:56.449005 13601 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer test_data
I1007 05:14:56.449057 13601 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1007 05:14:56.449596 13601 net.cpp:58] Initializing net from parameters: 
name: "amazon_to_webcam"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "source_data"
  type: "ImageData"
  top: "source_data"
  top: "source_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/dslr_list.txt"
    batch_size: 64
    shuffle: true
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "target_data"
  type: "ImageData"
  top: "target_data"
  top: "target_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/amazon_list.txt"
    batch_size: 64
    shuffle: true
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "target_label_silence"
  type: "Silence"
  bottom: "target_label"
  include {
    phase: TRAIN
  }
}
layer {
  name: "data"
  type: "Concat"
  bottom: "source_data"
  bottom: "target_data"
  top: "data"
  include {
    phase: TRAIN
  }
  concat_param {
    axis: 0
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slice_fc8"
  type: "Slice"
  bottom: "fc8"
  top: "fc8_source"
  top: "fc8_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 0
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "fc8_target"
  include {
    phase: TRAIN
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_source"
  bottom: "source_label"
  top: "softmax_loss"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fc8_softmax"
  type: "Softmax"
  bottom: "fc8"
  top: "fc8_softmax"
  include {
    phase: TRAIN
  }
}
layer {
  name: "slice_softmax"
  type: "Slice"
  bottom: "fc8_softmax"
  top: "source_softmax"
  top: "target_softmax"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 0
  }
}
layer {
  name: "jmmd_loss"
  type: "JMMDLoss"
  bottom: "source_softmax"
  bottom: "target_softmax"
  bottom: "source_softmax"
  bottom: "target_softmax"
  top: "jmmd_loss"
  loss_weight: 0.3
  include {
    phase: TRAIN
  }
}
layer {
  name: "silence_loss_value"
  type: "Silence"
  bottom: "jmmd_loss"
  include {
    phase: TRAIN
  }
}
I1007 05:14:56.449944 13601 layer_factory.hpp:77] Creating layer source_data
I1007 05:14:56.450006 13601 net.cpp:100] Creating Layer source_data
I1007 05:14:56.450024 13601 net.cpp:408] source_data -> source_data
I1007 05:14:56.450064 13601 net.cpp:408] source_data -> source_label
I1007 05:14:56.450086 13601 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1007 05:14:56.492246 13601 image_data_layer.cpp:38] Opening file ./data/office/dslr_list.txt
I1007 05:14:56.492568 13601 image_data_layer.cpp:53] Shuffling data
I1007 05:14:56.492652 13601 image_data_layer.cpp:58] A total of 498 images.
I1007 05:14:57.051829 13601 image_data_layer.cpp:85] output data size: 64,3,227,227
I1007 05:14:57.137434 13601 net.cpp:150] Setting up source_data
I1007 05:14:57.137475 13601 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1007 05:14:57.137481 13601 net.cpp:157] Top shape: 64 (64)
I1007 05:14:57.137485 13601 net.cpp:165] Memory required for data: 39574528
I1007 05:14:57.137516 13601 layer_factory.hpp:77] Creating layer target_data
I1007 05:14:57.137594 13601 net.cpp:100] Creating Layer target_data
I1007 05:14:57.137603 13601 net.cpp:408] target_data -> target_data
I1007 05:14:57.137625 13601 net.cpp:408] target_data -> target_label
I1007 05:14:57.137634 13601 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1007 05:14:57.139858 13601 image_data_layer.cpp:38] Opening file ./data/office/amazon_list.txt
I1007 05:14:57.140740 13601 image_data_layer.cpp:53] Shuffling data
I1007 05:14:57.140909 13601 image_data_layer.cpp:58] A total of 2817 images.
I1007 05:14:57.142262 13601 image_data_layer.cpp:85] output data size: 64,3,227,227
I1007 05:14:57.222867 13601 net.cpp:150] Setting up target_data
I1007 05:14:57.222908 13601 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1007 05:14:57.222913 13601 net.cpp:157] Top shape: 64 (64)
I1007 05:14:57.222916 13601 net.cpp:165] Memory required for data: 79149056
I1007 05:14:57.222964 13601 layer_factory.hpp:77] Creating layer target_label_silence
I1007 05:14:57.222997 13601 net.cpp:100] Creating Layer target_label_silence
I1007 05:14:57.223007 13601 net.cpp:434] target_label_silence <- target_label
I1007 05:14:57.223031 13601 net.cpp:150] Setting up target_label_silence
I1007 05:14:57.223036 13601 net.cpp:165] Memory required for data: 79149056
I1007 05:14:57.223038 13601 layer_factory.hpp:77] Creating layer data
I1007 05:14:57.223076 13601 net.cpp:100] Creating Layer data
I1007 05:14:57.223080 13601 net.cpp:434] data <- source_data
I1007 05:14:57.223086 13601 net.cpp:434] data <- target_data
I1007 05:14:57.223093 13601 net.cpp:408] data -> data
I1007 05:14:57.223155 13601 net.cpp:150] Setting up data
I1007 05:14:57.223165 13601 net.cpp:157] Top shape: 128 3 227 227 (19787136)
I1007 05:14:57.223168 13601 net.cpp:165] Memory required for data: 158297600
I1007 05:14:57.223172 13601 layer_factory.hpp:77] Creating layer conv1
I1007 05:14:57.223232 13601 net.cpp:100] Creating Layer conv1
I1007 05:14:57.223237 13601 net.cpp:434] conv1 <- data
I1007 05:14:57.223244 13601 net.cpp:408] conv1 -> conv1
I1007 05:14:57.228005 13601 net.cpp:150] Setting up conv1
I1007 05:14:57.228022 13601 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I1007 05:14:57.228027 13601 net.cpp:165] Memory required for data: 306982400
I1007 05:14:57.228041 13601 layer_factory.hpp:77] Creating layer relu1
I1007 05:14:57.228067 13601 net.cpp:100] Creating Layer relu1
I1007 05:14:57.228072 13601 net.cpp:434] relu1 <- conv1
I1007 05:14:57.228078 13601 net.cpp:395] relu1 -> conv1 (in-place)
I1007 05:14:57.228087 13601 net.cpp:150] Setting up relu1
I1007 05:14:57.228092 13601 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I1007 05:14:57.228096 13601 net.cpp:165] Memory required for data: 455667200
I1007 05:14:57.228106 13601 layer_factory.hpp:77] Creating layer pool1
I1007 05:14:57.228126 13601 net.cpp:100] Creating Layer pool1
I1007 05:14:57.228129 13601 net.cpp:434] pool1 <- conv1
I1007 05:14:57.228135 13601 net.cpp:408] pool1 -> pool1
I1007 05:14:57.228250 13601 net.cpp:150] Setting up pool1
I1007 05:14:57.228258 13601 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I1007 05:14:57.228261 13601 net.cpp:165] Memory required for data: 491499008
I1007 05:14:57.228279 13601 layer_factory.hpp:77] Creating layer norm1
I1007 05:14:57.228287 13601 net.cpp:100] Creating Layer norm1
I1007 05:14:57.228292 13601 net.cpp:434] norm1 <- pool1
I1007 05:14:57.228297 13601 net.cpp:408] norm1 -> norm1
I1007 05:14:57.228329 13601 net.cpp:150] Setting up norm1
I1007 05:14:57.228355 13601 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I1007 05:14:57.228375 13601 net.cpp:165] Memory required for data: 527330816
I1007 05:14:57.228379 13601 layer_factory.hpp:77] Creating layer conv2
I1007 05:14:57.228389 13601 net.cpp:100] Creating Layer conv2
I1007 05:14:57.228394 13601 net.cpp:434] conv2 <- norm1
I1007 05:14:57.228400 13601 net.cpp:408] conv2 -> conv2
I1007 05:14:57.237881 13601 net.cpp:150] Setting up conv2
I1007 05:14:57.237915 13601 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I1007 05:14:57.237920 13601 net.cpp:165] Memory required for data: 622882304
I1007 05:14:57.237931 13601 layer_factory.hpp:77] Creating layer relu2
I1007 05:14:57.237948 13601 net.cpp:100] Creating Layer relu2
I1007 05:14:57.237953 13601 net.cpp:434] relu2 <- conv2
I1007 05:14:57.237959 13601 net.cpp:395] relu2 -> conv2 (in-place)
I1007 05:14:57.237968 13601 net.cpp:150] Setting up relu2
I1007 05:14:57.237972 13601 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I1007 05:14:57.237975 13601 net.cpp:165] Memory required for data: 718433792
I1007 05:14:57.237987 13601 layer_factory.hpp:77] Creating layer pool2
I1007 05:14:57.237993 13601 net.cpp:100] Creating Layer pool2
I1007 05:14:57.237996 13601 net.cpp:434] pool2 <- conv2
I1007 05:14:57.238003 13601 net.cpp:408] pool2 -> pool2
I1007 05:14:57.238039 13601 net.cpp:150] Setting up pool2
I1007 05:14:57.238045 13601 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1007 05:14:57.238049 13601 net.cpp:165] Memory required for data: 740584960
I1007 05:14:57.238051 13601 layer_factory.hpp:77] Creating layer norm2
I1007 05:14:57.238059 13601 net.cpp:100] Creating Layer norm2
I1007 05:14:57.238062 13601 net.cpp:434] norm2 <- pool2
I1007 05:14:57.238068 13601 net.cpp:408] norm2 -> norm2
I1007 05:14:57.238095 13601 net.cpp:150] Setting up norm2
I1007 05:14:57.238101 13601 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1007 05:14:57.238103 13601 net.cpp:165] Memory required for data: 762736128
I1007 05:14:57.238106 13601 layer_factory.hpp:77] Creating layer conv3
I1007 05:14:57.238124 13601 net.cpp:100] Creating Layer conv3
I1007 05:14:57.238128 13601 net.cpp:434] conv3 <- norm2
I1007 05:14:57.238135 13601 net.cpp:408] conv3 -> conv3
I1007 05:14:57.258378 13601 net.cpp:150] Setting up conv3
I1007 05:14:57.258394 13601 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1007 05:14:57.258399 13601 net.cpp:165] Memory required for data: 795962880
I1007 05:14:57.258409 13601 layer_factory.hpp:77] Creating layer relu3
I1007 05:14:57.258415 13601 net.cpp:100] Creating Layer relu3
I1007 05:14:57.258419 13601 net.cpp:434] relu3 <- conv3
I1007 05:14:57.258424 13601 net.cpp:395] relu3 -> conv3 (in-place)
I1007 05:14:57.258431 13601 net.cpp:150] Setting up relu3
I1007 05:14:57.258435 13601 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1007 05:14:57.258438 13601 net.cpp:165] Memory required for data: 829189632
I1007 05:14:57.258450 13601 layer_factory.hpp:77] Creating layer conv4
I1007 05:14:57.258458 13601 net.cpp:100] Creating Layer conv4
I1007 05:14:57.258462 13601 net.cpp:434] conv4 <- conv3
I1007 05:14:57.258467 13601 net.cpp:408] conv4 -> conv4
I1007 05:14:57.273712 13601 net.cpp:150] Setting up conv4
I1007 05:14:57.273728 13601 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1007 05:14:57.273732 13601 net.cpp:165] Memory required for data: 862416384
I1007 05:14:57.273739 13601 layer_factory.hpp:77] Creating layer relu4
I1007 05:14:57.273756 13601 net.cpp:100] Creating Layer relu4
I1007 05:14:57.273762 13601 net.cpp:434] relu4 <- conv4
I1007 05:14:57.273768 13601 net.cpp:395] relu4 -> conv4 (in-place)
I1007 05:14:57.273774 13601 net.cpp:150] Setting up relu4
I1007 05:14:57.273779 13601 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1007 05:14:57.273783 13601 net.cpp:165] Memory required for data: 895643136
I1007 05:14:57.273787 13601 layer_factory.hpp:77] Creating layer conv5
I1007 05:14:57.273795 13601 net.cpp:100] Creating Layer conv5
I1007 05:14:57.273799 13601 net.cpp:434] conv5 <- conv4
I1007 05:14:57.273807 13601 net.cpp:408] conv5 -> conv5
I1007 05:14:57.284194 13601 net.cpp:150] Setting up conv5
I1007 05:14:57.284221 13601 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1007 05:14:57.284225 13601 net.cpp:165] Memory required for data: 917794304
I1007 05:14:57.284245 13601 layer_factory.hpp:77] Creating layer relu5
I1007 05:14:57.284252 13601 net.cpp:100] Creating Layer relu5
I1007 05:14:57.284256 13601 net.cpp:434] relu5 <- conv5
I1007 05:14:57.284262 13601 net.cpp:395] relu5 -> conv5 (in-place)
I1007 05:14:57.284270 13601 net.cpp:150] Setting up relu5
I1007 05:14:57.284274 13601 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1007 05:14:57.284277 13601 net.cpp:165] Memory required for data: 939945472
I1007 05:14:57.284281 13601 layer_factory.hpp:77] Creating layer pool5
I1007 05:14:57.284296 13601 net.cpp:100] Creating Layer pool5
I1007 05:14:57.284299 13601 net.cpp:434] pool5 <- conv5
I1007 05:14:57.284304 13601 net.cpp:408] pool5 -> pool5
I1007 05:14:57.284337 13601 net.cpp:150] Setting up pool5
I1007 05:14:57.284343 13601 net.cpp:157] Top shape: 128 256 6 6 (1179648)
I1007 05:14:57.284346 13601 net.cpp:165] Memory required for data: 944664064
I1007 05:14:57.284350 13601 layer_factory.hpp:77] Creating layer fc6
I1007 05:14:57.284358 13601 net.cpp:100] Creating Layer fc6
I1007 05:14:57.284363 13601 net.cpp:434] fc6 <- pool5
I1007 05:14:57.284368 13601 net.cpp:408] fc6 -> fc6
I1007 05:14:58.133922 13601 net.cpp:150] Setting up fc6
I1007 05:14:58.133975 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.133981 13601 net.cpp:165] Memory required for data: 946761216
I1007 05:14:58.133991 13601 layer_factory.hpp:77] Creating layer relu6
I1007 05:14:58.134008 13601 net.cpp:100] Creating Layer relu6
I1007 05:14:58.134014 13601 net.cpp:434] relu6 <- fc6
I1007 05:14:58.134022 13601 net.cpp:395] relu6 -> fc6 (in-place)
I1007 05:14:58.134032 13601 net.cpp:150] Setting up relu6
I1007 05:14:58.134037 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.134040 13601 net.cpp:165] Memory required for data: 948858368
I1007 05:14:58.134050 13601 layer_factory.hpp:77] Creating layer drop6
I1007 05:14:58.134064 13601 net.cpp:100] Creating Layer drop6
I1007 05:14:58.134068 13601 net.cpp:434] drop6 <- fc6
I1007 05:14:58.134073 13601 net.cpp:395] drop6 -> fc6 (in-place)
I1007 05:14:58.134126 13601 net.cpp:150] Setting up drop6
I1007 05:14:58.134132 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.134135 13601 net.cpp:165] Memory required for data: 950955520
I1007 05:14:58.134140 13601 layer_factory.hpp:77] Creating layer fc7
I1007 05:14:58.134148 13601 net.cpp:100] Creating Layer fc7
I1007 05:14:58.134152 13601 net.cpp:434] fc7 <- fc6
I1007 05:14:58.134158 13601 net.cpp:408] fc7 -> fc7
I1007 05:14:58.513268 13601 net.cpp:150] Setting up fc7
I1007 05:14:58.513311 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.513316 13601 net.cpp:165] Memory required for data: 953052672
I1007 05:14:58.513330 13601 layer_factory.hpp:77] Creating layer relu7
I1007 05:14:58.513353 13601 net.cpp:100] Creating Layer relu7
I1007 05:14:58.513361 13601 net.cpp:434] relu7 <- fc7
I1007 05:14:58.513370 13601 net.cpp:395] relu7 -> fc7 (in-place)
I1007 05:14:58.513381 13601 net.cpp:150] Setting up relu7
I1007 05:14:58.513386 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.513389 13601 net.cpp:165] Memory required for data: 955149824
I1007 05:14:58.513392 13601 layer_factory.hpp:77] Creating layer drop7
I1007 05:14:58.513417 13601 net.cpp:100] Creating Layer drop7
I1007 05:14:58.513420 13601 net.cpp:434] drop7 <- fc7
I1007 05:14:58.513427 13601 net.cpp:395] drop7 -> fc7 (in-place)
I1007 05:14:58.513443 13601 net.cpp:150] Setting up drop7
I1007 05:14:58.513449 13601 net.cpp:157] Top shape: 128 4096 (524288)
I1007 05:14:58.513453 13601 net.cpp:165] Memory required for data: 957246976
I1007 05:14:58.513463 13601 layer_factory.hpp:77] Creating layer fc8_new
I1007 05:14:58.513478 13601 net.cpp:100] Creating Layer fc8_new
I1007 05:14:58.513481 13601 net.cpp:434] fc8_new <- fc7
I1007 05:14:58.513489 13601 net.cpp:408] fc8_new -> fc8
I1007 05:14:58.522047 13601 net.cpp:150] Setting up fc8_new
I1007 05:14:58.522081 13601 net.cpp:157] Top shape: 128 31 (3968)
I1007 05:14:58.522119 13601 net.cpp:165] Memory required for data: 957262848
I1007 05:14:58.522135 13601 layer_factory.hpp:77] Creating layer fc8_fc8_new_0_split
I1007 05:14:58.522156 13601 net.cpp:100] Creating Layer fc8_fc8_new_0_split
I1007 05:14:58.522166 13601 net.cpp:434] fc8_fc8_new_0_split <- fc8
I1007 05:14:58.522179 13601 net.cpp:408] fc8_fc8_new_0_split -> fc8_fc8_new_0_split_0
I1007 05:14:58.522195 13601 net.cpp:408] fc8_fc8_new_0_split -> fc8_fc8_new_0_split_1
I1007 05:14:58.522261 13601 net.cpp:150] Setting up fc8_fc8_new_0_split
I1007 05:14:58.522275 13601 net.cpp:157] Top shape: 128 31 (3968)
I1007 05:14:58.522297 13601 net.cpp:157] Top shape: 128 31 (3968)
I1007 05:14:58.522306 13601 net.cpp:165] Memory required for data: 957294592
I1007 05:14:58.522316 13601 layer_factory.hpp:77] Creating layer slice_fc8
I1007 05:14:58.522343 13601 net.cpp:100] Creating Layer slice_fc8
I1007 05:14:58.522354 13601 net.cpp:434] slice_fc8 <- fc8_fc8_new_0_split_0
I1007 05:14:58.522367 13601 net.cpp:408] slice_fc8 -> fc8_source
I1007 05:14:58.522389 13601 net.cpp:408] slice_fc8 -> fc8_target
I1007 05:14:58.522460 13601 net.cpp:150] Setting up slice_fc8
I1007 05:14:58.522474 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.522485 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.522493 13601 net.cpp:165] Memory required for data: 957310464
I1007 05:14:58.522502 13601 layer_factory.hpp:77] Creating layer silence
I1007 05:14:58.522514 13601 net.cpp:100] Creating Layer silence
I1007 05:14:58.522524 13601 net.cpp:434] silence <- fc8_target
I1007 05:14:58.522536 13601 net.cpp:150] Setting up silence
I1007 05:14:58.522544 13601 net.cpp:165] Memory required for data: 957310464
I1007 05:14:58.522563 13601 layer_factory.hpp:77] Creating layer softmax_loss
I1007 05:14:58.522586 13601 net.cpp:100] Creating Layer softmax_loss
I1007 05:14:58.522598 13601 net.cpp:434] softmax_loss <- fc8_source
I1007 05:14:58.522609 13601 net.cpp:434] softmax_loss <- source_label
I1007 05:14:58.522620 13601 net.cpp:408] softmax_loss -> softmax_loss
I1007 05:14:58.522641 13601 layer_factory.hpp:77] Creating layer softmax_loss
I1007 05:14:58.522840 13601 net.cpp:150] Setting up softmax_loss
I1007 05:14:58.522855 13601 net.cpp:157] Top shape: (1)
I1007 05:14:58.522862 13601 net.cpp:160]     with loss weight 1
I1007 05:14:58.523036 13601 net.cpp:165] Memory required for data: 957310468
I1007 05:14:58.523048 13601 layer_factory.hpp:77] Creating layer fc8_softmax
I1007 05:14:58.523062 13601 net.cpp:100] Creating Layer fc8_softmax
I1007 05:14:58.523072 13601 net.cpp:434] fc8_softmax <- fc8_fc8_new_0_split_1
I1007 05:14:58.523085 13601 net.cpp:408] fc8_softmax -> fc8_softmax
I1007 05:14:58.523217 13601 net.cpp:150] Setting up fc8_softmax
I1007 05:14:58.523234 13601 net.cpp:157] Top shape: 128 31 (3968)
I1007 05:14:58.523243 13601 net.cpp:165] Memory required for data: 957326340
I1007 05:14:58.523252 13601 layer_factory.hpp:77] Creating layer slice_softmax
I1007 05:14:58.523284 13601 net.cpp:100] Creating Layer slice_softmax
I1007 05:14:58.523295 13601 net.cpp:434] slice_softmax <- fc8_softmax
I1007 05:14:58.523308 13601 net.cpp:408] slice_softmax -> source_softmax
I1007 05:14:58.523325 13601 net.cpp:408] slice_softmax -> target_softmax
I1007 05:14:58.523401 13601 net.cpp:150] Setting up slice_softmax
I1007 05:14:58.523416 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523425 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523433 13601 net.cpp:165] Memory required for data: 957342212
I1007 05:14:58.523443 13601 layer_factory.hpp:77] Creating layer source_softmax_slice_softmax_0_split
I1007 05:14:58.523470 13601 net.cpp:100] Creating Layer source_softmax_slice_softmax_0_split
I1007 05:14:58.523480 13601 net.cpp:434] source_softmax_slice_softmax_0_split <- source_softmax
I1007 05:14:58.523494 13601 net.cpp:408] source_softmax_slice_softmax_0_split -> source_softmax_slice_softmax_0_split_0
I1007 05:14:58.523509 13601 net.cpp:408] source_softmax_slice_softmax_0_split -> source_softmax_slice_softmax_0_split_1
I1007 05:14:58.523608 13601 net.cpp:150] Setting up source_softmax_slice_softmax_0_split
I1007 05:14:58.523623 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523634 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523643 13601 net.cpp:165] Memory required for data: 957358084
I1007 05:14:58.523653 13601 layer_factory.hpp:77] Creating layer target_softmax_slice_softmax_1_split
I1007 05:14:58.523669 13601 net.cpp:100] Creating Layer target_softmax_slice_softmax_1_split
I1007 05:14:58.523679 13601 net.cpp:434] target_softmax_slice_softmax_1_split <- target_softmax
I1007 05:14:58.523692 13601 net.cpp:408] target_softmax_slice_softmax_1_split -> target_softmax_slice_softmax_1_split_0
I1007 05:14:58.523738 13601 net.cpp:408] target_softmax_slice_softmax_1_split -> target_softmax_slice_softmax_1_split_1
I1007 05:14:58.523807 13601 net.cpp:150] Setting up target_softmax_slice_softmax_1_split
I1007 05:14:58.523819 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523831 13601 net.cpp:157] Top shape: 64 31 (1984)
I1007 05:14:58.523839 13601 net.cpp:165] Memory required for data: 957373956
I1007 05:14:58.523847 13601 layer_factory.hpp:77] Creating layer jmmd_loss
I1007 05:14:58.523864 13601 net.cpp:100] Creating Layer jmmd_loss
I1007 05:14:58.523874 13601 net.cpp:434] jmmd_loss <- source_softmax_slice_softmax_0_split_0
I1007 05:14:58.523885 13601 net.cpp:434] jmmd_loss <- target_softmax_slice_softmax_1_split_0
I1007 05:14:58.523895 13601 net.cpp:434] jmmd_loss <- source_softmax_slice_softmax_0_split_1
I1007 05:14:58.523905 13601 net.cpp:434] jmmd_loss <- target_softmax_slice_softmax_1_split_1
I1007 05:14:58.523921 13601 net.cpp:408] jmmd_loss -> jmmd_loss
I1007 05:14:58.524091 13601 net.cpp:150] Setting up jmmd_loss
I1007 05:14:58.524103 13601 net.cpp:157] Top shape: (1)
I1007 05:14:58.524112 13601 net.cpp:160]     with loss weight 1
I1007 05:14:58.524127 13601 net.cpp:165] Memory required for data: 957373960
I1007 05:14:58.524135 13601 layer_factory.hpp:77] Creating layer jmmd_loss_jmmd_loss_0_split
I1007 05:14:58.524147 13601 net.cpp:100] Creating Layer jmmd_loss_jmmd_loss_0_split
I1007 05:14:58.524157 13601 net.cpp:434] jmmd_loss_jmmd_loss_0_split <- jmmd_loss
I1007 05:14:58.524173 13601 net.cpp:408] jmmd_loss_jmmd_loss_0_split -> jmmd_loss_jmmd_loss_0_split_0
I1007 05:14:58.524186 13601 net.cpp:408] jmmd_loss_jmmd_loss_0_split -> jmmd_loss_jmmd_loss_0_split_1
I1007 05:14:58.524235 13601 net.cpp:150] Setting up jmmd_loss_jmmd_loss_0_split
I1007 05:14:58.524248 13601 net.cpp:157] Top shape: (1)
I1007 05:14:58.524258 13601 net.cpp:160]     with loss weight 0.3
I1007 05:14:58.524271 13601 net.cpp:157] Top shape: (1)
I1007 05:14:58.524279 13601 net.cpp:165] Memory required for data: 957373968
I1007 05:14:58.524291 13601 layer_factory.hpp:77] Creating layer silence_loss_value
I1007 05:14:58.524343 13601 net.cpp:100] Creating Layer silence_loss_value
I1007 05:14:58.524353 13601 net.cpp:434] silence_loss_value <- jmmd_loss_jmmd_loss_0_split_1
I1007 05:14:58.524368 13601 net.cpp:150] Setting up silence_loss_value
I1007 05:14:58.524375 13601 net.cpp:165] Memory required for data: 957373968
I1007 05:14:58.524387 13601 net.cpp:228] silence_loss_value does not need backward computation.
I1007 05:14:58.524396 13601 net.cpp:226] jmmd_loss_jmmd_loss_0_split needs backward computation.
I1007 05:14:58.524405 13601 net.cpp:226] jmmd_loss needs backward computation.
I1007 05:14:58.524415 13601 net.cpp:226] target_softmax_slice_softmax_1_split needs backward computation.
I1007 05:14:58.524426 13601 net.cpp:226] source_softmax_slice_softmax_0_split needs backward computation.
I1007 05:14:58.524435 13601 net.cpp:226] slice_softmax needs backward computation.
I1007 05:14:58.524443 13601 net.cpp:226] fc8_softmax needs backward computation.
I1007 05:14:58.524452 13601 net.cpp:226] softmax_loss needs backward computation.
I1007 05:14:58.524463 13601 net.cpp:228] silence does not need backward computation.
I1007 05:14:58.524472 13601 net.cpp:226] slice_fc8 needs backward computation.
I1007 05:14:58.524495 13601 net.cpp:226] fc8_fc8_new_0_split needs backward computation.
I1007 05:14:58.524518 13601 net.cpp:226] fc8_new needs backward computation.
I1007 05:14:58.524529 13601 net.cpp:226] drop7 needs backward computation.
I1007 05:14:58.524538 13601 net.cpp:226] relu7 needs backward computation.
I1007 05:14:58.524545 13601 net.cpp:226] fc7 needs backward computation.
I1007 05:14:58.524554 13601 net.cpp:226] drop6 needs backward computation.
I1007 05:14:58.524564 13601 net.cpp:226] relu6 needs backward computation.
I1007 05:14:58.524571 13601 net.cpp:226] fc6 needs backward computation.
I1007 05:14:58.524581 13601 net.cpp:226] pool5 needs backward computation.
I1007 05:14:58.524590 13601 net.cpp:226] relu5 needs backward computation.
I1007 05:14:58.524600 13601 net.cpp:226] conv5 needs backward computation.
I1007 05:14:58.524610 13601 net.cpp:226] relu4 needs backward computation.
I1007 05:14:58.524617 13601 net.cpp:226] conv4 needs backward computation.
I1007 05:14:58.524626 13601 net.cpp:226] relu3 needs backward computation.
I1007 05:14:58.524636 13601 net.cpp:226] conv3 needs backward computation.
I1007 05:14:58.524646 13601 net.cpp:228] norm2 does not need backward computation.
I1007 05:14:58.524655 13601 net.cpp:228] pool2 does not need backward computation.
I1007 05:14:58.524664 13601 net.cpp:228] relu2 does not need backward computation.
I1007 05:14:58.524674 13601 net.cpp:228] conv2 does not need backward computation.
I1007 05:14:58.524683 13601 net.cpp:228] norm1 does not need backward computation.
I1007 05:14:58.524693 13601 net.cpp:228] pool1 does not need backward computation.
I1007 05:14:58.524701 13601 net.cpp:228] relu1 does not need backward computation.
I1007 05:14:58.524711 13601 net.cpp:228] conv1 does not need backward computation.
I1007 05:14:58.524721 13601 net.cpp:228] data does not need backward computation.
I1007 05:14:58.524731 13601 net.cpp:228] target_label_silence does not need backward computation.
I1007 05:14:58.524742 13601 net.cpp:228] target_data does not need backward computation.
I1007 05:14:58.524754 13601 net.cpp:228] source_data does not need backward computation.
I1007 05:14:58.524761 13601 net.cpp:270] This network produces output jmmd_loss_jmmd_loss_0_split_0
I1007 05:14:58.524772 13601 net.cpp:270] This network produces output softmax_loss
I1007 05:14:58.524828 13601 net.cpp:283] Network initialization done.
I1007 05:14:58.526751 13601 solver.cpp:182] Creating test net (#0) specified by net file: models/JAN/alexnet/train_val.prototxt
I1007 05:14:58.526859 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer source_data
I1007 05:14:58.526870 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_data
I1007 05:14:58.526878 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_label_silence
I1007 05:14:58.526891 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1007 05:14:58.526924 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer slice_fc8
I1007 05:14:58.526933 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence
I1007 05:14:58.526942 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer softmax_loss
I1007 05:14:58.526950 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc8_softmax
I1007 05:14:58.526958 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer slice_softmax
I1007 05:14:58.526967 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer jmmd_loss
I1007 05:14:58.526974 13601 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence_loss_value
I1007 05:14:58.527487 13601 net.cpp:58] Initializing net from parameters: 
name: "amazon_to_webcam"
state {
  phase: TEST
}
layer {
  name: "test_data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/amazon_list.txt"
    batch_size: 1
    shuffle: false
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1007 05:14:58.527688 13601 layer_factory.hpp:77] Creating layer test_data
I1007 05:14:58.527714 13601 net.cpp:100] Creating Layer test_data
I1007 05:14:58.527726 13601 net.cpp:408] test_data -> data
I1007 05:14:58.527745 13601 net.cpp:408] test_data -> label
I1007 05:14:58.527761 13601 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1007 05:14:58.532810 13601 image_data_layer.cpp:38] Opening file ./data/office/amazon_list.txt
I1007 05:14:58.534518 13601 image_data_layer.cpp:58] A total of 2817 images.
I1007 05:14:58.537106 13601 image_data_layer.cpp:85] output data size: 1,3,227,227
I1007 05:14:58.541575 13601 net.cpp:150] Setting up test_data
I1007 05:14:58.541605 13601 net.cpp:157] Top shape: 1 3 227 227 (154587)
I1007 05:14:58.541617 13601 net.cpp:157] Top shape: 1 (1)
I1007 05:14:58.541625 13601 net.cpp:165] Memory required for data: 618352
I1007 05:14:58.541637 13601 layer_factory.hpp:77] Creating layer conv1
I1007 05:14:58.541664 13601 net.cpp:100] Creating Layer conv1
I1007 05:14:58.541673 13601 net.cpp:434] conv1 <- data
I1007 05:14:58.541687 13601 net.cpp:408] conv1 -> conv1
I1007 05:14:58.543938 13601 net.cpp:150] Setting up conv1
I1007 05:14:58.543961 13601 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1007 05:14:58.543968 13601 net.cpp:165] Memory required for data: 1779952
I1007 05:14:58.543988 13601 layer_factory.hpp:77] Creating layer relu1
I1007 05:14:58.544003 13601 net.cpp:100] Creating Layer relu1
I1007 05:14:58.544010 13601 net.cpp:434] relu1 <- conv1
I1007 05:14:58.544020 13601 net.cpp:395] relu1 -> conv1 (in-place)
I1007 05:14:58.544034 13601 net.cpp:150] Setting up relu1
I1007 05:14:58.544044 13601 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1007 05:14:58.544050 13601 net.cpp:165] Memory required for data: 2941552
I1007 05:14:58.544057 13601 layer_factory.hpp:77] Creating layer pool1
I1007 05:14:58.544070 13601 net.cpp:100] Creating Layer pool1
I1007 05:14:58.544077 13601 net.cpp:434] pool1 <- conv1
I1007 05:14:58.544087 13601 net.cpp:408] pool1 -> pool1
I1007 05:14:58.544149 13601 net.cpp:150] Setting up pool1
I1007 05:14:58.544162 13601 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1007 05:14:58.544169 13601 net.cpp:165] Memory required for data: 3221488
I1007 05:14:58.544176 13601 layer_factory.hpp:77] Creating layer norm1
I1007 05:14:58.544189 13601 net.cpp:100] Creating Layer norm1
I1007 05:14:58.544198 13601 net.cpp:434] norm1 <- pool1
I1007 05:14:58.544209 13601 net.cpp:408] norm1 -> norm1
I1007 05:14:58.544262 13601 net.cpp:150] Setting up norm1
I1007 05:14:58.544273 13601 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1007 05:14:58.544281 13601 net.cpp:165] Memory required for data: 3501424
I1007 05:14:58.544288 13601 layer_factory.hpp:77] Creating layer conv2
I1007 05:14:58.544304 13601 net.cpp:100] Creating Layer conv2
I1007 05:14:58.544312 13601 net.cpp:434] conv2 <- norm1
I1007 05:14:58.544323 13601 net.cpp:408] conv2 -> conv2
I1007 05:14:58.558588 13601 net.cpp:150] Setting up conv2
I1007 05:14:58.558609 13601 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1007 05:14:58.558616 13601 net.cpp:165] Memory required for data: 4247920
I1007 05:14:58.558650 13601 layer_factory.hpp:77] Creating layer relu2
I1007 05:14:58.558681 13601 net.cpp:100] Creating Layer relu2
I1007 05:14:58.558689 13601 net.cpp:434] relu2 <- conv2
I1007 05:14:58.558698 13601 net.cpp:395] relu2 -> conv2 (in-place)
I1007 05:14:58.558712 13601 net.cpp:150] Setting up relu2
I1007 05:14:58.558722 13601 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1007 05:14:58.558727 13601 net.cpp:165] Memory required for data: 4994416
I1007 05:14:58.558735 13601 layer_factory.hpp:77] Creating layer pool2
I1007 05:14:58.558746 13601 net.cpp:100] Creating Layer pool2
I1007 05:14:58.558753 13601 net.cpp:434] pool2 <- conv2
I1007 05:14:58.558763 13601 net.cpp:408] pool2 -> pool2
I1007 05:14:58.558821 13601 net.cpp:150] Setting up pool2
I1007 05:14:58.558833 13601 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1007 05:14:58.558840 13601 net.cpp:165] Memory required for data: 5167472
I1007 05:14:58.558846 13601 layer_factory.hpp:77] Creating layer norm2
I1007 05:14:58.558858 13601 net.cpp:100] Creating Layer norm2
I1007 05:14:58.558869 13601 net.cpp:434] norm2 <- pool2
I1007 05:14:58.558878 13601 net.cpp:408] norm2 -> norm2
I1007 05:14:58.558925 13601 net.cpp:150] Setting up norm2
I1007 05:14:58.558935 13601 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1007 05:14:58.558943 13601 net.cpp:165] Memory required for data: 5340528
I1007 05:14:58.558949 13601 layer_factory.hpp:77] Creating layer conv3
I1007 05:14:58.558964 13601 net.cpp:100] Creating Layer conv3
I1007 05:14:58.558971 13601 net.cpp:434] conv3 <- norm2
I1007 05:14:58.558982 13601 net.cpp:408] conv3 -> conv3
I1007 05:14:58.596575 13601 net.cpp:150] Setting up conv3
I1007 05:14:58.596611 13601 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1007 05:14:58.596618 13601 net.cpp:165] Memory required for data: 5600112
I1007 05:14:58.596637 13601 layer_factory.hpp:77] Creating layer relu3
I1007 05:14:58.596650 13601 net.cpp:100] Creating Layer relu3
I1007 05:14:58.596657 13601 net.cpp:434] relu3 <- conv3
I1007 05:14:58.596668 13601 net.cpp:395] relu3 -> conv3 (in-place)
I1007 05:14:58.596683 13601 net.cpp:150] Setting up relu3
I1007 05:14:58.596689 13601 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1007 05:14:58.596695 13601 net.cpp:165] Memory required for data: 5859696
I1007 05:14:58.596701 13601 layer_factory.hpp:77] Creating layer conv4
I1007 05:14:58.596717 13601 net.cpp:100] Creating Layer conv4
I1007 05:14:58.596724 13601 net.cpp:434] conv4 <- conv3
I1007 05:14:58.596734 13601 net.cpp:408] conv4 -> conv4
I1007 05:14:58.621482 13601 net.cpp:150] Setting up conv4
I1007 05:14:58.621510 13601 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1007 05:14:58.621515 13601 net.cpp:165] Memory required for data: 6119280
I1007 05:14:58.621526 13601 layer_factory.hpp:77] Creating layer relu4
I1007 05:14:58.621536 13601 net.cpp:100] Creating Layer relu4
I1007 05:14:58.621543 13601 net.cpp:434] relu4 <- conv4
I1007 05:14:58.621552 13601 net.cpp:395] relu4 -> conv4 (in-place)
I1007 05:14:58.621562 13601 net.cpp:150] Setting up relu4
I1007 05:14:58.621569 13601 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1007 05:14:58.621575 13601 net.cpp:165] Memory required for data: 6378864
I1007 05:14:58.621580 13601 layer_factory.hpp:77] Creating layer conv5
I1007 05:14:58.621593 13601 net.cpp:100] Creating Layer conv5
I1007 05:14:58.621599 13601 net.cpp:434] conv5 <- conv4
I1007 05:14:58.621609 13601 net.cpp:408] conv5 -> conv5
I1007 05:14:58.637230 13601 net.cpp:150] Setting up conv5
I1007 05:14:58.637253 13601 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1007 05:14:58.637257 13601 net.cpp:165] Memory required for data: 6551920
I1007 05:14:58.637272 13601 layer_factory.hpp:77] Creating layer relu5
I1007 05:14:58.637281 13601 net.cpp:100] Creating Layer relu5
I1007 05:14:58.637286 13601 net.cpp:434] relu5 <- conv5
I1007 05:14:58.637295 13601 net.cpp:395] relu5 -> conv5 (in-place)
I1007 05:14:58.637305 13601 net.cpp:150] Setting up relu5
I1007 05:14:58.637310 13601 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1007 05:14:58.637315 13601 net.cpp:165] Memory required for data: 6724976
I1007 05:14:58.637336 13601 layer_factory.hpp:77] Creating layer pool5
I1007 05:14:58.637364 13601 net.cpp:100] Creating Layer pool5
I1007 05:14:58.637369 13601 net.cpp:434] pool5 <- conv5
I1007 05:14:58.637377 13601 net.cpp:408] pool5 -> pool5
I1007 05:14:58.637423 13601 net.cpp:150] Setting up pool5
I1007 05:14:58.637431 13601 net.cpp:157] Top shape: 1 256 6 6 (9216)
I1007 05:14:58.637436 13601 net.cpp:165] Memory required for data: 6761840
I1007 05:14:58.637440 13601 layer_factory.hpp:77] Creating layer fc6
I1007 05:14:58.637454 13601 net.cpp:100] Creating Layer fc6
I1007 05:14:58.637459 13601 net.cpp:434] fc6 <- pool5
I1007 05:14:58.637467 13601 net.cpp:408] fc6 -> fc6
I1007 05:14:59.603998 13601 net.cpp:150] Setting up fc6
I1007 05:14:59.604035 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:14:59.604040 13601 net.cpp:165] Memory required for data: 6778224
I1007 05:14:59.604049 13601 layer_factory.hpp:77] Creating layer relu6
I1007 05:14:59.604063 13601 net.cpp:100] Creating Layer relu6
I1007 05:14:59.604068 13601 net.cpp:434] relu6 <- fc6
I1007 05:14:59.604075 13601 net.cpp:395] relu6 -> fc6 (in-place)
I1007 05:14:59.604086 13601 net.cpp:150] Setting up relu6
I1007 05:14:59.604090 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:14:59.604094 13601 net.cpp:165] Memory required for data: 6794608
I1007 05:14:59.604097 13601 layer_factory.hpp:77] Creating layer drop6
I1007 05:14:59.604105 13601 net.cpp:100] Creating Layer drop6
I1007 05:14:59.604110 13601 net.cpp:434] drop6 <- fc6
I1007 05:14:59.604115 13601 net.cpp:395] drop6 -> fc6 (in-place)
I1007 05:14:59.604135 13601 net.cpp:150] Setting up drop6
I1007 05:14:59.604140 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:14:59.604143 13601 net.cpp:165] Memory required for data: 6810992
I1007 05:14:59.604147 13601 layer_factory.hpp:77] Creating layer fc7
I1007 05:14:59.604156 13601 net.cpp:100] Creating Layer fc7
I1007 05:14:59.604159 13601 net.cpp:434] fc7 <- fc6
I1007 05:14:59.604166 13601 net.cpp:408] fc7 -> fc7
I1007 05:15:00.108875 13601 net.cpp:150] Setting up fc7
I1007 05:15:00.108927 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:15:00.108932 13601 net.cpp:165] Memory required for data: 6827376
I1007 05:15:00.108943 13601 layer_factory.hpp:77] Creating layer relu7
I1007 05:15:00.108959 13601 net.cpp:100] Creating Layer relu7
I1007 05:15:00.108966 13601 net.cpp:434] relu7 <- fc7
I1007 05:15:00.108975 13601 net.cpp:395] relu7 -> fc7 (in-place)
I1007 05:15:00.108989 13601 net.cpp:150] Setting up relu7
I1007 05:15:00.108994 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:15:00.108999 13601 net.cpp:165] Memory required for data: 6843760
I1007 05:15:00.109004 13601 layer_factory.hpp:77] Creating layer drop7
I1007 05:15:00.109014 13601 net.cpp:100] Creating Layer drop7
I1007 05:15:00.109019 13601 net.cpp:434] drop7 <- fc7
I1007 05:15:00.109025 13601 net.cpp:395] drop7 -> fc7 (in-place)
I1007 05:15:00.109050 13601 net.cpp:150] Setting up drop7
I1007 05:15:00.109057 13601 net.cpp:157] Top shape: 1 4096 (4096)
I1007 05:15:00.109061 13601 net.cpp:165] Memory required for data: 6860144
I1007 05:15:00.109066 13601 layer_factory.hpp:77] Creating layer fc8_new
I1007 05:15:00.109077 13601 net.cpp:100] Creating Layer fc8_new
I1007 05:15:00.109081 13601 net.cpp:434] fc8_new <- fc7
I1007 05:15:00.109089 13601 net.cpp:408] fc8_new -> fc8
I1007 05:15:00.112481 13601 net.cpp:150] Setting up fc8_new
I1007 05:15:00.112493 13601 net.cpp:157] Top shape: 1 31 (31)
I1007 05:15:00.112498 13601 net.cpp:165] Memory required for data: 6860268
I1007 05:15:00.112504 13601 layer_factory.hpp:77] Creating layer accuracy
I1007 05:15:00.112514 13601 net.cpp:100] Creating Layer accuracy
I1007 05:15:00.112519 13601 net.cpp:434] accuracy <- fc8
I1007 05:15:00.112524 13601 net.cpp:434] accuracy <- label
I1007 05:15:00.112532 13601 net.cpp:408] accuracy -> accuracy
I1007 05:15:00.112543 13601 net.cpp:150] Setting up accuracy
I1007 05:15:00.112548 13601 net.cpp:157] Top shape: (1)
I1007 05:15:00.112552 13601 net.cpp:165] Memory required for data: 6860272
I1007 05:15:00.112594 13601 net.cpp:228] accuracy does not need backward computation.
I1007 05:15:00.112617 13601 net.cpp:228] fc8_new does not need backward computation.
I1007 05:15:00.112622 13601 net.cpp:228] drop7 does not need backward computation.
I1007 05:15:00.112627 13601 net.cpp:228] relu7 does not need backward computation.
I1007 05:15:00.112630 13601 net.cpp:228] fc7 does not need backward computation.
I1007 05:15:00.112635 13601 net.cpp:228] drop6 does not need backward computation.
I1007 05:15:00.112639 13601 net.cpp:228] relu6 does not need backward computation.
I1007 05:15:00.112643 13601 net.cpp:228] fc6 does not need backward computation.
I1007 05:15:00.112649 13601 net.cpp:228] pool5 does not need backward computation.
I1007 05:15:00.112654 13601 net.cpp:228] relu5 does not need backward computation.
I1007 05:15:00.112658 13601 net.cpp:228] conv5 does not need backward computation.
I1007 05:15:00.112663 13601 net.cpp:228] relu4 does not need backward computation.
I1007 05:15:00.112668 13601 net.cpp:228] conv4 does not need backward computation.
I1007 05:15:00.112673 13601 net.cpp:228] relu3 does not need backward computation.
I1007 05:15:00.112678 13601 net.cpp:228] conv3 does not need backward computation.
I1007 05:15:00.112682 13601 net.cpp:228] norm2 does not need backward computation.
I1007 05:15:00.112686 13601 net.cpp:228] pool2 does not need backward computation.
I1007 05:15:00.112692 13601 net.cpp:228] relu2 does not need backward computation.
I1007 05:15:00.112696 13601 net.cpp:228] conv2 does not need backward computation.
I1007 05:15:00.112700 13601 net.cpp:228] norm1 does not need backward computation.
I1007 05:15:00.112705 13601 net.cpp:228] pool1 does not need backward computation.
I1007 05:15:00.112710 13601 net.cpp:228] relu1 does not need backward computation.
I1007 05:15:00.112715 13601 net.cpp:228] conv1 does not need backward computation.
I1007 05:15:00.112718 13601 net.cpp:228] test_data does not need backward computation.
I1007 05:15:00.112722 13601 net.cpp:270] This network produces output accuracy
I1007 05:15:00.112740 13601 net.cpp:283] Network initialization done.
I1007 05:15:00.112874 13601 solver.cpp:61] Solver scaffolding done.
I1007 05:15:00.113868 13601 caffe.cpp:155] Finetuning from models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1007 05:15:00.336170 13601 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1007 05:15:00.336221 13601 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1007 05:15:00.336230 13601 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1007 05:15:00.336388 13601 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1007 05:15:03.300621 13601 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1007 05:15:03.367054 13601 net.cpp:761] Ignoring source layer fc8
I1007 05:15:03.367089 13601 net.cpp:761] Ignoring source layer loss
I1007 05:15:03.577031 13601 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1007 05:15:03.577075 13601 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1007 05:15:03.577078 13601 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1007 05:15:03.577117 13601 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1007 05:15:05.899507 13601 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1007 05:15:05.900712 13601 net.cpp:761] Ignoring source layer data
I1007 05:15:05.960819 13601 net.cpp:761] Ignoring source layer fc8
I1007 05:15:05.960880 13601 net.cpp:761] Ignoring source layer loss
I1007 05:15:05.969629 13601 caffe.cpp:251] Starting Optimization
I1007 05:15:05.969676 13601 solver.cpp:282] Solving amazon_to_webcam
I1007 05:15:05.969691 13601 solver.cpp:283] Learning Rate Policy: inv
I1007 05:15:05.980311 13601 solver.cpp:340] Iteration 0, Testing net (#0)
I1007 05:15:05.980340 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:15:05.980345 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:15:05.980347 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:15:05.980351 13601 net.cpp:693] Ignoring source layer data
I1007 05:15:06.024896 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:15:06.024933 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:15:06.024938 13601 net.cpp:693] Ignoring source layer silence
I1007 05:15:06.024941 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:15:06.024945 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:15:06.024947 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:15:06.024951 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:15:06.024955 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:15:06.024957 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:15:06.024960 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:15:06.024965 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:15:06.067865 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:15:08.813375 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:15:11.455962 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:15:13.610698 13601 solver.cpp:407]     Test net output #0: accuracy = 0.0305289
I1007 05:15:13.794064 13601 solver.cpp:231] Iteration 0, loss = 4.11315
I1007 05:15:13.794121 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:15:13.794131 13601 solver.cpp:247]     Train net output #1: softmax_loss = 4.11315 (* 1 = 4.11315 loss)
I1007 05:15:13.794159 13601 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1007 05:16:47.145514 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:19:10.898237 13601 solver.cpp:340] Iteration 500, Testing net (#0)
I1007 05:19:10.898507 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:19:10.898541 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:19:10.898551 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:19:10.898560 13601 net.cpp:693] Ignoring source layer data
I1007 05:19:10.898635 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:19:10.898663 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:19:10.898671 13601 net.cpp:693] Ignoring source layer silence
I1007 05:19:10.898679 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:19:10.898687 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:19:10.898705 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:19:10.898712 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:19:10.898721 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:19:10.898736 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:19:10.898752 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:19:10.898761 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:19:12.847491 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:19:15.406415 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:19:17.942626 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:19:18.245364 13601 solver.cpp:407]     Test net output #0: accuracy = 0.544551
I1007 05:19:18.393034 13601 solver.cpp:231] Iteration 500, loss = 0.0239809
I1007 05:19:18.393097 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:19:18.393110 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0239809 (* 1 = 0.0239809 loss)
I1007 05:19:18.393122 13601 sgd_solver.cpp:106] Iteration 500, lr = 0.000737788
I1007 05:23:05.169868 13601 solver.cpp:340] Iteration 1000, Testing net (#0)
I1007 05:23:05.170089 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:23:05.170099 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:23:05.170105 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:23:05.170114 13601 net.cpp:693] Ignoring source layer data
I1007 05:23:05.170145 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:23:05.170151 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:23:05.170156 13601 net.cpp:693] Ignoring source layer silence
I1007 05:23:05.170159 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:23:05.170164 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:23:05.170169 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:23:05.170174 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:23:05.170178 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:23:05.170183 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:23:05.170188 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:23:05.170193 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:23:06.381656 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:23:08.934522 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:23:11.479482 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:23:12.576784 13601 solver.cpp:407]     Test net output #0: accuracy = 0.558395
I1007 05:23:12.725438 13601 solver.cpp:231] Iteration 1000, loss = 0.0215211
I1007 05:23:12.725493 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:23:12.725502 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0215211 (* 1 = 0.0215211 loss)
I1007 05:23:12.725514 13601 sgd_solver.cpp:106] Iteration 1000, lr = 0.000594604
I1007 05:26:58.785854 13601 solver.cpp:340] Iteration 1500, Testing net (#0)
I1007 05:26:58.786021 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:26:58.786033 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:26:58.786038 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:26:58.786042 13601 net.cpp:693] Ignoring source layer data
I1007 05:26:58.786072 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:26:58.786077 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:26:58.786082 13601 net.cpp:693] Ignoring source layer silence
I1007 05:26:58.786087 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:26:58.786092 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:26:58.786098 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:26:58.786100 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:26:58.786106 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:26:58.786110 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:26:58.786115 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:26:58.786120 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:26:59.111358 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:27:01.758298 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:27:04.309553 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:27:06.185384 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56159
I1007 05:27:06.334553 13601 solver.cpp:231] Iteration 1500, loss = 0.0377493
I1007 05:27:06.334610 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:27:06.334621 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0377493 (* 1 = 0.0377493 loss)
I1007 05:27:06.334630 13601 sgd_solver.cpp:106] Iteration 1500, lr = 0.000502973
I1007 05:29:05.734467 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:30:54.163172 13601 solver.cpp:340] Iteration 2000, Testing net (#0)
I1007 05:30:54.163313 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:30:54.163322 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:30:54.163326 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:30:54.163331 13601 net.cpp:693] Ignoring source layer data
I1007 05:30:54.163359 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:30:54.163367 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:30:54.163370 13601 net.cpp:693] Ignoring source layer silence
I1007 05:30:54.163375 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:30:54.163385 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:30:54.163389 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:30:54.163394 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:30:54.163399 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:30:54.163404 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:30:54.163408 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:30:54.163411 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:30:56.353009 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:30:58.912822 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:31:01.454390 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:31:01.580518 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56585
I1007 05:31:01.727901 13601 solver.cpp:231] Iteration 2000, loss = 0.00643297
I1007 05:31:01.727957 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:31:01.727965 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00643296 (* 1 = 0.00643296 loss)
I1007 05:31:01.727972 13601 sgd_solver.cpp:106] Iteration 2000, lr = 0.000438691
I1007 05:34:49.121076 13601 solver.cpp:340] Iteration 2500, Testing net (#0)
I1007 05:34:49.121305 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:34:49.121337 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:34:49.121352 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:34:49.121361 13601 net.cpp:693] Ignoring source layer data
I1007 05:34:49.121431 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:34:49.121459 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:34:49.121467 13601 net.cpp:693] Ignoring source layer silence
I1007 05:34:49.121480 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:34:49.121496 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:34:49.121505 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:34:49.121515 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:34:49.121525 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:34:49.121533 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:34:49.121546 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:34:49.121562 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:34:50.539306 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:34:53.088919 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:34:55.627038 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:34:56.539358 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56514
I1007 05:34:56.687072 13601 solver.cpp:231] Iteration 2500, loss = 0.00193334
I1007 05:34:56.687167 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:34:56.687178 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00193333 (* 1 = 0.00193333 loss)
I1007 05:34:56.687189 13601 sgd_solver.cpp:106] Iteration 2500, lr = 0.000390795
I1007 05:38:42.418582 13601 solver.cpp:340] Iteration 3000, Testing net (#0)
I1007 05:38:42.418875 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:38:42.418900 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:38:42.418907 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:38:42.418912 13601 net.cpp:693] Ignoring source layer data
I1007 05:38:42.419061 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:38:42.419070 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:38:42.419073 13601 net.cpp:693] Ignoring source layer silence
I1007 05:38:42.419077 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:38:42.419082 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:38:42.419086 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:38:42.419090 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:38:42.419095 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:38:42.419100 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:38:42.419103 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:38:42.419106 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:38:42.965921 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:38:45.581629 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:38:48.128945 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:38:49.818756 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56159
I1007 05:38:49.968792 13601 solver.cpp:231] Iteration 3000, loss = 0.000563477
I1007 05:38:49.968852 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:38:49.968861 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000563458 (* 1 = 0.000563458 loss)
I1007 05:38:49.968870 13601 sgd_solver.cpp:106] Iteration 3000, lr = 0.000353553
I1007 05:41:20.796491 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:42:37.723438 13601 solver.cpp:340] Iteration 3500, Testing net (#0)
I1007 05:42:37.723673 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:42:37.723711 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:42:37.723721 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:42:37.723731 13601 net.cpp:693] Ignoring source layer data
I1007 05:42:37.723788 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:42:37.723810 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:42:37.723819 13601 net.cpp:693] Ignoring source layer silence
I1007 05:42:37.723829 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:42:37.723836 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:42:37.723857 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:42:37.723866 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:42:37.723875 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:42:37.723884 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:42:37.723894 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:42:37.723903 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:42:40.134141 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:42:42.690953 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:42:45.399385 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56727
I1007 05:42:45.549968 13601 solver.cpp:231] Iteration 3500, loss = 0.000363307
I1007 05:42:45.550024 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:42:45.550061 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00036328 (* 1 = 0.00036328 loss)
I1007 05:42:45.550077 13601 sgd_solver.cpp:106] Iteration 3500, lr = 0.000323661
I1007 05:42:55.414208 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:46:34.695857 13601 solver.cpp:340] Iteration 4000, Testing net (#0)
I1007 05:46:34.696115 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:46:34.696133 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:46:34.696140 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:46:34.696144 13601 net.cpp:693] Ignoring source layer data
I1007 05:46:34.696183 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:46:34.696188 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:46:34.696192 13601 net.cpp:693] Ignoring source layer silence
I1007 05:46:34.696197 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:46:34.696200 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:46:34.696204 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:46:34.696218 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:46:34.696223 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:46:34.696228 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:46:34.696231 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:46:34.696235 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:46:36.349581 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:46:39.012924 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:46:41.639724 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:46:42.384558 13601 solver.cpp:407]     Test net output #0: accuracy = 0.56727
I1007 05:46:42.532151 13601 solver.cpp:231] Iteration 4000, loss = 0.00102522
I1007 05:46:42.532205 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:46:42.532213 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00102519 (* 1 = 0.00102519 loss)
I1007 05:46:42.532222 13601 sgd_solver.cpp:106] Iteration 4000, lr = 0.00029907
I1007 05:50:28.337393 13601 solver.cpp:340] Iteration 4500, Testing net (#0)
I1007 05:50:28.337539 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:50:28.337548 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:50:28.337551 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:50:28.337556 13601 net.cpp:693] Ignoring source layer data
I1007 05:50:28.337586 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:50:28.337596 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:50:28.337601 13601 net.cpp:693] Ignoring source layer silence
I1007 05:50:28.337606 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:50:28.337610 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:50:28.337615 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:50:28.337618 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:50:28.337623 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:50:28.337627 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:50:28.337631 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:50:28.337635 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:50:29.009234 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:50:31.571506 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:50:34.122805 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:50:35.630986 13601 solver.cpp:407]     Test net output #0: accuracy = 0.574015
I1007 05:50:35.778553 13601 solver.cpp:231] Iteration 4500, loss = 0.000239496
I1007 05:50:35.778604 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:50:35.778638 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000239465 (* 1 = 0.000239465 loss)
I1007 05:50:35.778647 13601 sgd_solver.cpp:106] Iteration 4500, lr = 0.000278438
I1007 05:53:38.230031 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:54:20.868362 13601 solver.cpp:340] Iteration 5000, Testing net (#0)
I1007 05:54:20.868537 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:54:20.868547 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:54:20.868554 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:54:20.868566 13601 net.cpp:693] Ignoring source layer data
I1007 05:54:20.868595 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:54:20.868599 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:54:20.868604 13601 net.cpp:693] Ignoring source layer silence
I1007 05:54:20.868608 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:54:20.868613 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:54:20.868618 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:54:20.868623 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:54:20.868626 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:54:20.868630 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:54:20.868634 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:54:20.868639 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:54:23.408478 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:54:25.952389 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:54:28.241919 13601 solver.cpp:407]     Test net output #0: accuracy = 0.573305
I1007 05:54:28.391772 13601 solver.cpp:231] Iteration 5000, loss = 0.00237054
I1007 05:54:28.391813 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:54:28.391822 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0023705 (* 1 = 0.0023705 loss)
I1007 05:54:28.391837 13601 sgd_solver.cpp:106] Iteration 5000, lr = 0.000260847
I1007 05:55:10.868057 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:58:11.916227 13601 solver.cpp:340] Iteration 5500, Testing net (#0)
I1007 05:58:11.916409 13601 net.cpp:693] Ignoring source layer source_data
I1007 05:58:11.916429 13601 net.cpp:693] Ignoring source layer target_data
I1007 05:58:11.916435 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 05:58:11.916440 13601 net.cpp:693] Ignoring source layer data
I1007 05:58:11.916479 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 05:58:11.916487 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 05:58:11.916493 13601 net.cpp:693] Ignoring source layer silence
I1007 05:58:11.916497 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 05:58:11.916501 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 05:58:11.916505 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 05:58:11.916512 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 05:58:11.916515 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 05:58:11.916519 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 05:58:11.916523 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 05:58:11.916528 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 05:58:13.658991 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:58:16.214766 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:58:18.749200 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 05:58:19.287201 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57863
I1007 05:58:19.441686 13601 solver.cpp:231] Iteration 5500, loss = 9.8607e-05
I1007 05:58:19.441753 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 05:58:19.441788 13601 solver.cpp:247]     Train net output #1: softmax_loss = 9.85683e-05 (* 1 = 9.85683e-05 loss)
I1007 05:58:19.441803 13601 sgd_solver.cpp:106] Iteration 5500, lr = 0.000245649
I1007 06:02:06.822201 13601 solver.cpp:340] Iteration 6000, Testing net (#0)
I1007 06:02:06.822880 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:02:06.822912 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:02:06.822929 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:02:06.822938 13601 net.cpp:693] Ignoring source layer data
I1007 06:02:06.823292 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:02:06.823312 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:02:06.823321 13601 net.cpp:693] Ignoring source layer silence
I1007 06:02:06.823329 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:02:06.823338 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:02:06.823348 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:02:06.823356 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:02:06.823364 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:02:06.823374 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:02:06.823380 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:02:06.823390 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:02:07.657549 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:02:10.315193 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:02:12.964170 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:02:14.359921 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57792
I1007 06:02:14.509980 13601 solver.cpp:231] Iteration 6000, loss = 0.000397932
I1007 06:02:14.510040 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:02:14.510049 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000397886 (* 1 = 0.000397886 loss)
I1007 06:02:14.510059 13601 sgd_solver.cpp:106] Iteration 6000, lr = 0.000232368
I1007 06:05:49.149344 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:05:58.126538 13601 solver.cpp:340] Iteration 6500, Testing net (#0)
I1007 06:05:58.126595 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:05:58.126602 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:05:58.126606 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:05:58.126611 13601 net.cpp:693] Ignoring source layer data
I1007 06:05:58.126647 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:05:58.126655 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:05:58.126659 13601 net.cpp:693] Ignoring source layer silence
I1007 06:05:58.126663 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:05:58.126667 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:05:58.126672 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:05:58.126677 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:05:58.126682 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:05:58.126685 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:05:58.126691 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:05:58.126695 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:06:00.837271 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:06:03.383114 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:06:05.488735 13601 solver.cpp:407]     Test net output #0: accuracy = 0.574015
I1007 06:06:05.636497 13601 solver.cpp:231] Iteration 6500, loss = 0.00061965
I1007 06:06:05.636553 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:06:05.636586 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000619599 (* 1 = 0.000619599 loss)
I1007 06:06:05.636600 13601 sgd_solver.cpp:106] Iteration 6500, lr = 0.00022065
I1007 06:07:21.052590 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:09:49.199017 13601 solver.cpp:340] Iteration 7000, Testing net (#0)
I1007 06:09:49.199229 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:09:49.199249 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:09:49.199254 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:09:49.199259 13601 net.cpp:693] Ignoring source layer data
I1007 06:09:49.199290 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:09:49.199300 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:09:49.199303 13601 net.cpp:693] Ignoring source layer silence
I1007 06:09:49.199307 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:09:49.199311 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:09:49.199316 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:09:49.199321 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:09:49.199324 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:09:49.199329 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:09:49.199333 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:09:49.199338 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:09:51.159234 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:09:53.716119 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:09:56.251756 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:09:56.609110 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58005
I1007 06:09:56.759097 13601 solver.cpp:231] Iteration 7000, loss = 0.00156139
I1007 06:09:56.759160 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:09:56.759171 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00156134 (* 1 = 0.00156134 loss)
I1007 06:09:56.759184 13601 sgd_solver.cpp:106] Iteration 7000, lr = 0.000210224
I1007 06:13:39.876266 13601 solver.cpp:340] Iteration 7500, Testing net (#0)
I1007 06:13:39.876402 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:13:39.876410 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:13:39.876415 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:13:39.876420 13601 net.cpp:693] Ignoring source layer data
I1007 06:13:39.876454 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:13:39.876462 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:13:39.876466 13601 net.cpp:693] Ignoring source layer silence
I1007 06:13:39.876471 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:13:39.876474 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:13:39.876479 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:13:39.876483 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:13:39.876487 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:13:39.876492 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:13:39.876495 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:13:39.876499 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:13:41.039662 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:13:43.592000 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:13:46.128378 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:13:47.277848 13601 solver.cpp:407]     Test net output #0: accuracy = 0.569045
I1007 06:13:47.426303 13601 solver.cpp:231] Iteration 7500, loss = 0.000287487
I1007 06:13:47.426355 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:13:47.426393 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000287431 (* 1 = 0.000287431 loss)
I1007 06:13:47.426403 13601 sgd_solver.cpp:106] Iteration 7500, lr = 0.00020088
I1007 06:17:31.865416 13601 solver.cpp:340] Iteration 8000, Testing net (#0)
I1007 06:17:31.865692 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:17:31.865725 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:17:31.865733 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:17:31.865743 13601 net.cpp:693] Ignoring source layer data
I1007 06:17:31.865813 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:17:31.865836 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:17:31.865849 13601 net.cpp:693] Ignoring source layer silence
I1007 06:17:31.865862 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:17:31.865887 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:17:31.865905 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:17:31.865917 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:17:31.865931 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:17:31.865945 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:17:31.865962 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:17:31.865985 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:17:32.126318 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:17:34.848906 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:17:37.394347 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:17:39.316033 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57934
I1007 06:17:39.463539 13601 solver.cpp:231] Iteration 8000, loss = 0.000322117
I1007 06:17:39.463594 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:17:39.463604 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000322061 (* 1 = 0.000322061 loss)
I1007 06:17:39.463613 13601 sgd_solver.cpp:106] Iteration 8000, lr = 0.00019245
I1007 06:19:24.302073 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:21:22.483970 13601 solver.cpp:340] Iteration 8500, Testing net (#0)
I1007 06:21:22.484195 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:21:22.484225 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:21:22.484235 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:21:22.484251 13601 net.cpp:693] Ignoring source layer data
I1007 06:21:22.484309 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:21:22.484318 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:21:22.484326 13601 net.cpp:693] Ignoring source layer silence
I1007 06:21:22.484334 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:21:22.484344 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:21:22.484351 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:21:22.484359 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:21:22.484367 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:21:22.484377 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:21:22.484385 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:21:22.484392 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:21:24.615195 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:21:27.185149 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:21:29.713204 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:21:29.893770 13601 solver.cpp:407]     Test net output #0: accuracy = 0.571885
I1007 06:21:30.040822 13601 solver.cpp:231] Iteration 8500, loss = 0.00106607
I1007 06:21:30.040873 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:21:30.040906 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00106601 (* 1 = 0.00106601 loss)
I1007 06:21:30.040916 13601 sgd_solver.cpp:106] Iteration 8500, lr = 0.000184802
I1007 06:25:10.422766 13601 solver.cpp:340] Iteration 9000, Testing net (#0)
I1007 06:25:10.423009 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:25:10.423034 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:25:10.423043 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:25:10.423049 13601 net.cpp:693] Ignoring source layer data
I1007 06:25:10.423096 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:25:10.423107 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:25:10.423113 13601 net.cpp:693] Ignoring source layer silence
I1007 06:25:10.423120 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:25:10.423132 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:25:10.423140 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:25:10.423146 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:25:10.423183 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:25:10.423194 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:25:10.423202 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:25:10.423207 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:25:11.772475 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:25:14.337153 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:25:16.869524 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:25:17.846839 13601 solver.cpp:407]     Test net output #0: accuracy = 0.571175
I1007 06:25:17.994422 13601 solver.cpp:231] Iteration 9000, loss = 0.00261508
I1007 06:25:17.994470 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:25:17.994485 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00261503 (* 1 = 0.00261503 loss)
I1007 06:25:17.994498 13601 sgd_solver.cpp:106] Iteration 9000, lr = 0.000177828
I1007 06:25:53.666834 13601 solver.cpp:457] Snapshotting to binary proto file models/JAN/alexnet/trained_model_iter_9082.caffemodel
I1007 06:25:54.772579 13601 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/JAN/alexnet/trained_model_iter_9082.solverstate
I1007 06:29:13.682703 13601 solver.cpp:340] Iteration 9500, Testing net (#0)
I1007 06:29:13.682930 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:29:13.682958 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:29:13.682968 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:29:13.682976 13601 net.cpp:693] Ignoring source layer data
I1007 06:29:13.683037 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:29:13.683045 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:29:13.683055 13601 net.cpp:693] Ignoring source layer silence
I1007 06:29:13.683063 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:29:13.683070 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:29:13.683078 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:29:13.683086 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:29:13.683094 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:29:13.683102 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:29:13.683109 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:29:13.683120 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:29:14.179826 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:29:16.894224 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:29:19.528772 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:29:21.362947 13601 solver.cpp:407]     Test net output #0: accuracy = 0.575435
I1007 06:29:21.512439 13601 solver.cpp:231] Iteration 9500, loss = 0.00192726
I1007 06:29:21.512491 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:29:21.512501 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00192721 (* 1 = 0.00192721 loss)
I1007 06:29:21.512512 13601 sgd_solver.cpp:106] Iteration 9500, lr = 0.000171438
I1007 06:31:38.959090 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:32:59.660193 13601 solver.cpp:340] Iteration 10000, Testing net (#0)
I1007 06:32:59.660418 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:32:59.660446 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:32:59.660454 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:32:59.660462 13601 net.cpp:693] Ignoring source layer data
I1007 06:32:59.660521 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:32:59.660531 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:32:59.660539 13601 net.cpp:693] Ignoring source layer silence
I1007 06:32:59.660547 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:32:59.660554 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:32:59.660563 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:32:59.660571 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:32:59.660578 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:32:59.660586 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:32:59.660595 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:32:59.660604 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:33:02.092550 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:33:04.689155 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:33:07.259510 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57224
I1007 06:33:07.406913 13601 solver.cpp:231] Iteration 10000, loss = 0.00186516
I1007 06:33:07.406960 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:33:07.406967 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0018651 (* 1 = 0.0018651 loss)
I1007 06:33:07.406981 13601 sgd_solver.cpp:106] Iteration 10000, lr = 0.00016556
I1007 06:33:08.485688 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:36:43.242879 13601 solver.cpp:340] Iteration 10500, Testing net (#0)
I1007 06:36:43.243136 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:36:43.243182 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:36:43.243192 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:36:43.243199 13601 net.cpp:693] Ignoring source layer data
I1007 06:36:43.243259 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:36:43.243269 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:36:43.243278 13601 net.cpp:693] Ignoring source layer silence
I1007 06:36:43.243285 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:36:43.243294 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:36:43.243302 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:36:43.243310 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:36:43.243317 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:36:43.243325 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:36:43.243337 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:36:43.243345 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:36:44.772737 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:36:47.292167 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:36:49.780869 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:36:50.536594 13601 solver.cpp:407]     Test net output #0: accuracy = 0.577565
I1007 06:36:50.683720 13601 solver.cpp:231] Iteration 10500, loss = 0.0131004
I1007 06:36:50.683765 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:36:50.683773 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0131004 (* 1 = 0.0131004 loss)
I1007 06:36:50.683781 13601 sgd_solver.cpp:106] Iteration 10500, lr = 0.000160131
I1007 06:40:21.953197 13601 solver.cpp:340] Iteration 11000, Testing net (#0)
I1007 06:40:21.953513 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:40:21.953542 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:40:21.953552 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:40:21.953559 13601 net.cpp:693] Ignoring source layer data
I1007 06:40:21.953830 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:40:21.953841 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:40:21.953850 13601 net.cpp:693] Ignoring source layer silence
I1007 06:40:21.953857 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:40:21.953864 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:40:21.953873 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:40:21.953881 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:40:21.953888 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:40:21.953897 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:40:21.953907 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:40:21.953913 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:40:22.661015 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:40:25.207331 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:40:27.587462 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:40:29.039764 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57934
I1007 06:40:29.187152 13601 solver.cpp:231] Iteration 11000, loss = 0.00152444
I1007 06:40:29.187211 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:40:29.187219 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00152437 (* 1 = 0.00152437 loss)
I1007 06:40:29.187229 13601 sgd_solver.cpp:106] Iteration 11000, lr = 0.000155101
I1007 06:43:12.138960 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:44:06.197098 13601 solver.cpp:340] Iteration 11500, Testing net (#0)
I1007 06:44:06.197286 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:44:06.197294 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:44:06.197299 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:44:06.197304 13601 net.cpp:693] Ignoring source layer data
I1007 06:44:06.197471 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:44:06.197477 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:44:06.197484 13601 net.cpp:693] Ignoring source layer silence
I1007 06:44:06.197487 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:44:06.197491 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:44:06.197495 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:44:06.197499 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:44:06.197504 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:44:06.197510 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:44:06.197512 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:44:06.197516 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:44:08.608229 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:44:10.988294 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:44:13.182008 13601 solver.cpp:407]     Test net output #0: accuracy = 0.580405
I1007 06:44:13.343262 13601 solver.cpp:231] Iteration 11500, loss = 0.000343631
I1007 06:44:13.343338 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:44:13.343353 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000343563 (* 1 = 0.000343563 loss)
I1007 06:44:13.343365 13601 sgd_solver.cpp:106] Iteration 11500, lr = 0.000150424
I1007 06:44:47.469919 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:48:06.560922 13601 solver.cpp:340] Iteration 12000, Testing net (#0)
I1007 06:48:06.561161 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:48:06.561184 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:48:06.561193 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:48:06.561200 13601 net.cpp:693] Ignoring source layer data
I1007 06:48:06.561254 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:48:06.561261 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:48:06.561269 13601 net.cpp:693] Ignoring source layer silence
I1007 06:48:06.561288 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:48:06.561297 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:48:06.561305 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:48:06.561313 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:48:06.561321 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:48:06.561331 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:48:06.561338 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:48:06.561345 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:48:08.283821 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:48:10.741247 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:48:13.119977 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:48:13.672351 13601 solver.cpp:407]     Test net output #0: accuracy = 0.578985
I1007 06:48:13.823845 13601 solver.cpp:231] Iteration 12000, loss = 0.000250103
I1007 06:48:13.823873 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:48:13.823881 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000250032 (* 1 = 0.000250032 loss)
I1007 06:48:13.823890 13601 sgd_solver.cpp:106] Iteration 12000, lr = 0.000146064
I1007 06:52:03.689705 13601 solver.cpp:340] Iteration 12500, Testing net (#0)
I1007 06:52:03.689966 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:52:03.689993 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:52:03.690002 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:52:03.690011 13601 net.cpp:693] Ignoring source layer data
I1007 06:52:03.690353 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:52:03.690367 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:52:03.690374 13601 net.cpp:693] Ignoring source layer silence
I1007 06:52:03.690382 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:52:03.690392 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:52:03.690399 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:52:03.690407 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:52:03.690414 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:52:03.690424 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:52:03.690433 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:52:03.690439 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:52:04.516808 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:52:06.981305 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:52:09.363250 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:52:10.645452 13601 solver.cpp:407]     Test net output #0: accuracy = 0.576855
I1007 06:52:10.794268 13601 solver.cpp:231] Iteration 12500, loss = 0.000297215
I1007 06:52:10.794323 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:52:10.794332 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000297143 (* 1 = 0.000297143 loss)
I1007 06:52:10.794345 13601 sgd_solver.cpp:106] Iteration 12500, lr = 0.000141987
I1007 06:55:44.485321 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:56:02.790402 13601 solver.cpp:340] Iteration 13000, Testing net (#0)
I1007 06:56:02.790475 13601 net.cpp:693] Ignoring source layer source_data
I1007 06:56:02.790482 13601 net.cpp:693] Ignoring source layer target_data
I1007 06:56:02.790486 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 06:56:02.790491 13601 net.cpp:693] Ignoring source layer data
I1007 06:56:02.790643 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 06:56:02.790648 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 06:56:02.790653 13601 net.cpp:693] Ignoring source layer silence
I1007 06:56:02.790658 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 06:56:02.790663 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 06:56:02.790666 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 06:56:02.790673 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 06:56:02.790678 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 06:56:02.790681 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 06:56:02.790685 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 06:56:02.790690 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 06:56:05.484395 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:56:07.952500 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 06:56:10.141149 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57863
I1007 06:56:10.291860 13601 solver.cpp:231] Iteration 13000, loss = 0.000428704
I1007 06:56:10.291916 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 06:56:10.291925 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000428635 (* 1 = 0.000428635 loss)
I1007 06:56:10.291939 13601 sgd_solver.cpp:106] Iteration 13000, lr = 0.000138167
I1007 06:57:21.464464 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:00:09.566269 13601 solver.cpp:340] Iteration 13500, Testing net (#0)
I1007 07:00:09.566500 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:00:09.566524 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:00:09.566534 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:00:09.566543 13601 net.cpp:693] Ignoring source layer data
I1007 07:00:09.566601 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:00:09.566609 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:00:09.566617 13601 net.cpp:693] Ignoring source layer silence
I1007 07:00:09.566627 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:00:09.566633 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:00:09.566642 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:00:09.566649 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:00:09.566658 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:00:09.566666 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:00:09.566674 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:00:09.566681 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:00:11.537134 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:00:14.127475 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:00:16.652870 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:00:17.154656 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58431
I1007 07:00:17.301221 13601 solver.cpp:231] Iteration 13500, loss = 9.99417e-05
I1007 07:00:17.301270 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:00:17.301276 13601 solver.cpp:247]     Train net output #1: softmax_loss = 9.98672e-05 (* 1 = 9.98672e-05 loss)
I1007 07:00:17.301290 13601 sgd_solver.cpp:106] Iteration 13500, lr = 0.000134578
I1007 07:04:08.402052 13601 solver.cpp:340] Iteration 14000, Testing net (#0)
I1007 07:04:08.402323 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:04:08.402333 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:04:08.402336 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:04:08.402341 13601 net.cpp:693] Ignoring source layer data
I1007 07:04:08.402377 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:04:08.402381 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:04:08.402386 13601 net.cpp:693] Ignoring source layer silence
I1007 07:04:08.402390 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:04:08.402395 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:04:08.402398 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:04:08.402402 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:04:08.402407 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:04:08.402411 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:04:08.402415 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:04:08.402420 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:04:09.612124 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:04:11.988945 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:04:14.351891 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:04:15.472918 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58289
I1007 07:04:15.625392 13601 solver.cpp:231] Iteration 14000, loss = 0.00134089
I1007 07:04:15.625452 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:04:15.625460 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0013408 (* 1 = 0.0013408 loss)
I1007 07:04:15.625475 13601 sgd_solver.cpp:106] Iteration 14000, lr = 0.000131199
I1007 07:08:09.491925 13601 solver.cpp:340] Iteration 14500, Testing net (#0)
I1007 07:08:09.492132 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:08:09.492141 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:08:09.492146 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:08:09.492151 13601 net.cpp:693] Ignoring source layer data
I1007 07:08:09.492183 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:08:09.492188 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:08:09.492192 13601 net.cpp:693] Ignoring source layer silence
I1007 07:08:09.492197 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:08:09.492202 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:08:09.492205 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:08:09.492210 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:08:09.492215 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:08:09.492220 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:08:09.492224 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:08:09.492228 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:08:09.688832 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:08:12.364692 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:08:14.837837 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:08:16.759163 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57934
I1007 07:08:16.912979 13601 solver.cpp:231] Iteration 14500, loss = 0.000427332
I1007 07:08:16.913044 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:08:16.913054 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000427246 (* 1 = 0.000427246 loss)
I1007 07:08:16.913065 13601 sgd_solver.cpp:106] Iteration 14500, lr = 0.000128012
I1007 07:09:59.126682 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:12:12.370256 13601 solver.cpp:340] Iteration 15000, Testing net (#0)
I1007 07:12:12.370519 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:12:12.370544 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:12:12.370555 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:12:12.370563 13601 net.cpp:693] Ignoring source layer data
I1007 07:12:12.370620 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:12:12.370628 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:12:12.370637 13601 net.cpp:693] Ignoring source layer silence
I1007 07:12:12.370645 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:12:12.370652 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:12:12.370661 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:12:12.370669 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:12:12.370677 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:12:12.370685 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:12:12.370692 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:12:12.370702 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:12:14.536645 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:12:17.218850 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:12:20.417798 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:12:20.701457 13601 solver.cpp:407]     Test net output #0: accuracy = 0.581115
I1007 07:12:20.855208 13601 solver.cpp:231] Iteration 15000, loss = 0.000385886
I1007 07:12:20.855271 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:12:20.855281 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000385801 (* 1 = 0.000385801 loss)
I1007 07:12:20.855298 13601 sgd_solver.cpp:106] Iteration 15000, lr = 0.000125
I1007 07:16:17.781471 13601 solver.cpp:340] Iteration 15500, Testing net (#0)
I1007 07:16:17.781751 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:16:17.781776 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:16:17.781786 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:16:17.781795 13601 net.cpp:693] Ignoring source layer data
I1007 07:16:17.781853 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:16:17.781862 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:16:17.781872 13601 net.cpp:693] Ignoring source layer silence
I1007 07:16:17.781878 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:16:17.781886 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:16:17.781893 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:16:17.781903 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:16:17.781910 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:16:17.781922 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:16:17.781934 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:16:17.781945 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:16:19.069263 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:16:22.306439 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:16:25.601575 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:16:26.722180 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57721
I1007 07:16:26.874657 13601 solver.cpp:231] Iteration 15500, loss = 0.00323395
I1007 07:16:26.874716 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:16:26.874725 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00323386 (* 1 = 0.00323386 loss)
I1007 07:16:26.874740 13601 sgd_solver.cpp:106] Iteration 15500, lr = 0.000122148
I1007 07:20:21.357961 13601 solver.cpp:340] Iteration 16000, Testing net (#0)
I1007 07:20:21.358250 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:20:21.358275 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:20:21.358286 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:20:21.358294 13601 net.cpp:693] Ignoring source layer data
I1007 07:20:21.358353 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:20:21.358362 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:20:21.358371 13601 net.cpp:693] Ignoring source layer silence
I1007 07:20:21.358379 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:20:21.358386 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:20:21.358394 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:20:21.358403 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:20:21.358412 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:20:21.358419 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:20:21.358428 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:20:21.358436 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:20:21.792215 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:20:24.364063 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:20:26.776569 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:20:28.467211 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57792
I1007 07:20:28.614341 13601 solver.cpp:231] Iteration 16000, loss = 0.000218808
I1007 07:20:28.614390 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:20:28.614398 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000218724 (* 1 = 0.000218724 loss)
I1007 07:20:28.614410 13601 sgd_solver.cpp:106] Iteration 16000, lr = 0.000119444
I1007 07:22:38.129990 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:24:19.193943 13601 solver.cpp:340] Iteration 16500, Testing net (#0)
I1007 07:24:19.194160 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:24:19.194190 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:24:19.194197 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:24:19.194205 13601 net.cpp:693] Ignoring source layer data
I1007 07:24:19.194300 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:24:19.194314 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:24:19.194321 13601 net.cpp:693] Ignoring source layer silence
I1007 07:24:19.194329 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:24:19.194336 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:24:19.194346 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:24:19.194353 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:24:19.194361 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:24:19.194370 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:24:19.194378 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:24:19.194386 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:24:21.480360 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:24:23.869385 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:24:26.343626 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:24:26.400084 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57863
I1007 07:24:26.554837 13601 solver.cpp:231] Iteration 16500, loss = 0.000230533
I1007 07:24:26.554903 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:24:26.554915 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000230442 (* 1 = 0.000230442 loss)
I1007 07:24:26.554932 13601 sgd_solver.cpp:106] Iteration 16500, lr = 0.000116875
I1007 07:28:21.453313 13601 solver.cpp:340] Iteration 17000, Testing net (#0)
I1007 07:28:21.453609 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:28:21.453636 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:28:21.453645 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:28:21.453652 13601 net.cpp:693] Ignoring source layer data
I1007 07:28:21.453707 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:28:21.453718 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:28:21.453727 13601 net.cpp:693] Ignoring source layer silence
I1007 07:28:21.453733 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:28:21.453742 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:28:21.453750 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:28:21.453758 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:28:21.453765 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:28:21.453773 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:28:21.453783 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:28:21.453790 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:28:22.956995 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:28:25.471834 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:28:28.163571 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:28:29.059720 13601 solver.cpp:407]     Test net output #0: accuracy = 0.575435
I1007 07:28:29.214565 13601 solver.cpp:231] Iteration 17000, loss = 0.000144905
I1007 07:28:29.214628 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:28:29.214640 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000144819 (* 1 = 0.000144819 loss)
I1007 07:28:29.214658 13601 sgd_solver.cpp:106] Iteration 17000, lr = 0.000114432
I1007 07:32:19.224730 13601 solver.cpp:340] Iteration 17500, Testing net (#0)
I1007 07:32:19.224982 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:32:19.225008 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:32:19.225016 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:32:19.225024 13601 net.cpp:693] Ignoring source layer data
I1007 07:32:19.225085 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:32:19.225095 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:32:19.225103 13601 net.cpp:693] Ignoring source layer silence
I1007 07:32:19.225111 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:32:19.225118 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:32:19.225127 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:32:19.225136 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:32:19.225142 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:32:19.225150 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:32:19.225159 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:32:19.225167 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:32:19.889391 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:32:22.543246 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:32:25.101861 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:32:26.709280 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57863
I1007 07:32:26.866611 13601 solver.cpp:231] Iteration 17500, loss = 0.000103228
I1007 07:32:26.866683 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:32:26.866694 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000103141 (* 1 = 0.000103141 loss)
I1007 07:32:26.866706 13601 sgd_solver.cpp:106] Iteration 17500, lr = 0.000112104
I1007 07:35:11.798714 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:36:16.426707 13601 solver.cpp:340] Iteration 18000, Testing net (#0)
I1007 07:36:16.427016 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:36:16.427043 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:36:16.427053 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:36:16.427062 13601 net.cpp:693] Ignoring source layer data
I1007 07:36:16.427351 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:36:16.427364 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:36:16.427371 13601 net.cpp:693] Ignoring source layer silence
I1007 07:36:16.427379 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:36:16.427388 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:36:16.427397 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:36:16.427403 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:36:16.427412 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:36:16.427422 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:36:16.427428 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:36:16.427436 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:36:18.835198 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:36:21.224001 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:36:23.484601 13601 solver.cpp:407]     Test net output #0: accuracy = 0.5836
I1007 07:36:23.640035 13601 solver.cpp:231] Iteration 18000, loss = 0.00130625
I1007 07:36:23.640090 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:36:23.640101 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00130617 (* 1 = 0.00130617 loss)
I1007 07:36:23.640112 13601 sgd_solver.cpp:106] Iteration 18000, lr = 0.000109884
I1007 07:36:46.892731 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:40:17.318228 13601 solver.cpp:340] Iteration 18500, Testing net (#0)
I1007 07:40:17.318462 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:40:17.318487 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:40:17.318496 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:40:17.318505 13601 net.cpp:693] Ignoring source layer data
I1007 07:40:17.318562 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:40:17.318570 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:40:17.318578 13601 net.cpp:693] Ignoring source layer silence
I1007 07:40:17.318585 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:40:17.318594 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:40:17.318603 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:40:17.318609 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:40:17.318617 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:40:17.318626 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:40:17.318634 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:40:17.318642 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:40:19.019232 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:40:21.593746 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:40:23.971369 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:40:24.589359 13601 solver.cpp:407]     Test net output #0: accuracy = 0.581115
I1007 07:40:24.742897 13601 solver.cpp:231] Iteration 18500, loss = 0.000546639
I1007 07:40:24.742947 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:40:24.742957 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000546552 (* 1 = 0.000546552 loss)
I1007 07:40:24.742967 13601 sgd_solver.cpp:106] Iteration 18500, lr = 0.000107764
I1007 07:44:19.429080 13601 solver.cpp:340] Iteration 19000, Testing net (#0)
I1007 07:44:19.429383 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:44:19.429409 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:44:19.429419 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:44:19.429426 13601 net.cpp:693] Ignoring source layer data
I1007 07:44:19.429455 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:44:19.429463 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:44:19.429471 13601 net.cpp:693] Ignoring source layer silence
I1007 07:44:19.429478 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:44:19.429487 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:44:19.429496 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:44:19.429503 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:44:19.429510 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:44:19.429520 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:44:19.429528 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:44:19.429535 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:44:20.308655 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:44:22.759824 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:44:25.144368 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:44:26.502938 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57863
I1007 07:44:26.664706 13601 solver.cpp:231] Iteration 19000, loss = 0.0018884
I1007 07:44:26.664762 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:44:26.664774 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00188831 (* 1 = 0.00188831 loss)
I1007 07:44:26.664786 13601 sgd_solver.cpp:106] Iteration 19000, lr = 0.000105737
I1007 07:47:49.789752 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:48:22.642213 13601 solver.cpp:340] Iteration 19500, Testing net (#0)
I1007 07:48:22.642415 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:48:22.642438 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:48:22.642447 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:48:22.642457 13601 net.cpp:693] Ignoring source layer data
I1007 07:48:22.642482 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:48:22.642490 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:48:22.642498 13601 net.cpp:693] Ignoring source layer silence
I1007 07:48:22.642508 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:48:22.642515 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:48:22.642523 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:48:22.642530 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:48:22.642539 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:48:22.642547 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:48:22.642555 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:48:22.642562 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:48:25.279404 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:48:28.753340 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:48:31.176623 13601 solver.cpp:407]     Test net output #0: accuracy = 0.580405
I1007 07:48:31.323592 13601 solver.cpp:231] Iteration 19500, loss = 0.00260759
I1007 07:48:31.323644 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:48:31.323652 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.0026075 (* 1 = 0.0026075 loss)
I1007 07:48:31.323660 13601 sgd_solver.cpp:106] Iteration 19500, lr = 0.000103797
I1007 07:49:26.805979 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:52:24.910595 13601 solver.cpp:340] Iteration 20000, Testing net (#0)
I1007 07:52:24.910768 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:52:24.910778 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:52:24.910782 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:52:24.910787 13601 net.cpp:693] Ignoring source layer data
I1007 07:52:24.910805 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:52:24.910810 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:52:24.910815 13601 net.cpp:693] Ignoring source layer silence
I1007 07:52:24.910820 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:52:24.910823 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:52:24.910827 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:52:24.910832 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:52:24.910837 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:52:24.910842 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:52:24.910846 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:52:24.910851 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:52:26.706693 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:52:29.085731 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:52:31.445273 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:52:31.892395 13601 solver.cpp:407]     Test net output #0: accuracy = 0.580405
I1007 07:52:32.043267 13601 solver.cpp:231] Iteration 20000, loss = 8.86751e-05
I1007 07:52:32.043316 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:52:32.043325 13601 solver.cpp:247]     Train net output #1: softmax_loss = 8.85931e-05 (* 1 = 8.85931e-05 loss)
I1007 07:52:32.043334 13601 sgd_solver.cpp:106] Iteration 20000, lr = 0.000101938
I1007 07:56:21.303160 13601 solver.cpp:340] Iteration 20500, Testing net (#0)
I1007 07:56:21.303375 13601 net.cpp:693] Ignoring source layer source_data
I1007 07:56:21.303400 13601 net.cpp:693] Ignoring source layer target_data
I1007 07:56:21.303408 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 07:56:21.303418 13601 net.cpp:693] Ignoring source layer data
I1007 07:56:21.303443 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 07:56:21.303452 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 07:56:21.303459 13601 net.cpp:693] Ignoring source layer silence
I1007 07:56:21.303468 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 07:56:21.303477 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 07:56:21.303484 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 07:56:21.303491 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 07:56:21.303500 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 07:56:21.303508 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 07:56:21.303516 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 07:56:21.303524 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 07:56:22.337704 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:56:24.728355 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:56:27.098474 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 07:56:28.284281 13601 solver.cpp:407]     Test net output #0: accuracy = 0.581825
I1007 07:56:28.431236 13601 solver.cpp:231] Iteration 20500, loss = 0.000199227
I1007 07:56:28.431288 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 07:56:28.431296 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000199141 (* 1 = 0.000199141 loss)
I1007 07:56:28.431304 13601 sgd_solver.cpp:106] Iteration 20500, lr = 0.000100155
I1007 08:00:19.328899 13601 solver.cpp:340] Iteration 21000, Testing net (#0)
I1007 08:00:19.329180 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:00:19.329205 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:00:19.329213 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:00:19.329223 13601 net.cpp:693] Ignoring source layer data
I1007 08:00:19.329253 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:00:19.329265 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:00:19.329273 13601 net.cpp:693] Ignoring source layer silence
I1007 08:00:19.329283 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:00:19.329291 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:00:19.329299 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:00:19.329306 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:00:19.329316 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:00:19.329324 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:00:19.329332 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:00:19.329340 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:00:19.395977 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:00:22.077123 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:00:24.451077 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:00:26.361917 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58431
I1007 08:00:26.519230 13601 solver.cpp:231] Iteration 21000, loss = 0.000316735
I1007 08:00:26.519291 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:00:26.519304 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000316651 (* 1 = 0.000316651 loss)
I1007 08:00:26.519320 13601 sgd_solver.cpp:106] Iteration 21000, lr = 9.84426e-05
I1007 08:01:57.843542 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:04:25.611909 13601 solver.cpp:340] Iteration 21500, Testing net (#0)
I1007 08:04:25.612116 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:04:25.612140 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:04:25.612150 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:04:25.612159 13601 net.cpp:693] Ignoring source layer data
I1007 08:04:25.612184 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:04:25.612191 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:04:25.612200 13601 net.cpp:693] Ignoring source layer silence
I1007 08:04:25.612208 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:04:25.612215 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:04:25.612223 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:04:25.612232 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:04:25.612241 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:04:25.612248 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:04:25.612256 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:04:25.612264 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:04:27.631335 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:04:30.125581 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:04:32.483440 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:04:32.754223 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58218
I1007 08:04:32.901568 13601 solver.cpp:231] Iteration 21500, loss = 0.000204163
I1007 08:04:32.901619 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:04:32.901626 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000204078 (* 1 = 0.000204078 loss)
I1007 08:04:32.901638 13601 sgd_solver.cpp:106] Iteration 21500, lr = 9.67973e-05
I1007 08:08:33.148327 13601 solver.cpp:340] Iteration 22000, Testing net (#0)
I1007 08:08:33.148634 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:08:33.148658 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:08:33.148668 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:08:33.148675 13601 net.cpp:693] Ignoring source layer data
I1007 08:08:33.148699 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:08:33.148707 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:08:33.148716 13601 net.cpp:693] Ignoring source layer silence
I1007 08:08:33.148725 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:08:33.148731 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:08:33.148739 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:08:33.148748 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:08:33.148756 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:08:33.148764 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:08:33.148772 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:08:33.148782 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:08:34.380112 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:08:36.766731 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:08:39.138635 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:08:40.147788 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58431
I1007 08:08:40.303531 13601 solver.cpp:231] Iteration 22000, loss = 0.000214207
I1007 08:08:40.303591 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:08:40.303602 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000214116 (* 1 = 0.000214116 loss)
I1007 08:08:40.303613 13601 sgd_solver.cpp:106] Iteration 22000, lr = 9.52147e-05
I1007 08:12:38.487352 13601 solver.cpp:340] Iteration 22500, Testing net (#0)
I1007 08:12:38.487579 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:12:38.487604 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:12:38.487615 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:12:38.487622 13601 net.cpp:693] Ignoring source layer data
I1007 08:12:38.487646 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:12:38.487654 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:12:38.487664 13601 net.cpp:693] Ignoring source layer silence
I1007 08:12:38.487671 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:12:38.487679 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:12:38.487687 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:12:38.487696 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:12:38.487704 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:12:38.487711 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:12:38.487720 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:12:38.487728 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:12:38.836482 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:12:41.382045 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:12:43.743172 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:12:45.466418 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57934
I1007 08:12:45.618674 13601 solver.cpp:231] Iteration 22500, loss = 6.69206e-05
I1007 08:12:45.618731 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:12:45.618741 13601 solver.cpp:247]     Train net output #1: softmax_loss = 6.68307e-05 (* 1 = 6.68307e-05 loss)
I1007 08:12:45.618752 13601 sgd_solver.cpp:106] Iteration 22500, lr = 9.36913e-05
I1007 08:14:48.316367 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:16:36.899400 13601 solver.cpp:340] Iteration 23000, Testing net (#0)
I1007 08:16:36.899629 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:16:36.899662 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:16:36.899670 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:16:36.899678 13601 net.cpp:693] Ignoring source layer data
I1007 08:16:36.899701 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:16:36.899711 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:16:36.899718 13601 net.cpp:693] Ignoring source layer silence
I1007 08:16:36.899726 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:16:36.899734 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:16:36.899744 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:16:36.899750 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:16:36.899758 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:16:36.899766 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:16:36.899775 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:16:36.899782 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:16:39.038609 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:16:41.540935 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:16:43.907016 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:16:44.014438 13601 solver.cpp:407]     Test net output #0: accuracy = 0.57934
I1007 08:16:44.161285 13601 solver.cpp:231] Iteration 23000, loss = 5.26711e-05
I1007 08:16:44.161334 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:16:44.161341 13601 solver.cpp:247]     Train net output #1: softmax_loss = 5.25821e-05 (* 1 = 5.25821e-05 loss)
I1007 08:16:44.161350 13601 sgd_solver.cpp:106] Iteration 23000, lr = 9.22235e-05
I1007 08:20:39.866966 13601 solver.cpp:340] Iteration 23500, Testing net (#0)
I1007 08:20:39.867215 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:20:39.867241 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:20:39.867249 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:20:39.867257 13601 net.cpp:693] Ignoring source layer data
I1007 08:20:39.867285 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:20:39.867295 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:20:39.867301 13601 net.cpp:693] Ignoring source layer silence
I1007 08:20:39.867311 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:20:39.867319 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:20:39.867328 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:20:39.867336 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:20:39.867343 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:20:39.867352 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:20:39.867360 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:20:39.867368 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:20:41.290236 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:20:43.960589 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:20:46.351783 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:20:47.194919 13601 solver.cpp:407]     Test net output #0: accuracy = 0.581825
I1007 08:20:47.348384 13601 solver.cpp:231] Iteration 23500, loss = 0.000733639
I1007 08:20:47.348440 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:20:47.348453 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000733549 (* 1 = 0.000733549 loss)
I1007 08:20:47.348465 13601 sgd_solver.cpp:106] Iteration 23500, lr = 9.08083e-05
I1007 08:24:41.602947 13601 solver.cpp:340] Iteration 24000, Testing net (#0)
I1007 08:24:41.603298 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:24:41.603320 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:24:41.603329 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:24:41.603337 13601 net.cpp:693] Ignoring source layer data
I1007 08:24:41.603363 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:24:41.603371 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:24:41.603379 13601 net.cpp:693] Ignoring source layer silence
I1007 08:24:41.603387 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:24:41.603394 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:24:41.603404 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:24:41.603411 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:24:41.603420 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:24:41.603427 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:24:41.603436 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:24:41.603444 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:24:42.182570 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:24:44.850602 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:24:47.587215 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:24:49.306491 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58218
I1007 08:24:49.456434 13601 solver.cpp:231] Iteration 24000, loss = 0.000185955
I1007 08:24:49.456488 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:24:49.456497 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000185865 (* 1 = 0.000185865 loss)
I1007 08:24:49.456507 13601 sgd_solver.cpp:106] Iteration 24000, lr = 8.94427e-05
I1007 08:27:24.005388 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:28:45.434062 13601 solver.cpp:340] Iteration 24500, Testing net (#0)
I1007 08:28:45.434270 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:28:45.434294 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:28:45.434303 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:28:45.434311 13601 net.cpp:693] Ignoring source layer data
I1007 08:28:45.434335 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:28:45.434343 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:28:45.434351 13601 net.cpp:693] Ignoring source layer silence
I1007 08:28:45.434358 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:28:45.434367 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:28:45.434376 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:28:45.434383 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:28:45.434391 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:28:45.434401 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:28:45.434407 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:28:45.434415 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:28:47.728507 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:28:50.108885 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:28:52.417707 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58218
I1007 08:28:52.564652 13601 solver.cpp:231] Iteration 24500, loss = 0.000365134
I1007 08:28:52.564721 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:28:52.564729 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000365043 (* 1 = 0.000365043 loss)
I1007 08:28:52.564755 13601 sgd_solver.cpp:106] Iteration 24500, lr = 8.81241e-05
I1007 08:29:03.006419 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:32:47.249518 13601 solver.cpp:340] Iteration 25000, Testing net (#0)
I1007 08:32:47.249781 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:32:47.249805 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:32:47.249814 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:32:47.249822 13601 net.cpp:693] Ignoring source layer data
I1007 08:32:47.249850 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:32:47.249857 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:32:47.249866 13601 net.cpp:693] Ignoring source layer silence
I1007 08:32:47.249872 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:32:47.249881 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:32:47.249889 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:32:47.249897 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:32:47.249905 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:32:47.249914 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:32:47.249922 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:32:47.249929 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:32:48.858052 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:32:51.276892 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:32:53.639340 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:32:54.306401 13601 solver.cpp:407]     Test net output #0: accuracy = 0.586794
I1007 08:32:54.458109 13601 solver.cpp:231] Iteration 25000, loss = 0.000197663
I1007 08:32:54.458166 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:32:54.458175 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000197575 (* 1 = 0.000197575 loss)
I1007 08:32:54.458186 13601 sgd_solver.cpp:106] Iteration 25000, lr = 8.685e-05
I1007 08:36:54.047303 13601 solver.cpp:340] Iteration 25500, Testing net (#0)
I1007 08:36:54.047521 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:36:54.047544 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:36:54.047554 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:36:54.047561 13601 net.cpp:693] Ignoring source layer data
I1007 08:36:54.047588 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:36:54.047600 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:36:54.047607 13601 net.cpp:693] Ignoring source layer silence
I1007 08:36:54.047614 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:36:54.047623 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:36:54.047631 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:36:54.047641 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:36:54.047649 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:36:54.047659 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:36:54.047667 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:36:54.047674 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:36:54.854979 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:36:57.385274 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:37:00.829296 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:37:02.771951 13601 solver.cpp:407]     Test net output #0: accuracy = 0.584665
I1007 08:37:02.918838 13601 solver.cpp:231] Iteration 25500, loss = 0.00861864
I1007 08:37:02.918889 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:37:02.918896 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.00861855 (* 1 = 0.00861855 loss)
I1007 08:37:02.918906 13601 sgd_solver.cpp:106] Iteration 25500, lr = 8.56181e-05
I1007 08:40:12.140213 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:40:55.574331 13601 solver.cpp:340] Iteration 26000, Testing net (#0)
I1007 08:40:55.574555 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:40:55.574580 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:40:55.574589 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:40:55.574599 13601 net.cpp:693] Ignoring source layer data
I1007 08:40:55.574625 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:40:55.574633 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:40:55.574641 13601 net.cpp:693] Ignoring source layer silence
I1007 08:40:55.574651 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:40:55.574658 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:40:55.574666 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:40:55.574673 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:40:55.574682 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:40:55.574690 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:40:55.574698 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:40:55.574707 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:40:58.090714 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:41:00.456609 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:41:02.906635 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58502
I1007 08:41:03.053567 13601 solver.cpp:231] Iteration 26000, loss = 0.000117584
I1007 08:41:03.053614 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:41:03.053622 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000117486 (* 1 = 0.000117486 loss)
I1007 08:41:03.053632 13601 sgd_solver.cpp:106] Iteration 26000, lr = 8.44262e-05
I1007 08:41:50.099756 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:44:59.288282 13601 solver.cpp:340] Iteration 26500, Testing net (#0)
I1007 08:44:59.288493 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:44:59.288517 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:44:59.288527 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:44:59.288537 13601 net.cpp:693] Ignoring source layer data
I1007 08:44:59.288563 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:44:59.288570 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:44:59.288578 13601 net.cpp:693] Ignoring source layer silence
I1007 08:44:59.288588 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:44:59.288595 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:44:59.288604 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:44:59.288611 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:44:59.288620 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:44:59.288628 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:44:59.288636 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:44:59.288643 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:45:01.401980 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:45:03.824172 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:45:06.750303 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:45:07.464638 13601 solver.cpp:407]     Test net output #0: accuracy = 0.584665
I1007 08:45:07.611508 13601 solver.cpp:231] Iteration 26500, loss = 0.000187819
I1007 08:45:07.611557 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:45:07.611564 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000187721 (* 1 = 0.000187721 loss)
I1007 08:45:07.611574 13601 sgd_solver.cpp:106] Iteration 26500, lr = 8.32723e-05
I1007 08:49:01.133394 13601 solver.cpp:340] Iteration 27000, Testing net (#0)
I1007 08:49:01.133662 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:49:01.133690 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:49:01.133698 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:49:01.133708 13601 net.cpp:693] Ignoring source layer data
I1007 08:49:01.133734 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:49:01.133743 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:49:01.133750 13601 net.cpp:693] Ignoring source layer silence
I1007 08:49:01.133759 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:49:01.133767 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:49:01.133774 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:49:01.133782 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:49:01.133792 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:49:01.133800 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:49:01.133807 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:49:01.133816 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:49:02.201637 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:49:04.651710 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:49:07.082950 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:49:08.357513 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58147
I1007 08:49:08.507822 13601 solver.cpp:231] Iteration 27000, loss = 0.000228537
I1007 08:49:08.507876 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:49:08.507884 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000228434 (* 1 = 0.000228434 loss)
I1007 08:49:08.507895 13601 sgd_solver.cpp:106] Iteration 27000, lr = 8.21545e-05
I1007 08:52:59.332129 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:53:10.517510 13601 solver.cpp:340] Iteration 27500, Testing net (#0)
I1007 08:53:10.517560 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:53:10.517565 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:53:10.517570 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:53:10.517575 13601 net.cpp:693] Ignoring source layer data
I1007 08:53:10.517590 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:53:10.517593 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:53:10.517598 13601 net.cpp:693] Ignoring source layer silence
I1007 08:53:10.517602 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:53:10.517606 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:53:10.517611 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:53:10.517616 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:53:10.517621 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:53:10.517624 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:53:10.517628 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:53:10.517632 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:53:13.252602 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:53:15.644902 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:53:17.609002 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58431
I1007 08:53:17.761101 13601 solver.cpp:231] Iteration 27500, loss = 0.000205147
I1007 08:53:17.761148 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:53:17.761158 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000205049 (* 1 = 0.000205049 loss)
I1007 08:53:17.761168 13601 sgd_solver.cpp:106] Iteration 27500, lr = 8.10712e-05
I1007 08:54:39.603492 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:57:14.342149 13601 solver.cpp:340] Iteration 28000, Testing net (#0)
I1007 08:57:14.342393 13601 net.cpp:693] Ignoring source layer source_data
I1007 08:57:14.342417 13601 net.cpp:693] Ignoring source layer target_data
I1007 08:57:14.342427 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 08:57:14.342435 13601 net.cpp:693] Ignoring source layer data
I1007 08:57:14.342461 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 08:57:14.342469 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 08:57:14.342478 13601 net.cpp:693] Ignoring source layer silence
I1007 08:57:14.342486 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 08:57:14.342494 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 08:57:14.342501 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 08:57:14.342511 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 08:57:14.342519 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 08:57:14.342526 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 08:57:14.342535 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 08:57:14.342543 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 08:57:16.257997 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:57:18.646332 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:57:21.006124 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 08:57:21.338285 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58289
I1007 08:57:21.491977 13601 solver.cpp:231] Iteration 28000, loss = 0.000212137
I1007 08:57:21.492044 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 08:57:21.492054 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000212038 (* 1 = 0.000212038 loss)
I1007 08:57:21.492065 13601 sgd_solver.cpp:106] Iteration 28000, lr = 8.00205e-05
I1007 09:01:19.329787 13601 solver.cpp:340] Iteration 28500, Testing net (#0)
I1007 09:01:19.330029 13601 net.cpp:693] Ignoring source layer source_data
I1007 09:01:19.330054 13601 net.cpp:693] Ignoring source layer target_data
I1007 09:01:19.330065 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 09:01:19.330072 13601 net.cpp:693] Ignoring source layer data
I1007 09:01:19.330099 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 09:01:19.330108 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 09:01:19.330117 13601 net.cpp:693] Ignoring source layer silence
I1007 09:01:19.330126 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 09:01:19.330132 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 09:01:19.330140 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 09:01:19.330150 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 09:01:19.330157 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 09:01:19.330165 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 09:01:19.330173 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 09:01:19.330183 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 09:01:20.503222 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:01:22.942760 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:01:25.307481 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:01:26.385025 13601 solver.cpp:407]     Test net output #0: accuracy = 0.580405
I1007 09:01:26.539459 13601 solver.cpp:231] Iteration 28500, loss = 0.000601222
I1007 09:01:26.539553 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 09:01:26.539564 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000601134 (* 1 = 0.000601134 loss)
I1007 09:01:26.539577 13601 sgd_solver.cpp:106] Iteration 28500, lr = 7.90012e-05
I1007 09:05:20.056092 13601 solver.cpp:340] Iteration 29000, Testing net (#0)
I1007 09:05:20.056373 13601 net.cpp:693] Ignoring source layer source_data
I1007 09:05:20.056394 13601 net.cpp:693] Ignoring source layer target_data
I1007 09:05:20.056404 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 09:05:20.056412 13601 net.cpp:693] Ignoring source layer data
I1007 09:05:20.056435 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 09:05:20.056443 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 09:05:20.056453 13601 net.cpp:693] Ignoring source layer silence
I1007 09:05:20.056460 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 09:05:20.056468 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 09:05:20.056476 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 09:05:20.056485 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 09:05:20.056493 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 09:05:20.056501 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 09:05:20.056509 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 09:05:20.056519 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 09:05:20.331439 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:05:22.921613 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:05:25.362912 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:05:27.208608 13601 solver.cpp:407]     Test net output #0: accuracy = 0.586794
I1007 09:05:27.358809 13601 solver.cpp:231] Iteration 29000, loss = 0.000747777
I1007 09:05:27.358862 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 09:05:27.358870 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000747688 (* 1 = 0.000747688 loss)
I1007 09:05:27.358882 13601 sgd_solver.cpp:106] Iteration 29000, lr = 7.80116e-05
I1007 09:07:16.747735 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:09:17.349135 13601 solver.cpp:340] Iteration 29500, Testing net (#0)
I1007 09:09:17.349346 13601 net.cpp:693] Ignoring source layer source_data
I1007 09:09:17.349372 13601 net.cpp:693] Ignoring source layer target_data
I1007 09:09:17.349381 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 09:09:17.349390 13601 net.cpp:693] Ignoring source layer data
I1007 09:09:17.349416 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 09:09:17.349426 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 09:09:17.349432 13601 net.cpp:693] Ignoring source layer silence
I1007 09:09:17.349440 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 09:09:17.349447 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 09:09:17.349457 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 09:09:17.349464 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 09:09:17.349472 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 09:09:17.349480 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 09:09:17.349489 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 09:09:17.349498 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 09:09:19.422003 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:09:21.806205 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:09:24.170920 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:09:24.337455 13601 solver.cpp:407]     Test net output #0: accuracy = 0.581825
I1007 09:09:24.484064 13601 solver.cpp:231] Iteration 29500, loss = 0.000112232
I1007 09:09:24.484114 13601 solver.cpp:247]     Train net output #0: jmmd_loss_jmmd_loss_0_split_0 = 0 (* 0.3 = 0 loss)
I1007 09:09:24.484122 13601 solver.cpp:247]     Train net output #1: softmax_loss = 0.000112141 (* 1 = 0.000112141 loss)
I1007 09:09:24.484133 13601 sgd_solver.cpp:106] Iteration 29500, lr = 7.70504e-05
I1007 09:13:22.662386 13601 solver.cpp:320] Iteration 30000, loss = 0.000171148
I1007 09:13:22.662672 13601 solver.cpp:340] Iteration 30000, Testing net (#0)
I1007 09:13:22.662700 13601 net.cpp:693] Ignoring source layer source_data
I1007 09:13:22.662709 13601 net.cpp:693] Ignoring source layer target_data
I1007 09:13:22.662717 13601 net.cpp:693] Ignoring source layer target_label_silence
I1007 09:13:22.662725 13601 net.cpp:693] Ignoring source layer data
I1007 09:13:22.662752 13601 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1007 09:13:22.662761 13601 net.cpp:693] Ignoring source layer slice_fc8
I1007 09:13:22.662768 13601 net.cpp:693] Ignoring source layer silence
I1007 09:13:22.662776 13601 net.cpp:693] Ignoring source layer softmax_loss
I1007 09:13:22.662786 13601 net.cpp:693] Ignoring source layer fc8_softmax
I1007 09:13:22.662793 13601 net.cpp:693] Ignoring source layer slice_softmax
I1007 09:13:22.662801 13601 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1007 09:13:22.662808 13601 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1007 09:13:22.662818 13601 net.cpp:693] Ignoring source layer jmmd_loss
I1007 09:13:22.662825 13601 net.cpp:693] Ignoring source layer jmmd_loss_jmmd_loss_0_split
I1007 09:13:22.662833 13601 net.cpp:693] Ignoring source layer silence_loss_value
I1007 09:13:24.079507 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:13:26.840863 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:13:29.734179 13601 blocking_queue.cpp:50] Data layer prefetch queue empty
I1007 09:13:30.804153 13601 solver.cpp:407]     Test net output #0: accuracy = 0.58147
I1007 09:13:30.804180 13601 solver.cpp:325] Optimization Done.
I1007 09:13:30.804186 13601 caffe.cpp:254] Optimization Done.
