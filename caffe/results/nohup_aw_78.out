nohup: ignoring input
I1008 10:24:47.049868 54999 caffe.cpp:217] Using GPUs 0
I1008 10:24:50.580963 54999 caffe.cpp:222] GPU 0: TITAN X (Pascal)
I1008 10:24:51.277536 54999 solver.cpp:49] Initializing solver from parameters: 
test_iter: 795
test_interval: 500
base_lr: 0.001
display: 500
max_iter: 30000
lr_policy: "inv"
gamma: 0.001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 60000
snapshot_prefix: "models/JAN/alexnet/trained_model"
solver_mode: GPU
device_id: 0
net: "models/JAN/alexnet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: false
I1008 10:24:51.277720 54999 solver.cpp:92] Creating training net from net file: models/JAN/alexnet/train_val.prototxt
I1008 10:24:51.278723 54999 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer test_data
I1008 10:24:51.278756 54999 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1008 10:24:51.279080 54999 net.cpp:58] Initializing net from parameters: 
name: "amazon_to_webcam"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "source_data"
  type: "ImageData"
  top: "source_data"
  top: "source_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/amazon_list.txt"
    batch_size: 64
    shuffle: true
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "target_data"
  type: "ImageData"
  top: "target_data"
  top: "target_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/webcam_list.txt"
    batch_size: 64
    shuffle: true
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "target_label_silence"
  type: "Silence"
  bottom: "target_label"
  include {
    phase: TRAIN
  }
}
layer {
  name: "data"
  type: "Concat"
  bottom: "source_data"
  bottom: "target_data"
  top: "data"
  include {
    phase: TRAIN
  }
  concat_param {
    axis: 0
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slice_fc7"
  type: "Slice"
  bottom: "fc7"
  top: "fc7_source"
  top: "fc7_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 0
  }
}
layer {
  name: "slice_fc8"
  type: "Slice"
  bottom: "fc8"
  top: "fc8_source"
  top: "fc8_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 0
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "fc8_target"
  include {
    phase: TRAIN
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_source"
  bottom: "source_label"
  top: "softmax_loss"
  include {
    phase: TRAIN
  }
}
layer {
  name: "fc8_softmax"
  type: "Softmax"
  bottom: "fc8"
  top: "fc8_softmax"
  include {
    phase: TRAIN
  }
}
layer {
  name: "slice_softmax"
  type: "Slice"
  bottom: "fc8_softmax"
  top: "source_softmax"
  top: "target_softmax"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 0
  }
}
layer {
  name: "jmmd_loss_fc7"
  type: "JMMDLoss"
  bottom: "fc7_source"
  bottom: "fc7_target"
  bottom: "source_softmax"
  bottom: "target_softmax"
  top: "jmmd_loss_fc7"
  loss_weight: 0.3
  include {
    phase: TRAIN
  }
}
layer {
  name: "jmmd_loss_softmax"
  type: "JMMDLoss"
  bottom: "source_softmax"
  bottom: "target_softmax"
  bottom: "source_softmax"
  bottom: "target_softmax"
  top: "jmmd_loss_softmax"
  loss_weight: 0.3
  include {
    phase: TRAIN
  }
}
layer {
  name: "silence_loss_value"
  type: "Silence"
  bottom: "jmmd_loss_fc7"
  bottom: "jmmd_loss_softmax"
  include {
    phase: TRAIN
  }
}
I1008 10:24:51.279381 54999 layer_factory.hpp:77] Creating layer source_data
I1008 10:24:51.279444 54999 net.cpp:100] Creating Layer source_data
I1008 10:24:51.279464 54999 net.cpp:408] source_data -> source_data
I1008 10:24:51.279495 54999 net.cpp:408] source_data -> source_label
I1008 10:24:51.279511 54999 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1008 10:24:51.310132 54999 image_data_layer.cpp:38] Opening file ./data/office/amazon_list.txt
I1008 10:24:51.311038 54999 image_data_layer.cpp:53] Shuffling data
I1008 10:24:51.311269 54999 image_data_layer.cpp:58] A total of 2817 images.
I1008 10:24:51.766633 54999 image_data_layer.cpp:85] output data size: 64,3,227,227
I1008 10:24:51.860227 54999 net.cpp:150] Setting up source_data
I1008 10:24:51.860283 54999 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1008 10:24:51.860291 54999 net.cpp:157] Top shape: 64 (64)
I1008 10:24:51.860296 54999 net.cpp:165] Memory required for data: 39574528
I1008 10:24:51.860307 54999 layer_factory.hpp:77] Creating layer target_data
I1008 10:24:51.860343 54999 net.cpp:100] Creating Layer target_data
I1008 10:24:51.860353 54999 net.cpp:408] target_data -> target_data
I1008 10:24:51.860373 54999 net.cpp:408] target_data -> target_label
I1008 10:24:51.860383 54999 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1008 10:24:51.861874 54999 image_data_layer.cpp:38] Opening file ./data/office/webcam_list.txt
I1008 10:24:51.862140 54999 image_data_layer.cpp:53] Shuffling data
I1008 10:24:51.862205 54999 image_data_layer.cpp:58] A total of 795 images.
I1008 10:24:51.868532 54999 image_data_layer.cpp:85] output data size: 64,3,227,227
I1008 10:24:51.960193 54999 net.cpp:150] Setting up target_data
I1008 10:24:51.960244 54999 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1008 10:24:51.960252 54999 net.cpp:157] Top shape: 64 (64)
I1008 10:24:51.960256 54999 net.cpp:165] Memory required for data: 79149056
I1008 10:24:51.960266 54999 layer_factory.hpp:77] Creating layer target_label_silence
I1008 10:24:51.960289 54999 net.cpp:100] Creating Layer target_label_silence
I1008 10:24:51.960299 54999 net.cpp:434] target_label_silence <- target_label
I1008 10:24:51.960319 54999 net.cpp:150] Setting up target_label_silence
I1008 10:24:51.960324 54999 net.cpp:165] Memory required for data: 79149056
I1008 10:24:51.960327 54999 layer_factory.hpp:77] Creating layer data
I1008 10:24:51.960340 54999 net.cpp:100] Creating Layer data
I1008 10:24:51.960345 54999 net.cpp:434] data <- source_data
I1008 10:24:51.960350 54999 net.cpp:434] data <- target_data
I1008 10:24:51.960358 54999 net.cpp:408] data -> data
I1008 10:24:51.960422 54999 net.cpp:150] Setting up data
I1008 10:24:51.960430 54999 net.cpp:157] Top shape: 128 3 227 227 (19787136)
I1008 10:24:51.960435 54999 net.cpp:165] Memory required for data: 158297600
I1008 10:24:51.960440 54999 layer_factory.hpp:77] Creating layer conv1
I1008 10:24:51.960464 54999 net.cpp:100] Creating Layer conv1
I1008 10:24:51.960469 54999 net.cpp:434] conv1 <- data
I1008 10:24:51.960476 54999 net.cpp:408] conv1 -> conv1
I1008 10:24:51.964928 54999 net.cpp:150] Setting up conv1
I1008 10:24:51.964948 54999 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I1008 10:24:51.964953 54999 net.cpp:165] Memory required for data: 306982400
I1008 10:24:51.964970 54999 layer_factory.hpp:77] Creating layer relu1
I1008 10:24:51.964982 54999 net.cpp:100] Creating Layer relu1
I1008 10:24:51.964987 54999 net.cpp:434] relu1 <- conv1
I1008 10:24:51.964994 54999 net.cpp:395] relu1 -> conv1 (in-place)
I1008 10:24:51.965004 54999 net.cpp:150] Setting up relu1
I1008 10:24:51.965011 54999 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I1008 10:24:51.965014 54999 net.cpp:165] Memory required for data: 455667200
I1008 10:24:51.965019 54999 layer_factory.hpp:77] Creating layer pool1
I1008 10:24:51.965030 54999 net.cpp:100] Creating Layer pool1
I1008 10:24:51.965034 54999 net.cpp:434] pool1 <- conv1
I1008 10:24:51.965041 54999 net.cpp:408] pool1 -> pool1
I1008 10:24:51.965224 54999 net.cpp:150] Setting up pool1
I1008 10:24:51.965314 54999 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I1008 10:24:51.965355 54999 net.cpp:165] Memory required for data: 491499008
I1008 10:24:51.965369 54999 layer_factory.hpp:77] Creating layer norm1
I1008 10:24:51.965394 54999 net.cpp:100] Creating Layer norm1
I1008 10:24:51.965409 54999 net.cpp:434] norm1 <- pool1
I1008 10:24:51.965425 54999 net.cpp:408] norm1 -> norm1
I1008 10:24:51.965503 54999 net.cpp:150] Setting up norm1
I1008 10:24:51.965518 54999 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I1008 10:24:51.965528 54999 net.cpp:165] Memory required for data: 527330816
I1008 10:24:51.965538 54999 layer_factory.hpp:77] Creating layer conv2
I1008 10:24:51.965567 54999 net.cpp:100] Creating Layer conv2
I1008 10:24:51.965576 54999 net.cpp:434] conv2 <- norm1
I1008 10:24:51.965592 54999 net.cpp:408] conv2 -> conv2
I1008 10:24:51.986956 54999 net.cpp:150] Setting up conv2
I1008 10:24:51.986989 54999 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I1008 10:24:51.986999 54999 net.cpp:165] Memory required for data: 622882304
I1008 10:24:51.987020 54999 layer_factory.hpp:77] Creating layer relu2
I1008 10:24:51.987035 54999 net.cpp:100] Creating Layer relu2
I1008 10:24:51.987045 54999 net.cpp:434] relu2 <- conv2
I1008 10:24:51.987058 54999 net.cpp:395] relu2 -> conv2 (in-place)
I1008 10:24:51.987076 54999 net.cpp:150] Setting up relu2
I1008 10:24:51.987087 54999 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I1008 10:24:51.987094 54999 net.cpp:165] Memory required for data: 718433792
I1008 10:24:51.987102 54999 layer_factory.hpp:77] Creating layer pool2
I1008 10:24:51.987118 54999 net.cpp:100] Creating Layer pool2
I1008 10:24:51.987125 54999 net.cpp:434] pool2 <- conv2
I1008 10:24:51.987138 54999 net.cpp:408] pool2 -> pool2
I1008 10:24:51.987231 54999 net.cpp:150] Setting up pool2
I1008 10:24:51.987247 54999 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1008 10:24:51.987256 54999 net.cpp:165] Memory required for data: 740584960
I1008 10:24:51.987262 54999 layer_factory.hpp:77] Creating layer norm2
I1008 10:24:51.987275 54999 net.cpp:100] Creating Layer norm2
I1008 10:24:51.987285 54999 net.cpp:434] norm2 <- pool2
I1008 10:24:51.987298 54999 net.cpp:408] norm2 -> norm2
I1008 10:24:51.987357 54999 net.cpp:150] Setting up norm2
I1008 10:24:51.987368 54999 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1008 10:24:51.987377 54999 net.cpp:165] Memory required for data: 762736128
I1008 10:24:51.987385 54999 layer_factory.hpp:77] Creating layer conv3
I1008 10:24:51.987404 54999 net.cpp:100] Creating Layer conv3
I1008 10:24:51.987412 54999 net.cpp:434] conv3 <- norm2
I1008 10:24:51.987427 54999 net.cpp:408] conv3 -> conv3
I1008 10:24:52.028669 54999 net.cpp:150] Setting up conv3
I1008 10:24:52.028699 54999 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1008 10:24:52.028707 54999 net.cpp:165] Memory required for data: 795962880
I1008 10:24:52.028724 54999 layer_factory.hpp:77] Creating layer relu3
I1008 10:24:52.028743 54999 net.cpp:100] Creating Layer relu3
I1008 10:24:52.028753 54999 net.cpp:434] relu3 <- conv3
I1008 10:24:52.028764 54999 net.cpp:395] relu3 -> conv3 (in-place)
I1008 10:24:52.028777 54999 net.cpp:150] Setting up relu3
I1008 10:24:52.028786 54999 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1008 10:24:52.028792 54999 net.cpp:165] Memory required for data: 829189632
I1008 10:24:52.028800 54999 layer_factory.hpp:77] Creating layer conv4
I1008 10:24:52.028816 54999 net.cpp:100] Creating Layer conv4
I1008 10:24:52.028823 54999 net.cpp:434] conv4 <- conv3
I1008 10:24:52.028836 54999 net.cpp:408] conv4 -> conv4
I1008 10:24:52.055418 54999 net.cpp:150] Setting up conv4
I1008 10:24:52.055445 54999 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1008 10:24:52.055452 54999 net.cpp:165] Memory required for data: 862416384
I1008 10:24:52.055462 54999 layer_factory.hpp:77] Creating layer relu4
I1008 10:24:52.055474 54999 net.cpp:100] Creating Layer relu4
I1008 10:24:52.055481 54999 net.cpp:434] relu4 <- conv4
I1008 10:24:52.055491 54999 net.cpp:395] relu4 -> conv4 (in-place)
I1008 10:24:52.055519 54999 net.cpp:150] Setting up relu4
I1008 10:24:52.055528 54999 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I1008 10:24:52.055557 54999 net.cpp:165] Memory required for data: 895643136
I1008 10:24:52.055562 54999 layer_factory.hpp:77] Creating layer conv5
I1008 10:24:52.055580 54999 net.cpp:100] Creating Layer conv5
I1008 10:24:52.055586 54999 net.cpp:434] conv5 <- conv4
I1008 10:24:52.055598 54999 net.cpp:408] conv5 -> conv5
I1008 10:24:52.072299 54999 net.cpp:150] Setting up conv5
I1008 10:24:52.072320 54999 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1008 10:24:52.072326 54999 net.cpp:165] Memory required for data: 917794304
I1008 10:24:52.072341 54999 layer_factory.hpp:77] Creating layer relu5
I1008 10:24:52.072351 54999 net.cpp:100] Creating Layer relu5
I1008 10:24:52.072357 54999 net.cpp:434] relu5 <- conv5
I1008 10:24:52.072365 54999 net.cpp:395] relu5 -> conv5 (in-place)
I1008 10:24:52.072376 54999 net.cpp:150] Setting up relu5
I1008 10:24:52.072382 54999 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I1008 10:24:52.072387 54999 net.cpp:165] Memory required for data: 939945472
I1008 10:24:52.072392 54999 layer_factory.hpp:77] Creating layer pool5
I1008 10:24:52.072403 54999 net.cpp:100] Creating Layer pool5
I1008 10:24:52.072408 54999 net.cpp:434] pool5 <- conv5
I1008 10:24:52.072417 54999 net.cpp:408] pool5 -> pool5
I1008 10:24:52.072463 54999 net.cpp:150] Setting up pool5
I1008 10:24:52.072471 54999 net.cpp:157] Top shape: 128 256 6 6 (1179648)
I1008 10:24:52.072476 54999 net.cpp:165] Memory required for data: 944664064
I1008 10:24:52.072481 54999 layer_factory.hpp:77] Creating layer fc6
I1008 10:24:52.072492 54999 net.cpp:100] Creating Layer fc6
I1008 10:24:52.072499 54999 net.cpp:434] fc6 <- pool5
I1008 10:24:52.072507 54999 net.cpp:408] fc6 -> fc6
I1008 10:24:53.062578 54999 net.cpp:150] Setting up fc6
I1008 10:24:53.062636 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.062641 54999 net.cpp:165] Memory required for data: 946761216
I1008 10:24:53.062656 54999 layer_factory.hpp:77] Creating layer relu6
I1008 10:24:53.062674 54999 net.cpp:100] Creating Layer relu6
I1008 10:24:53.062680 54999 net.cpp:434] relu6 <- fc6
I1008 10:24:53.062688 54999 net.cpp:395] relu6 -> fc6 (in-place)
I1008 10:24:53.062700 54999 net.cpp:150] Setting up relu6
I1008 10:24:53.062703 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.062706 54999 net.cpp:165] Memory required for data: 948858368
I1008 10:24:53.062711 54999 layer_factory.hpp:77] Creating layer drop6
I1008 10:24:53.062719 54999 net.cpp:100] Creating Layer drop6
I1008 10:24:53.062722 54999 net.cpp:434] drop6 <- fc6
I1008 10:24:53.062726 54999 net.cpp:395] drop6 -> fc6 (in-place)
I1008 10:24:53.062748 54999 net.cpp:150] Setting up drop6
I1008 10:24:53.062754 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.062757 54999 net.cpp:165] Memory required for data: 950955520
I1008 10:24:53.062760 54999 layer_factory.hpp:77] Creating layer fc7
I1008 10:24:53.062769 54999 net.cpp:100] Creating Layer fc7
I1008 10:24:53.062772 54999 net.cpp:434] fc7 <- fc6
I1008 10:24:53.062777 54999 net.cpp:408] fc7 -> fc7
I1008 10:24:53.412614 54999 net.cpp:150] Setting up fc7
I1008 10:24:53.412662 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.412667 54999 net.cpp:165] Memory required for data: 953052672
I1008 10:24:53.412677 54999 layer_factory.hpp:77] Creating layer relu7
I1008 10:24:53.412689 54999 net.cpp:100] Creating Layer relu7
I1008 10:24:53.412695 54999 net.cpp:434] relu7 <- fc7
I1008 10:24:53.412703 54999 net.cpp:395] relu7 -> fc7 (in-place)
I1008 10:24:53.412714 54999 net.cpp:150] Setting up relu7
I1008 10:24:53.412717 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.412721 54999 net.cpp:165] Memory required for data: 955149824
I1008 10:24:53.412726 54999 layer_factory.hpp:77] Creating layer drop7
I1008 10:24:53.412734 54999 net.cpp:100] Creating Layer drop7
I1008 10:24:53.412737 54999 net.cpp:434] drop7 <- fc7
I1008 10:24:53.412742 54999 net.cpp:395] drop7 -> fc7 (in-place)
I1008 10:24:53.412781 54999 net.cpp:150] Setting up drop7
I1008 10:24:53.412788 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.412811 54999 net.cpp:165] Memory required for data: 957246976
I1008 10:24:53.412814 54999 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I1008 10:24:53.412822 54999 net.cpp:100] Creating Layer fc7_drop7_0_split
I1008 10:24:53.412824 54999 net.cpp:434] fc7_drop7_0_split <- fc7
I1008 10:24:53.412829 54999 net.cpp:408] fc7_drop7_0_split -> fc7_drop7_0_split_0
I1008 10:24:53.412837 54999 net.cpp:408] fc7_drop7_0_split -> fc7_drop7_0_split_1
I1008 10:24:53.412863 54999 net.cpp:150] Setting up fc7_drop7_0_split
I1008 10:24:53.412869 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.412873 54999 net.cpp:157] Top shape: 128 4096 (524288)
I1008 10:24:53.412876 54999 net.cpp:165] Memory required for data: 961441280
I1008 10:24:53.412878 54999 layer_factory.hpp:77] Creating layer fc8_new
I1008 10:24:53.412890 54999 net.cpp:100] Creating Layer fc8_new
I1008 10:24:53.412894 54999 net.cpp:434] fc8_new <- fc7_drop7_0_split_0
I1008 10:24:53.412900 54999 net.cpp:408] fc8_new -> fc8
I1008 10:24:53.415999 54999 net.cpp:150] Setting up fc8_new
I1008 10:24:53.416008 54999 net.cpp:157] Top shape: 128 31 (3968)
I1008 10:24:53.416012 54999 net.cpp:165] Memory required for data: 961457152
I1008 10:24:53.416018 54999 layer_factory.hpp:77] Creating layer fc8_fc8_new_0_split
I1008 10:24:53.416024 54999 net.cpp:100] Creating Layer fc8_fc8_new_0_split
I1008 10:24:53.416028 54999 net.cpp:434] fc8_fc8_new_0_split <- fc8
I1008 10:24:53.416033 54999 net.cpp:408] fc8_fc8_new_0_split -> fc8_fc8_new_0_split_0
I1008 10:24:53.416039 54999 net.cpp:408] fc8_fc8_new_0_split -> fc8_fc8_new_0_split_1
I1008 10:24:53.416062 54999 net.cpp:150] Setting up fc8_fc8_new_0_split
I1008 10:24:53.416069 54999 net.cpp:157] Top shape: 128 31 (3968)
I1008 10:24:53.416071 54999 net.cpp:157] Top shape: 128 31 (3968)
I1008 10:24:53.416074 54999 net.cpp:165] Memory required for data: 961488896
I1008 10:24:53.416079 54999 layer_factory.hpp:77] Creating layer slice_fc7
I1008 10:24:53.416088 54999 net.cpp:100] Creating Layer slice_fc7
I1008 10:24:53.416091 54999 net.cpp:434] slice_fc7 <- fc7_drop7_0_split_1
I1008 10:24:53.416097 54999 net.cpp:408] slice_fc7 -> fc7_source
I1008 10:24:53.416106 54999 net.cpp:408] slice_fc7 -> fc7_target
I1008 10:24:53.416131 54999 net.cpp:150] Setting up slice_fc7
I1008 10:24:53.416136 54999 net.cpp:157] Top shape: 64 4096 (262144)
I1008 10:24:53.416141 54999 net.cpp:157] Top shape: 64 4096 (262144)
I1008 10:24:53.416143 54999 net.cpp:165] Memory required for data: 963586048
I1008 10:24:53.416146 54999 layer_factory.hpp:77] Creating layer slice_fc8
I1008 10:24:53.416152 54999 net.cpp:100] Creating Layer slice_fc8
I1008 10:24:53.416157 54999 net.cpp:434] slice_fc8 <- fc8_fc8_new_0_split_0
I1008 10:24:53.416162 54999 net.cpp:408] slice_fc8 -> fc8_source
I1008 10:24:53.416167 54999 net.cpp:408] slice_fc8 -> fc8_target
I1008 10:24:53.416193 54999 net.cpp:150] Setting up slice_fc8
I1008 10:24:53.416198 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416201 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416204 54999 net.cpp:165] Memory required for data: 963601920
I1008 10:24:53.416208 54999 layer_factory.hpp:77] Creating layer silence
I1008 10:24:53.416216 54999 net.cpp:100] Creating Layer silence
I1008 10:24:53.416219 54999 net.cpp:434] silence <- fc8_target
I1008 10:24:53.416224 54999 net.cpp:150] Setting up silence
I1008 10:24:53.416226 54999 net.cpp:165] Memory required for data: 963601920
I1008 10:24:53.416230 54999 layer_factory.hpp:77] Creating layer softmax_loss
I1008 10:24:53.416237 54999 net.cpp:100] Creating Layer softmax_loss
I1008 10:24:53.416240 54999 net.cpp:434] softmax_loss <- fc8_source
I1008 10:24:53.416244 54999 net.cpp:434] softmax_loss <- source_label
I1008 10:24:53.416249 54999 net.cpp:408] softmax_loss -> softmax_loss
I1008 10:24:53.416260 54999 layer_factory.hpp:77] Creating layer softmax_loss
I1008 10:24:53.416332 54999 net.cpp:150] Setting up softmax_loss
I1008 10:24:53.416344 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.416348 54999 net.cpp:160]     with loss weight 1
I1008 10:24:53.416378 54999 net.cpp:165] Memory required for data: 963601924
I1008 10:24:53.416381 54999 layer_factory.hpp:77] Creating layer fc8_softmax
I1008 10:24:53.416404 54999 net.cpp:100] Creating Layer fc8_softmax
I1008 10:24:53.416411 54999 net.cpp:434] fc8_softmax <- fc8_fc8_new_0_split_1
I1008 10:24:53.416416 54999 net.cpp:408] fc8_softmax -> fc8_softmax
I1008 10:24:53.416461 54999 net.cpp:150] Setting up fc8_softmax
I1008 10:24:53.416467 54999 net.cpp:157] Top shape: 128 31 (3968)
I1008 10:24:53.416471 54999 net.cpp:165] Memory required for data: 963617796
I1008 10:24:53.416473 54999 layer_factory.hpp:77] Creating layer slice_softmax
I1008 10:24:53.416481 54999 net.cpp:100] Creating Layer slice_softmax
I1008 10:24:53.416484 54999 net.cpp:434] slice_softmax <- fc8_softmax
I1008 10:24:53.416491 54999 net.cpp:408] slice_softmax -> source_softmax
I1008 10:24:53.416496 54999 net.cpp:408] slice_softmax -> target_softmax
I1008 10:24:53.416522 54999 net.cpp:150] Setting up slice_softmax
I1008 10:24:53.416527 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416530 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416533 54999 net.cpp:165] Memory required for data: 963633668
I1008 10:24:53.416537 54999 layer_factory.hpp:77] Creating layer source_softmax_slice_softmax_0_split
I1008 10:24:53.416541 54999 net.cpp:100] Creating Layer source_softmax_slice_softmax_0_split
I1008 10:24:53.416545 54999 net.cpp:434] source_softmax_slice_softmax_0_split <- source_softmax
I1008 10:24:53.416550 54999 net.cpp:408] source_softmax_slice_softmax_0_split -> source_softmax_slice_softmax_0_split_0
I1008 10:24:53.416555 54999 net.cpp:408] source_softmax_slice_softmax_0_split -> source_softmax_slice_softmax_0_split_1
I1008 10:24:53.416560 54999 net.cpp:408] source_softmax_slice_softmax_0_split -> source_softmax_slice_softmax_0_split_2
I1008 10:24:53.416599 54999 net.cpp:150] Setting up source_softmax_slice_softmax_0_split
I1008 10:24:53.416604 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416607 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416611 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416615 54999 net.cpp:165] Memory required for data: 963657476
I1008 10:24:53.416617 54999 layer_factory.hpp:77] Creating layer target_softmax_slice_softmax_1_split
I1008 10:24:53.416623 54999 net.cpp:100] Creating Layer target_softmax_slice_softmax_1_split
I1008 10:24:53.416627 54999 net.cpp:434] target_softmax_slice_softmax_1_split <- target_softmax
I1008 10:24:53.416632 54999 net.cpp:408] target_softmax_slice_softmax_1_split -> target_softmax_slice_softmax_1_split_0
I1008 10:24:53.416637 54999 net.cpp:408] target_softmax_slice_softmax_1_split -> target_softmax_slice_softmax_1_split_1
I1008 10:24:53.416642 54999 net.cpp:408] target_softmax_slice_softmax_1_split -> target_softmax_slice_softmax_1_split_2
I1008 10:24:53.416673 54999 net.cpp:150] Setting up target_softmax_slice_softmax_1_split
I1008 10:24:53.416678 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416682 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416685 54999 net.cpp:157] Top shape: 64 31 (1984)
I1008 10:24:53.416688 54999 net.cpp:165] Memory required for data: 963681284
I1008 10:24:53.416692 54999 layer_factory.hpp:77] Creating layer jmmd_loss_fc7
I1008 10:24:53.416698 54999 net.cpp:100] Creating Layer jmmd_loss_fc7
I1008 10:24:53.416702 54999 net.cpp:434] jmmd_loss_fc7 <- fc7_source
I1008 10:24:53.416707 54999 net.cpp:434] jmmd_loss_fc7 <- fc7_target
I1008 10:24:53.416710 54999 net.cpp:434] jmmd_loss_fc7 <- source_softmax_slice_softmax_0_split_0
I1008 10:24:53.416714 54999 net.cpp:434] jmmd_loss_fc7 <- target_softmax_slice_softmax_1_split_0
I1008 10:24:53.416718 54999 net.cpp:408] jmmd_loss_fc7 -> jmmd_loss_fc7
I1008 10:24:53.416800 54999 net.cpp:150] Setting up jmmd_loss_fc7
I1008 10:24:53.416806 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.416810 54999 net.cpp:160]     with loss weight 1
I1008 10:24:53.416821 54999 net.cpp:165] Memory required for data: 963681288
I1008 10:24:53.416831 54999 layer_factory.hpp:77] Creating layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:24:53.416836 54999 net.cpp:100] Creating Layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:24:53.416839 54999 net.cpp:434] jmmd_loss_fc7_jmmd_loss_fc7_0_split <- jmmd_loss_fc7
I1008 10:24:53.416846 54999 net.cpp:408] jmmd_loss_fc7_jmmd_loss_fc7_0_split -> jmmd_loss_fc7_jmmd_loss_fc7_0_split_0
I1008 10:24:53.416851 54999 net.cpp:408] jmmd_loss_fc7_jmmd_loss_fc7_0_split -> jmmd_loss_fc7_jmmd_loss_fc7_0_split_1
I1008 10:24:53.416868 54999 net.cpp:150] Setting up jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:24:53.416873 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.416877 54999 net.cpp:160]     with loss weight 0.3
I1008 10:24:53.416882 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.416884 54999 net.cpp:165] Memory required for data: 963681296
I1008 10:24:53.416887 54999 layer_factory.hpp:77] Creating layer jmmd_loss_softmax
I1008 10:24:53.416899 54999 net.cpp:100] Creating Layer jmmd_loss_softmax
I1008 10:24:53.416903 54999 net.cpp:434] jmmd_loss_softmax <- source_softmax_slice_softmax_0_split_1
I1008 10:24:53.416908 54999 net.cpp:434] jmmd_loss_softmax <- target_softmax_slice_softmax_1_split_1
I1008 10:24:53.416911 54999 net.cpp:434] jmmd_loss_softmax <- source_softmax_slice_softmax_0_split_2
I1008 10:24:53.416914 54999 net.cpp:434] jmmd_loss_softmax <- target_softmax_slice_softmax_1_split_2
I1008 10:24:53.416919 54999 net.cpp:408] jmmd_loss_softmax -> jmmd_loss_softmax
I1008 10:24:53.416977 54999 net.cpp:150] Setting up jmmd_loss_softmax
I1008 10:24:53.416983 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.416986 54999 net.cpp:160]     with loss weight 1
I1008 10:24:53.416990 54999 net.cpp:165] Memory required for data: 963681300
I1008 10:24:53.416993 54999 layer_factory.hpp:77] Creating layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:24:53.416998 54999 net.cpp:100] Creating Layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:24:53.417001 54999 net.cpp:434] jmmd_loss_softmax_jmmd_loss_softmax_0_split <- jmmd_loss_softmax
I1008 10:24:53.417006 54999 net.cpp:408] jmmd_loss_softmax_jmmd_loss_softmax_0_split -> jmmd_loss_softmax_jmmd_loss_softmax_0_split_0
I1008 10:24:53.417012 54999 net.cpp:408] jmmd_loss_softmax_jmmd_loss_softmax_0_split -> jmmd_loss_softmax_jmmd_loss_softmax_0_split_1
I1008 10:24:53.417028 54999 net.cpp:150] Setting up jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:24:53.417033 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.417035 54999 net.cpp:160]     with loss weight 0.3
I1008 10:24:53.417040 54999 net.cpp:157] Top shape: (1)
I1008 10:24:53.417043 54999 net.cpp:165] Memory required for data: 963681308
I1008 10:24:53.417047 54999 layer_factory.hpp:77] Creating layer silence_loss_value
I1008 10:24:53.417052 54999 net.cpp:100] Creating Layer silence_loss_value
I1008 10:24:53.417055 54999 net.cpp:434] silence_loss_value <- jmmd_loss_fc7_jmmd_loss_fc7_0_split_1
I1008 10:24:53.417059 54999 net.cpp:434] silence_loss_value <- jmmd_loss_softmax_jmmd_loss_softmax_0_split_1
I1008 10:24:53.417063 54999 net.cpp:150] Setting up silence_loss_value
I1008 10:24:53.417065 54999 net.cpp:165] Memory required for data: 963681308
I1008 10:24:53.417070 54999 net.cpp:228] silence_loss_value does not need backward computation.
I1008 10:24:53.417074 54999 net.cpp:226] jmmd_loss_softmax_jmmd_loss_softmax_0_split needs backward computation.
I1008 10:24:53.417078 54999 net.cpp:226] jmmd_loss_softmax needs backward computation.
I1008 10:24:53.417081 54999 net.cpp:226] jmmd_loss_fc7_jmmd_loss_fc7_0_split needs backward computation.
I1008 10:24:53.417084 54999 net.cpp:226] jmmd_loss_fc7 needs backward computation.
I1008 10:24:53.417088 54999 net.cpp:226] target_softmax_slice_softmax_1_split needs backward computation.
I1008 10:24:53.417091 54999 net.cpp:226] source_softmax_slice_softmax_0_split needs backward computation.
I1008 10:24:53.417095 54999 net.cpp:226] slice_softmax needs backward computation.
I1008 10:24:53.417098 54999 net.cpp:226] fc8_softmax needs backward computation.
I1008 10:24:53.417117 54999 net.cpp:226] softmax_loss needs backward computation.
I1008 10:24:53.417120 54999 net.cpp:228] silence does not need backward computation.
I1008 10:24:53.417124 54999 net.cpp:226] slice_fc8 needs backward computation.
I1008 10:24:53.417127 54999 net.cpp:226] slice_fc7 needs backward computation.
I1008 10:24:53.417130 54999 net.cpp:226] fc8_fc8_new_0_split needs backward computation.
I1008 10:24:53.417135 54999 net.cpp:226] fc8_new needs backward computation.
I1008 10:24:53.417137 54999 net.cpp:226] fc7_drop7_0_split needs backward computation.
I1008 10:24:53.417140 54999 net.cpp:226] drop7 needs backward computation.
I1008 10:24:53.417143 54999 net.cpp:226] relu7 needs backward computation.
I1008 10:24:53.417146 54999 net.cpp:226] fc7 needs backward computation.
I1008 10:24:53.417150 54999 net.cpp:226] drop6 needs backward computation.
I1008 10:24:53.417152 54999 net.cpp:226] relu6 needs backward computation.
I1008 10:24:53.417155 54999 net.cpp:226] fc6 needs backward computation.
I1008 10:24:53.417160 54999 net.cpp:226] pool5 needs backward computation.
I1008 10:24:53.417162 54999 net.cpp:226] relu5 needs backward computation.
I1008 10:24:53.417166 54999 net.cpp:226] conv5 needs backward computation.
I1008 10:24:53.417170 54999 net.cpp:226] relu4 needs backward computation.
I1008 10:24:53.417172 54999 net.cpp:226] conv4 needs backward computation.
I1008 10:24:53.417176 54999 net.cpp:226] relu3 needs backward computation.
I1008 10:24:53.417178 54999 net.cpp:226] conv3 needs backward computation.
I1008 10:24:53.417181 54999 net.cpp:228] norm2 does not need backward computation.
I1008 10:24:53.417186 54999 net.cpp:228] pool2 does not need backward computation.
I1008 10:24:53.417188 54999 net.cpp:228] relu2 does not need backward computation.
I1008 10:24:53.417192 54999 net.cpp:228] conv2 does not need backward computation.
I1008 10:24:53.417196 54999 net.cpp:228] norm1 does not need backward computation.
I1008 10:24:53.417198 54999 net.cpp:228] pool1 does not need backward computation.
I1008 10:24:53.417202 54999 net.cpp:228] relu1 does not need backward computation.
I1008 10:24:53.417206 54999 net.cpp:228] conv1 does not need backward computation.
I1008 10:24:53.417209 54999 net.cpp:228] data does not need backward computation.
I1008 10:24:53.417213 54999 net.cpp:228] target_label_silence does not need backward computation.
I1008 10:24:53.417217 54999 net.cpp:228] target_data does not need backward computation.
I1008 10:24:53.417222 54999 net.cpp:228] source_data does not need backward computation.
I1008 10:24:53.417227 54999 net.cpp:270] This network produces output jmmd_loss_fc7_jmmd_loss_fc7_0_split_0
I1008 10:24:53.417237 54999 net.cpp:270] This network produces output jmmd_loss_softmax_jmmd_loss_softmax_0_split_0
I1008 10:24:53.417239 54999 net.cpp:270] This network produces output softmax_loss
I1008 10:24:53.417264 54999 net.cpp:283] Network initialization done.
I1008 10:24:53.418018 54999 solver.cpp:182] Creating test net (#0) specified by net file: models/JAN/alexnet/train_val.prototxt
I1008 10:24:53.418076 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer source_data
I1008 10:24:53.418081 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_data
I1008 10:24:53.418084 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_label_silence
I1008 10:24:53.418088 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1008 10:24:53.418100 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer slice_fc7
I1008 10:24:53.418104 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer slice_fc8
I1008 10:24:53.418107 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence
I1008 10:24:53.418110 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer softmax_loss
I1008 10:24:53.418126 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc8_softmax
I1008 10:24:53.418129 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer slice_softmax
I1008 10:24:53.418133 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer jmmd_loss_fc7
I1008 10:24:53.418135 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer jmmd_loss_softmax
I1008 10:24:53.418138 54999 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence_loss_value
I1008 10:24:53.418325 54999 net.cpp:58] Initializing net from parameters: 
name: "amazon_to_webcam"
state {
  phase: TEST
}
layer {
  name: "test_data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "./data/ilsvrc12/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "./data/office/webcam_list.txt"
    batch_size: 1
    shuffle: false
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1008 10:24:53.418401 54999 layer_factory.hpp:77] Creating layer test_data
I1008 10:24:53.418414 54999 net.cpp:100] Creating Layer test_data
I1008 10:24:53.418418 54999 net.cpp:408] test_data -> data
I1008 10:24:53.418426 54999 net.cpp:408] test_data -> label
I1008 10:24:53.418433 54999 data_transformer.cpp:25] Loading mean file from: ./data/ilsvrc12/imagenet_mean.binaryproto
I1008 10:24:53.421478 54999 image_data_layer.cpp:38] Opening file ./data/office/webcam_list.txt
I1008 10:24:53.421680 54999 image_data_layer.cpp:58] A total of 795 images.
I1008 10:24:53.424135 54999 image_data_layer.cpp:85] output data size: 1,3,227,227
I1008 10:24:53.426651 54999 net.cpp:150] Setting up test_data
I1008 10:24:53.426666 54999 net.cpp:157] Top shape: 1 3 227 227 (154587)
I1008 10:24:53.426669 54999 net.cpp:157] Top shape: 1 (1)
I1008 10:24:53.426672 54999 net.cpp:165] Memory required for data: 618352
I1008 10:24:53.426676 54999 layer_factory.hpp:77] Creating layer conv1
I1008 10:24:53.426688 54999 net.cpp:100] Creating Layer conv1
I1008 10:24:53.426692 54999 net.cpp:434] conv1 <- data
I1008 10:24:53.426697 54999 net.cpp:408] conv1 -> conv1
I1008 10:24:53.427644 54999 net.cpp:150] Setting up conv1
I1008 10:24:53.427654 54999 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1008 10:24:53.427657 54999 net.cpp:165] Memory required for data: 1779952
I1008 10:24:53.427665 54999 layer_factory.hpp:77] Creating layer relu1
I1008 10:24:53.427672 54999 net.cpp:100] Creating Layer relu1
I1008 10:24:53.427676 54999 net.cpp:434] relu1 <- conv1
I1008 10:24:53.427680 54999 net.cpp:395] relu1 -> conv1 (in-place)
I1008 10:24:53.427685 54999 net.cpp:150] Setting up relu1
I1008 10:24:53.427690 54999 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1008 10:24:53.427692 54999 net.cpp:165] Memory required for data: 2941552
I1008 10:24:53.427695 54999 layer_factory.hpp:77] Creating layer pool1
I1008 10:24:53.427700 54999 net.cpp:100] Creating Layer pool1
I1008 10:24:53.427705 54999 net.cpp:434] pool1 <- conv1
I1008 10:24:53.427708 54999 net.cpp:408] pool1 -> pool1
I1008 10:24:53.427736 54999 net.cpp:150] Setting up pool1
I1008 10:24:53.427741 54999 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1008 10:24:53.427744 54999 net.cpp:165] Memory required for data: 3221488
I1008 10:24:53.427747 54999 layer_factory.hpp:77] Creating layer norm1
I1008 10:24:53.427760 54999 net.cpp:100] Creating Layer norm1
I1008 10:24:53.427772 54999 net.cpp:434] norm1 <- pool1
I1008 10:24:53.427778 54999 net.cpp:408] norm1 -> norm1
I1008 10:24:53.427803 54999 net.cpp:150] Setting up norm1
I1008 10:24:53.427809 54999 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1008 10:24:53.427811 54999 net.cpp:165] Memory required for data: 3501424
I1008 10:24:53.427814 54999 layer_factory.hpp:77] Creating layer conv2
I1008 10:24:53.427821 54999 net.cpp:100] Creating Layer conv2
I1008 10:24:53.427824 54999 net.cpp:434] conv2 <- norm1
I1008 10:24:53.427829 54999 net.cpp:408] conv2 -> conv2
I1008 10:24:53.433806 54999 net.cpp:150] Setting up conv2
I1008 10:24:53.433815 54999 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1008 10:24:53.433818 54999 net.cpp:165] Memory required for data: 4247920
I1008 10:24:53.433825 54999 layer_factory.hpp:77] Creating layer relu2
I1008 10:24:53.433831 54999 net.cpp:100] Creating Layer relu2
I1008 10:24:53.433835 54999 net.cpp:434] relu2 <- conv2
I1008 10:24:53.433838 54999 net.cpp:395] relu2 -> conv2 (in-place)
I1008 10:24:53.433843 54999 net.cpp:150] Setting up relu2
I1008 10:24:53.433847 54999 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1008 10:24:53.433851 54999 net.cpp:165] Memory required for data: 4994416
I1008 10:24:53.433853 54999 layer_factory.hpp:77] Creating layer pool2
I1008 10:24:53.433857 54999 net.cpp:100] Creating Layer pool2
I1008 10:24:53.433861 54999 net.cpp:434] pool2 <- conv2
I1008 10:24:53.433866 54999 net.cpp:408] pool2 -> pool2
I1008 10:24:53.433889 54999 net.cpp:150] Setting up pool2
I1008 10:24:53.433894 54999 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1008 10:24:53.433898 54999 net.cpp:165] Memory required for data: 5167472
I1008 10:24:53.433902 54999 layer_factory.hpp:77] Creating layer norm2
I1008 10:24:53.433907 54999 net.cpp:100] Creating Layer norm2
I1008 10:24:53.433909 54999 net.cpp:434] norm2 <- pool2
I1008 10:24:53.433913 54999 net.cpp:408] norm2 -> norm2
I1008 10:24:53.433935 54999 net.cpp:150] Setting up norm2
I1008 10:24:53.433940 54999 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1008 10:24:53.433943 54999 net.cpp:165] Memory required for data: 5340528
I1008 10:24:53.433946 54999 layer_factory.hpp:77] Creating layer conv3
I1008 10:24:53.433954 54999 net.cpp:100] Creating Layer conv3
I1008 10:24:53.433956 54999 net.cpp:434] conv3 <- norm2
I1008 10:24:53.433960 54999 net.cpp:408] conv3 -> conv3
I1008 10:24:53.452669 54999 net.cpp:150] Setting up conv3
I1008 10:24:53.452684 54999 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1008 10:24:53.452688 54999 net.cpp:165] Memory required for data: 5600112
I1008 10:24:53.452695 54999 layer_factory.hpp:77] Creating layer relu3
I1008 10:24:53.452702 54999 net.cpp:100] Creating Layer relu3
I1008 10:24:53.452705 54999 net.cpp:434] relu3 <- conv3
I1008 10:24:53.452709 54999 net.cpp:395] relu3 -> conv3 (in-place)
I1008 10:24:53.452715 54999 net.cpp:150] Setting up relu3
I1008 10:24:53.452719 54999 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1008 10:24:53.452723 54999 net.cpp:165] Memory required for data: 5859696
I1008 10:24:53.452725 54999 layer_factory.hpp:77] Creating layer conv4
I1008 10:24:53.452731 54999 net.cpp:100] Creating Layer conv4
I1008 10:24:53.452735 54999 net.cpp:434] conv4 <- conv3
I1008 10:24:53.452739 54999 net.cpp:408] conv4 -> conv4
I1008 10:24:53.466821 54999 net.cpp:150] Setting up conv4
I1008 10:24:53.466835 54999 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1008 10:24:53.466840 54999 net.cpp:165] Memory required for data: 6119280
I1008 10:24:53.466845 54999 layer_factory.hpp:77] Creating layer relu4
I1008 10:24:53.466850 54999 net.cpp:100] Creating Layer relu4
I1008 10:24:53.466855 54999 net.cpp:434] relu4 <- conv4
I1008 10:24:53.466859 54999 net.cpp:395] relu4 -> conv4 (in-place)
I1008 10:24:53.466864 54999 net.cpp:150] Setting up relu4
I1008 10:24:53.466868 54999 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1008 10:24:53.466871 54999 net.cpp:165] Memory required for data: 6378864
I1008 10:24:53.466874 54999 layer_factory.hpp:77] Creating layer conv5
I1008 10:24:53.466900 54999 net.cpp:100] Creating Layer conv5
I1008 10:24:53.466912 54999 net.cpp:434] conv5 <- conv4
I1008 10:24:53.466917 54999 net.cpp:408] conv5 -> conv5
I1008 10:24:53.476910 54999 net.cpp:150] Setting up conv5
I1008 10:24:53.476927 54999 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1008 10:24:53.476930 54999 net.cpp:165] Memory required for data: 6551920
I1008 10:24:53.476938 54999 layer_factory.hpp:77] Creating layer relu5
I1008 10:24:53.476945 54999 net.cpp:100] Creating Layer relu5
I1008 10:24:53.476948 54999 net.cpp:434] relu5 <- conv5
I1008 10:24:53.476953 54999 net.cpp:395] relu5 -> conv5 (in-place)
I1008 10:24:53.476959 54999 net.cpp:150] Setting up relu5
I1008 10:24:53.476963 54999 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1008 10:24:53.476966 54999 net.cpp:165] Memory required for data: 6724976
I1008 10:24:53.476969 54999 layer_factory.hpp:77] Creating layer pool5
I1008 10:24:53.476974 54999 net.cpp:100] Creating Layer pool5
I1008 10:24:53.476977 54999 net.cpp:434] pool5 <- conv5
I1008 10:24:53.476981 54999 net.cpp:408] pool5 -> pool5
I1008 10:24:53.477008 54999 net.cpp:150] Setting up pool5
I1008 10:24:53.477013 54999 net.cpp:157] Top shape: 1 256 6 6 (9216)
I1008 10:24:53.477017 54999 net.cpp:165] Memory required for data: 6761840
I1008 10:24:53.477020 54999 layer_factory.hpp:77] Creating layer fc6
I1008 10:24:53.477027 54999 net.cpp:100] Creating Layer fc6
I1008 10:24:53.477030 54999 net.cpp:434] fc6 <- pool5
I1008 10:24:53.477035 54999 net.cpp:408] fc6 -> fc6
I1008 10:24:54.263622 54999 net.cpp:150] Setting up fc6
I1008 10:24:54.263692 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.263697 54999 net.cpp:165] Memory required for data: 6778224
I1008 10:24:54.263712 54999 layer_factory.hpp:77] Creating layer relu6
I1008 10:24:54.263731 54999 net.cpp:100] Creating Layer relu6
I1008 10:24:54.263737 54999 net.cpp:434] relu6 <- fc6
I1008 10:24:54.263746 54999 net.cpp:395] relu6 -> fc6 (in-place)
I1008 10:24:54.263757 54999 net.cpp:150] Setting up relu6
I1008 10:24:54.263761 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.263764 54999 net.cpp:165] Memory required for data: 6794608
I1008 10:24:54.263767 54999 layer_factory.hpp:77] Creating layer drop6
I1008 10:24:54.263779 54999 net.cpp:100] Creating Layer drop6
I1008 10:24:54.263783 54999 net.cpp:434] drop6 <- fc6
I1008 10:24:54.263788 54999 net.cpp:395] drop6 -> fc6 (in-place)
I1008 10:24:54.263809 54999 net.cpp:150] Setting up drop6
I1008 10:24:54.263816 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.263818 54999 net.cpp:165] Memory required for data: 6810992
I1008 10:24:54.263821 54999 layer_factory.hpp:77] Creating layer fc7
I1008 10:24:54.263833 54999 net.cpp:100] Creating Layer fc7
I1008 10:24:54.263836 54999 net.cpp:434] fc7 <- fc6
I1008 10:24:54.263842 54999 net.cpp:408] fc7 -> fc7
I1008 10:24:54.612102 54999 net.cpp:150] Setting up fc7
I1008 10:24:54.612149 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.612154 54999 net.cpp:165] Memory required for data: 6827376
I1008 10:24:54.612164 54999 layer_factory.hpp:77] Creating layer relu7
I1008 10:24:54.612179 54999 net.cpp:100] Creating Layer relu7
I1008 10:24:54.612182 54999 net.cpp:434] relu7 <- fc7
I1008 10:24:54.612191 54999 net.cpp:395] relu7 -> fc7 (in-place)
I1008 10:24:54.612201 54999 net.cpp:150] Setting up relu7
I1008 10:24:54.612205 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.612208 54999 net.cpp:165] Memory required for data: 6843760
I1008 10:24:54.612211 54999 layer_factory.hpp:77] Creating layer drop7
I1008 10:24:54.612223 54999 net.cpp:100] Creating Layer drop7
I1008 10:24:54.612226 54999 net.cpp:434] drop7 <- fc7
I1008 10:24:54.612231 54999 net.cpp:395] drop7 -> fc7 (in-place)
I1008 10:24:54.612252 54999 net.cpp:150] Setting up drop7
I1008 10:24:54.612257 54999 net.cpp:157] Top shape: 1 4096 (4096)
I1008 10:24:54.612260 54999 net.cpp:165] Memory required for data: 6860144
I1008 10:24:54.612263 54999 layer_factory.hpp:77] Creating layer fc8_new
I1008 10:24:54.612274 54999 net.cpp:100] Creating Layer fc8_new
I1008 10:24:54.612303 54999 net.cpp:434] fc8_new <- fc7
I1008 10:24:54.612310 54999 net.cpp:408] fc8_new -> fc8
I1008 10:24:54.614876 54999 net.cpp:150] Setting up fc8_new
I1008 10:24:54.614886 54999 net.cpp:157] Top shape: 1 31 (31)
I1008 10:24:54.614888 54999 net.cpp:165] Memory required for data: 6860268
I1008 10:24:54.614893 54999 layer_factory.hpp:77] Creating layer accuracy
I1008 10:24:54.614902 54999 net.cpp:100] Creating Layer accuracy
I1008 10:24:54.614907 54999 net.cpp:434] accuracy <- fc8
I1008 10:24:54.614910 54999 net.cpp:434] accuracy <- label
I1008 10:24:54.614915 54999 net.cpp:408] accuracy -> accuracy
I1008 10:24:54.614923 54999 net.cpp:150] Setting up accuracy
I1008 10:24:54.614928 54999 net.cpp:157] Top shape: (1)
I1008 10:24:54.614930 54999 net.cpp:165] Memory required for data: 6860272
I1008 10:24:54.614933 54999 net.cpp:228] accuracy does not need backward computation.
I1008 10:24:54.614936 54999 net.cpp:228] fc8_new does not need backward computation.
I1008 10:24:54.614940 54999 net.cpp:228] drop7 does not need backward computation.
I1008 10:24:54.614943 54999 net.cpp:228] relu7 does not need backward computation.
I1008 10:24:54.614945 54999 net.cpp:228] fc7 does not need backward computation.
I1008 10:24:54.614949 54999 net.cpp:228] drop6 does not need backward computation.
I1008 10:24:54.614953 54999 net.cpp:228] relu6 does not need backward computation.
I1008 10:24:54.614955 54999 net.cpp:228] fc6 does not need backward computation.
I1008 10:24:54.614959 54999 net.cpp:228] pool5 does not need backward computation.
I1008 10:24:54.614962 54999 net.cpp:228] relu5 does not need backward computation.
I1008 10:24:54.614965 54999 net.cpp:228] conv5 does not need backward computation.
I1008 10:24:54.614969 54999 net.cpp:228] relu4 does not need backward computation.
I1008 10:24:54.614975 54999 net.cpp:228] conv4 does not need backward computation.
I1008 10:24:54.614979 54999 net.cpp:228] relu3 does not need backward computation.
I1008 10:24:54.614981 54999 net.cpp:228] conv3 does not need backward computation.
I1008 10:24:54.614985 54999 net.cpp:228] norm2 does not need backward computation.
I1008 10:24:54.614989 54999 net.cpp:228] pool2 does not need backward computation.
I1008 10:24:54.614991 54999 net.cpp:228] relu2 does not need backward computation.
I1008 10:24:54.614995 54999 net.cpp:228] conv2 does not need backward computation.
I1008 10:24:54.615000 54999 net.cpp:228] norm1 does not need backward computation.
I1008 10:24:54.615002 54999 net.cpp:228] pool1 does not need backward computation.
I1008 10:24:54.615005 54999 net.cpp:228] relu1 does not need backward computation.
I1008 10:24:54.615010 54999 net.cpp:228] conv1 does not need backward computation.
I1008 10:24:54.615013 54999 net.cpp:228] test_data does not need backward computation.
I1008 10:24:54.615018 54999 net.cpp:270] This network produces output accuracy
I1008 10:24:54.615031 54999 net.cpp:283] Network initialization done.
I1008 10:24:54.615330 54999 solver.cpp:61] Solver scaffolding done.
I1008 10:24:54.615739 54999 caffe.cpp:155] Finetuning from models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1008 10:24:54.780314 54999 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1008 10:24:54.780364 54999 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1008 10:24:54.780371 54999 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1008 10:24:54.780508 54999 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1008 10:24:54.997158 54999 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1008 10:24:55.040773 54999 net.cpp:761] Ignoring source layer fc8
I1008 10:24:55.040814 54999 net.cpp:761] Ignoring source layer loss
I1008 10:24:55.202518 54999 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1008 10:24:55.202594 54999 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1008 10:24:55.202597 54999 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1008 10:24:55.202605 54999 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1008 10:24:55.411936 54999 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1008 10:24:55.412791 54999 net.cpp:761] Ignoring source layer data
I1008 10:24:55.453944 54999 net.cpp:761] Ignoring source layer fc8
I1008 10:24:55.453976 54999 net.cpp:761] Ignoring source layer loss
I1008 10:24:55.457710 54999 caffe.cpp:251] Starting Optimization
I1008 10:24:55.457731 54999 solver.cpp:282] Solving amazon_to_webcam
I1008 10:24:55.457733 54999 solver.cpp:283] Learning Rate Policy: inv
I1008 10:24:55.464702 54999 solver.cpp:340] Iteration 0, Testing net (#0)
I1008 10:24:55.464720 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:24:55.464723 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:24:55.464725 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:24:55.464730 54999 net.cpp:693] Ignoring source layer data
I1008 10:24:55.501576 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:24:55.501629 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:24:55.501634 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:24:55.501638 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:24:55.501641 54999 net.cpp:693] Ignoring source layer silence
I1008 10:24:55.501643 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:24:55.501646 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:24:55.501649 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:24:55.501652 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:24:55.501655 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:24:55.501657 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:24:55.501660 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:24:55.501663 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:24:55.501667 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:24:55.501668 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:24:55.550792 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:24:59.446403 54999 solver.cpp:407]     Test net output #0: accuracy = 0.0213836
I1008 10:24:59.645731 54999 solver.cpp:231] Iteration 0, loss = 4.16855
I1008 10:24:59.645766 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:24:59.645776 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:24:59.645782 54999 solver.cpp:247]     Train net output #2: softmax_loss = 4.16855 (* 1 = 4.16855 loss)
I1008 10:24:59.645802 54999 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1008 10:26:46.778883 54999 solver.cpp:340] Iteration 500, Testing net (#0)
I1008 10:26:46.778980 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:26:46.778988 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:26:46.778991 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:26:46.778995 54999 net.cpp:693] Ignoring source layer data
I1008 10:26:46.779023 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:26:46.779031 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:26:46.779076 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:26:46.779080 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:26:46.779084 54999 net.cpp:693] Ignoring source layer silence
I1008 10:26:46.779088 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:26:46.779089 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:26:46.779093 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:26:46.779096 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:26:46.779098 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:26:46.779101 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:26:46.779104 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:26:46.779108 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:26:46.779110 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:26:46.779114 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:26:48.061249 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:26:50.884536 54999 solver.cpp:407]     Test net output #0: accuracy = 0.667925
I1008 10:26:51.066484 54999 solver.cpp:231] Iteration 500, loss = 0.292544
I1008 10:26:51.066560 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:26:51.066570 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:26:51.066579 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.292544 (* 1 = 0.292544 loss)
I1008 10:26:51.066589 54999 sgd_solver.cpp:106] Iteration 500, lr = 0.000737788
I1008 10:28:37.919634 54999 solver.cpp:340] Iteration 1000, Testing net (#0)
I1008 10:28:37.919988 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:28:37.920017 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:28:37.920027 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:28:37.920034 54999 net.cpp:693] Ignoring source layer data
I1008 10:28:37.920099 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:28:37.920117 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:28:37.920126 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:28:37.920135 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:28:37.920142 54999 net.cpp:693] Ignoring source layer silence
I1008 10:28:37.920151 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:28:37.920159 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:28:37.920167 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:28:37.920176 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:28:37.920193 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:28:37.920202 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:28:37.920208 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:28:37.920217 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:28:37.920225 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:28:37.920233 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:28:40.117389 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:28:41.865455 54999 solver.cpp:407]     Test net output #0: accuracy = 0.695597
I1008 10:28:42.048094 54999 solver.cpp:231] Iteration 1000, loss = 0.307064
I1008 10:28:42.048188 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:28:42.048207 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:28:42.048231 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.307064 (* 1 = 0.307064 loss)
I1008 10:28:42.048259 54999 sgd_solver.cpp:106] Iteration 1000, lr = 0.000594604
I1008 10:30:29.914047 54999 solver.cpp:340] Iteration 1500, Testing net (#0)
I1008 10:30:29.914374 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:30:29.914399 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:30:29.914404 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:30:29.914407 54999 net.cpp:693] Ignoring source layer data
I1008 10:30:29.914582 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:30:29.914602 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:30:29.914608 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:30:29.914610 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:30:29.914613 54999 net.cpp:693] Ignoring source layer silence
I1008 10:30:29.914616 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:30:29.914620 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:30:29.914623 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:30:29.914626 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:30:29.914629 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:30:29.914633 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:30:29.914636 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:30:29.914639 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:30:29.914643 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:30:29.914646 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:30:33.082861 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:30:33.854643 54999 solver.cpp:407]     Test net output #0: accuracy = 0.70566
I1008 10:30:34.034855 54999 solver.cpp:231] Iteration 1500, loss = 0.111272
I1008 10:30:34.034927 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:30:34.034940 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:30:34.034948 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.111272 (* 1 = 0.111272 loss)
I1008 10:30:34.034961 54999 sgd_solver.cpp:106] Iteration 1500, lr = 0.000502973
I1008 10:32:22.057905 54999 solver.cpp:340] Iteration 2000, Testing net (#0)
I1008 10:32:22.058145 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:32:22.058172 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:32:22.058182 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:32:22.058192 54999 net.cpp:693] Ignoring source layer data
I1008 10:32:22.058249 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:32:22.058267 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:32:22.058276 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:32:22.058285 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:32:22.058293 54999 net.cpp:693] Ignoring source layer silence
I1008 10:32:22.058301 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:32:22.058317 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:32:22.058327 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:32:22.058334 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:32:22.058342 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:32:22.058351 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:32:22.058359 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:32:22.058367 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:32:22.058375 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:32:22.058383 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:32:26.020936 54999 solver.cpp:407]     Test net output #0: accuracy = 0.722013
I1008 10:32:26.198750 54999 solver.cpp:231] Iteration 2000, loss = 0.163738
I1008 10:32:26.198786 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:32:26.198796 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:32:26.198804 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.163738 (* 1 = 0.163738 loss)
I1008 10:32:26.198814 54999 sgd_solver.cpp:106] Iteration 2000, lr = 0.000438691
I1008 10:34:13.272536 54999 solver.cpp:340] Iteration 2500, Testing net (#0)
I1008 10:34:13.272797 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:34:13.272825 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:34:13.272835 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:34:13.272842 54999 net.cpp:693] Ignoring source layer data
I1008 10:34:13.272905 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:34:13.272923 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:34:13.272931 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:34:13.272939 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:34:13.272948 54999 net.cpp:693] Ignoring source layer silence
I1008 10:34:13.272958 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:34:13.272965 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:34:13.272972 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:34:13.272996 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:34:13.273018 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:34:13.273026 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:34:13.273035 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:34:13.273042 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:34:13.273051 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:34:13.273059 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:34:13.607005 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:34:17.219700 54999 solver.cpp:407]     Test net output #0: accuracy = 0.725786
I1008 10:34:17.401872 54999 solver.cpp:231] Iteration 2500, loss = 0.0640802
I1008 10:34:17.401947 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:34:17.401958 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:34:17.401968 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0640801 (* 1 = 0.0640801 loss)
I1008 10:34:17.401978 54999 sgd_solver.cpp:106] Iteration 2500, lr = 0.000390795
I1008 10:36:05.403988 54999 solver.cpp:340] Iteration 3000, Testing net (#0)
I1008 10:36:05.404227 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:36:05.404250 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:36:05.404261 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:36:05.404269 54999 net.cpp:693] Ignoring source layer data
I1008 10:36:05.404327 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:36:05.404342 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:36:05.404353 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:36:05.404362 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:36:05.404371 54999 net.cpp:693] Ignoring source layer silence
I1008 10:36:05.404379 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:36:05.404389 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:36:05.404397 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:36:05.404405 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:36:05.404412 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:36:05.404422 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:36:05.404459 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:36:05.404469 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:36:05.404476 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:36:05.404486 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:36:06.878494 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:36:09.344069 54999 solver.cpp:407]     Test net output #0: accuracy = 0.719497
I1008 10:36:09.526273 54999 solver.cpp:231] Iteration 3000, loss = 0.0688812
I1008 10:36:09.526356 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:36:09.526372 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:36:09.526386 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0688811 (* 1 = 0.0688811 loss)
I1008 10:36:09.526402 54999 sgd_solver.cpp:106] Iteration 3000, lr = 0.000353553
I1008 10:37:57.601836 54999 solver.cpp:340] Iteration 3500, Testing net (#0)
I1008 10:37:57.602108 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:37:57.602141 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:37:57.602157 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:37:57.602174 54999 net.cpp:693] Ignoring source layer data
I1008 10:37:57.602248 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:37:57.602268 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:37:57.602290 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:37:57.602306 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:37:57.602325 54999 net.cpp:693] Ignoring source layer silence
I1008 10:37:57.602339 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:37:57.602354 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:37:57.602370 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:37:57.602382 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:37:57.602396 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:37:57.602409 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:37:57.602424 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:37:57.602438 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:37:57.602452 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:37:57.602464 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:37:59.983614 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:38:01.529310 54999 solver.cpp:407]     Test net output #0: accuracy = 0.722013
I1008 10:38:01.706598 54999 solver.cpp:231] Iteration 3500, loss = 0.0589567
I1008 10:38:01.706630 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:38:01.706642 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:38:01.706650 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0589566 (* 1 = 0.0589566 loss)
I1008 10:38:01.706657 54999 sgd_solver.cpp:106] Iteration 3500, lr = 0.000323661
I1008 10:39:49.846330 54999 solver.cpp:340] Iteration 4000, Testing net (#0)
I1008 10:39:49.846557 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:39:49.846585 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:39:49.846593 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:39:49.846601 54999 net.cpp:693] Ignoring source layer data
I1008 10:39:49.846709 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:39:49.846727 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:39:49.846736 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:39:49.846782 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:39:49.846793 54999 net.cpp:693] Ignoring source layer silence
I1008 10:39:49.846801 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:39:49.846809 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:39:49.846817 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:39:49.846827 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:39:49.846834 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:39:49.846843 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:39:49.846849 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:39:49.846859 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:39:49.846868 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:39:49.846875 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:39:53.251977 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:39:53.827795 54999 solver.cpp:407]     Test net output #0: accuracy = 0.732075
I1008 10:39:54.012720 54999 solver.cpp:231] Iteration 4000, loss = 0.0631046
I1008 10:39:54.012786 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:39:54.012799 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:39:54.012806 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0631045 (* 1 = 0.0631045 loss)
I1008 10:39:54.012820 54999 sgd_solver.cpp:106] Iteration 4000, lr = 0.00029907
I1008 10:41:40.929297 54999 solver.cpp:340] Iteration 4500, Testing net (#0)
I1008 10:41:40.929512 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:41:40.929540 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:41:40.929549 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:41:40.929558 54999 net.cpp:693] Ignoring source layer data
I1008 10:41:40.929621 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:41:40.929639 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:41:40.929649 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:41:40.929656 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:41:40.929664 54999 net.cpp:693] Ignoring source layer silence
I1008 10:41:40.929674 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:41:40.929682 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:41:40.929689 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:41:40.929697 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:41:40.929708 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:41:40.929714 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:41:40.929723 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:41:40.929729 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:41:40.929739 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:41:40.929747 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:41:44.952981 54999 solver.cpp:407]     Test net output #0: accuracy = 0.734591
I1008 10:41:45.136049 54999 solver.cpp:231] Iteration 4500, loss = 0.0870402
I1008 10:41:45.136124 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:41:45.136137 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:41:45.136144 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0870401 (* 1 = 0.0870401 loss)
I1008 10:41:45.136158 54999 sgd_solver.cpp:106] Iteration 4500, lr = 0.000278438
I1008 10:43:32.692469 54999 solver.cpp:340] Iteration 5000, Testing net (#0)
I1008 10:43:32.692708 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:43:32.692764 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:43:32.692775 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:43:32.692785 54999 net.cpp:693] Ignoring source layer data
I1008 10:43:32.692849 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:43:32.692865 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:43:32.692874 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:43:32.692883 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:43:32.692891 54999 net.cpp:693] Ignoring source layer silence
I1008 10:43:32.692899 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:43:32.692908 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:43:32.692917 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:43:32.692924 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:43:32.692932 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:43:32.692940 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:43:32.692950 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:43:32.692957 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:43:32.692965 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:43:32.692972 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:43:33.373816 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:43:36.735625 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 10:43:36.918673 54999 solver.cpp:231] Iteration 5000, loss = 0.0638121
I1008 10:43:36.918740 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:43:36.918752 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:43:36.918761 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.063812 (* 1 = 0.063812 loss)
I1008 10:43:36.918774 54999 sgd_solver.cpp:106] Iteration 5000, lr = 0.000260847
I1008 10:45:25.292099 54999 solver.cpp:340] Iteration 5500, Testing net (#0)
I1008 10:45:25.292338 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:45:25.292366 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:45:25.292374 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:45:25.292382 54999 net.cpp:693] Ignoring source layer data
I1008 10:45:25.292443 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:45:25.292459 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:45:25.292467 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:45:25.292475 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:45:25.292485 54999 net.cpp:693] Ignoring source layer silence
I1008 10:45:25.292501 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:45:25.292510 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:45:25.292526 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:45:25.292536 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:45:25.292543 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:45:25.292551 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:45:25.292559 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:45:25.292568 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:45:25.292577 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:45:25.292584 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:45:26.901600 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:45:29.547219 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74088
I1008 10:45:29.727566 54999 solver.cpp:231] Iteration 5500, loss = 0.0301231
I1008 10:45:29.727624 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:45:29.727636 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:45:29.727645 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.030123 (* 1 = 0.030123 loss)
I1008 10:45:29.727660 54999 sgd_solver.cpp:106] Iteration 5500, lr = 0.000245649
I1008 10:47:16.806422 54999 solver.cpp:340] Iteration 6000, Testing net (#0)
I1008 10:47:16.806669 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:47:16.806699 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:47:16.806707 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:47:16.806715 54999 net.cpp:693] Ignoring source layer data
I1008 10:47:16.806772 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:47:16.806789 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:47:16.806798 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:47:16.806807 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:47:16.806814 54999 net.cpp:693] Ignoring source layer silence
I1008 10:47:16.806824 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:47:16.806831 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:47:16.806850 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:47:16.806859 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:47:16.806867 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:47:16.806875 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:47:16.806884 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:47:16.806890 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:47:16.806900 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:47:16.806908 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:47:19.438256 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:47:20.805186 54999 solver.cpp:407]     Test net output #0: accuracy = 0.748428
I1008 10:47:20.987865 54999 solver.cpp:231] Iteration 6000, loss = 0.0308512
I1008 10:47:20.987941 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:47:20.987953 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:47:20.987962 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0308512 (* 1 = 0.0308512 loss)
I1008 10:47:20.987973 54999 sgd_solver.cpp:106] Iteration 6000, lr = 0.000232368
I1008 10:49:08.644178 54999 solver.cpp:340] Iteration 6500, Testing net (#0)
I1008 10:49:08.644418 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:49:08.644441 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:49:08.644453 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:49:08.644461 54999 net.cpp:693] Ignoring source layer data
I1008 10:49:08.644556 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:49:08.644574 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:49:08.644584 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:49:08.644593 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:49:08.644600 54999 net.cpp:693] Ignoring source layer silence
I1008 10:49:08.644608 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:49:08.644618 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:49:08.644625 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:49:08.644634 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:49:08.644642 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:49:08.644660 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:49:08.644670 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:49:08.644711 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:49:08.644721 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:49:08.644732 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:49:12.253203 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:49:12.636895 54999 solver.cpp:407]     Test net output #0: accuracy = 0.737107
I1008 10:49:12.818315 54999 solver.cpp:231] Iteration 6500, loss = 0.0352825
I1008 10:49:12.818392 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:49:12.818403 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:49:12.818413 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0352825 (* 1 = 0.0352825 loss)
I1008 10:49:12.818423 54999 sgd_solver.cpp:106] Iteration 6500, lr = 0.00022065
I1008 10:51:00.939601 54999 solver.cpp:340] Iteration 7000, Testing net (#0)
I1008 10:51:00.939752 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:51:00.939761 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:51:00.939764 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:51:00.939769 54999 net.cpp:693] Ignoring source layer data
I1008 10:51:00.939946 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:51:00.939968 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:51:00.939975 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:51:00.939978 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:51:00.939982 54999 net.cpp:693] Ignoring source layer silence
I1008 10:51:00.939985 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:51:00.939988 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:51:00.939991 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:51:00.939995 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:51:00.939997 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:51:00.939999 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:51:00.940003 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:51:00.940006 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:51:00.940008 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:51:00.940011 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:51:05.299810 54999 solver.cpp:407]     Test net output #0: accuracy = 0.743396
I1008 10:51:05.483225 54999 solver.cpp:231] Iteration 7000, loss = 0.0813437
I1008 10:51:05.483291 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:51:05.483304 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:51:05.483312 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0813436 (* 1 = 0.0813436 loss)
I1008 10:51:05.483328 54999 sgd_solver.cpp:106] Iteration 7000, lr = 0.000210224
I1008 10:52:53.239552 54999 solver.cpp:340] Iteration 7500, Testing net (#0)
I1008 10:52:53.239791 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:52:53.239822 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:52:53.239832 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:52:53.239840 54999 net.cpp:693] Ignoring source layer data
I1008 10:52:53.239907 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:52:53.239924 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:52:53.239933 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:52:53.239941 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:52:53.239971 54999 net.cpp:693] Ignoring source layer silence
I1008 10:52:53.239986 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:52:53.240069 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:52:53.240080 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:52:53.240088 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:52:53.240105 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:52:53.240113 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:52:53.240120 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:52:53.240128 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:52:53.240139 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:52:53.240149 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:52:54.184907 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:52:57.192610 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 10:52:57.376336 54999 solver.cpp:231] Iteration 7500, loss = 0.0437897
I1008 10:52:57.376415 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:52:57.376426 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:52:57.376435 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0437897 (* 1 = 0.0437897 loss)
I1008 10:52:57.376446 54999 sgd_solver.cpp:106] Iteration 7500, lr = 0.00020088
I1008 10:54:44.804920 54999 solver.cpp:340] Iteration 8000, Testing net (#0)
I1008 10:54:44.805184 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:54:44.805214 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:54:44.805225 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:54:44.805233 54999 net.cpp:693] Ignoring source layer data
I1008 10:54:44.805462 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:54:44.805521 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:54:44.805538 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:54:44.805546 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:54:44.805559 54999 net.cpp:693] Ignoring source layer silence
I1008 10:54:44.805570 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:54:44.805580 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:54:44.805588 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:54:44.805595 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:54:44.805603 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:54:44.805614 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:54:44.805644 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:54:44.805652 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:54:44.805660 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:54:44.805670 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:54:46.704390 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:54:48.845777 54999 solver.cpp:407]     Test net output #0: accuracy = 0.745912
I1008 10:54:49.027710 54999 solver.cpp:231] Iteration 8000, loss = 0.0135062
I1008 10:54:49.027786 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:54:49.027798 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:54:49.027806 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0135062 (* 1 = 0.0135062 loss)
I1008 10:54:49.027817 54999 sgd_solver.cpp:106] Iteration 8000, lr = 0.00019245
I1008 10:56:37.324189 54999 solver.cpp:340] Iteration 8500, Testing net (#0)
I1008 10:56:37.324426 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:56:37.324452 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:56:37.324498 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:56:37.324510 54999 net.cpp:693] Ignoring source layer data
I1008 10:56:37.324587 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:56:37.324604 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:56:37.324612 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:56:37.324622 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:56:37.324630 54999 net.cpp:693] Ignoring source layer silence
I1008 10:56:37.324638 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:56:37.324645 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:56:37.324656 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:56:37.324662 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:56:37.324671 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:56:37.324678 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:56:37.324687 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:56:37.324695 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:56:37.324702 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:56:37.324710 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:56:40.140203 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:56:41.274255 54999 solver.cpp:407]     Test net output #0: accuracy = 0.748428
I1008 10:56:41.456701 54999 solver.cpp:231] Iteration 8500, loss = 0.0303239
I1008 10:56:41.456778 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:56:41.456789 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:56:41.456797 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0303239 (* 1 = 0.0303239 loss)
I1008 10:56:41.456809 54999 sgd_solver.cpp:106] Iteration 8500, lr = 0.000184802
I1008 10:58:28.887696 54999 solver.cpp:340] Iteration 9000, Testing net (#0)
I1008 10:58:28.887945 54999 net.cpp:693] Ignoring source layer source_data
I1008 10:58:28.887976 54999 net.cpp:693] Ignoring source layer target_data
I1008 10:58:28.887986 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 10:58:28.887995 54999 net.cpp:693] Ignoring source layer data
I1008 10:58:28.888065 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 10:58:28.888082 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 10:58:28.888097 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 10:58:28.888104 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 10:58:28.888124 54999 net.cpp:693] Ignoring source layer silence
I1008 10:58:28.888133 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 10:58:28.888149 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 10:58:28.888156 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 10:58:28.888170 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 10:58:28.888180 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 10:58:28.888187 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 10:58:28.888195 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 10:58:28.888204 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 10:58:28.888211 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 10:58:28.888219 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 10:58:32.736781 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 10:58:32.879483 54999 solver.cpp:407]     Test net output #0: accuracy = 0.742138
I1008 10:58:33.055717 54999 solver.cpp:231] Iteration 9000, loss = 0.0511849
I1008 10:58:33.055750 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:58:33.055790 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 10:58:33.055804 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0511849 (* 1 = 0.0511849 loss)
I1008 10:58:33.055814 54999 sgd_solver.cpp:106] Iteration 9000, lr = 0.000177828
I1008 11:00:20.435595 54999 solver.cpp:340] Iteration 9500, Testing net (#0)
I1008 11:00:20.435771 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:00:20.435780 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:00:20.435782 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:00:20.435786 54999 net.cpp:693] Ignoring source layer data
I1008 11:00:20.435814 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:00:20.435822 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:00:20.435827 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:00:20.435835 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:00:20.435839 54999 net.cpp:693] Ignoring source layer silence
I1008 11:00:20.435842 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:00:20.435847 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:00:20.435849 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:00:20.435853 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:00:20.435855 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:00:20.435858 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:00:20.435861 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:00:20.435864 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:00:20.435868 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:00:20.435871 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:00:24.421341 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 11:00:24.600494 54999 solver.cpp:231] Iteration 9500, loss = 0.0564409
I1008 11:00:24.600546 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:00:24.600558 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:00:24.600566 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0564408 (* 1 = 0.0564408 loss)
I1008 11:00:24.600574 54999 sgd_solver.cpp:106] Iteration 9500, lr = 0.000171438
I1008 11:02:12.292734 54999 solver.cpp:340] Iteration 10000, Testing net (#0)
I1008 11:02:12.292929 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:02:12.292945 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:02:12.292949 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:02:12.292954 54999 net.cpp:693] Ignoring source layer data
I1008 11:02:12.292990 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:02:12.292999 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:02:12.293002 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:02:12.293006 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:02:12.293010 54999 net.cpp:693] Ignoring source layer silence
I1008 11:02:12.293015 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:02:12.293018 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:02:12.293023 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:02:12.293027 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:02:12.293031 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:02:12.293035 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:02:12.293040 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:02:12.293043 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:02:12.293068 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:02:12.293073 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:02:13.469111 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:02:16.268844 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 11:02:16.451495 54999 solver.cpp:231] Iteration 10000, loss = 0.00417522
I1008 11:02:16.451565 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:02:16.451576 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:02:16.451584 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00417516 (* 1 = 0.00417516 loss)
I1008 11:02:16.451596 54999 sgd_solver.cpp:106] Iteration 10000, lr = 0.00016556
I1008 11:04:04.713949 54999 solver.cpp:340] Iteration 10500, Testing net (#0)
I1008 11:04:04.714174 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:04:04.714192 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:04:04.714198 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:04:04.714203 54999 net.cpp:693] Ignoring source layer data
I1008 11:04:04.714246 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:04:04.714254 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:04:04.714259 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:04:04.714264 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:04:04.714270 54999 net.cpp:693] Ignoring source layer silence
I1008 11:04:04.714275 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:04:04.714280 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:04:04.714285 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:04:04.714292 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:04:04.714295 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:04:04.714300 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:04:04.714305 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:04:04.714311 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:04:04.714316 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:04:04.714321 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:04:06.823695 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:04:08.840276 54999 solver.cpp:407]     Test net output #0: accuracy = 0.744654
I1008 11:04:09.024500 54999 solver.cpp:231] Iteration 10500, loss = 0.0142111
I1008 11:04:09.024590 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:04:09.024602 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:04:09.024615 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0142111 (* 1 = 0.0142111 loss)
I1008 11:04:09.024627 54999 sgd_solver.cpp:106] Iteration 10500, lr = 0.000160131
I1008 11:05:57.556063 54999 solver.cpp:340] Iteration 11000, Testing net (#0)
I1008 11:05:57.556314 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:05:57.556342 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:05:57.556351 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:05:57.556360 54999 net.cpp:693] Ignoring source layer data
I1008 11:05:57.556424 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:05:57.556443 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:05:57.556452 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:05:57.556459 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:05:57.556474 54999 net.cpp:693] Ignoring source layer silence
I1008 11:05:57.556484 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:05:57.556524 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:05:57.556533 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:05:57.556541 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:05:57.556551 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:05:57.556560 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:05:57.556566 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:05:57.556574 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:05:57.556584 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:05:57.556592 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:06:00.886873 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:06:01.822427 54999 solver.cpp:407]     Test net output #0: accuracy = 0.748428
I1008 11:06:02.004268 54999 solver.cpp:231] Iteration 11000, loss = 0.00401919
I1008 11:06:02.004341 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:06:02.004351 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:06:02.004361 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00401911 (* 1 = 0.00401911 loss)
I1008 11:06:02.004374 54999 sgd_solver.cpp:106] Iteration 11000, lr = 0.000155101
I1008 11:07:50.027276 54999 solver.cpp:340] Iteration 11500, Testing net (#0)
I1008 11:07:50.027542 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:07:50.027570 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:07:50.027592 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:07:50.027601 54999 net.cpp:693] Ignoring source layer data
I1008 11:07:50.027659 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:07:50.027675 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:07:50.027685 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:07:50.027693 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:07:50.027701 54999 net.cpp:693] Ignoring source layer silence
I1008 11:07:50.027709 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:07:50.027726 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:07:50.027734 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:07:50.027755 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:07:50.027762 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:07:50.027779 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:07:50.027787 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:07:50.027796 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:07:50.027803 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:07:50.027812 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:07:54.118831 54999 solver.cpp:407]     Test net output #0: accuracy = 0.750943
I1008 11:07:54.296625 54999 solver.cpp:231] Iteration 11500, loss = 0.0285041
I1008 11:07:54.296696 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:07:54.296710 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:07:54.296718 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.028504 (* 1 = 0.028504 loss)
I1008 11:07:54.296730 54999 sgd_solver.cpp:106] Iteration 11500, lr = 0.000150424
I1008 11:09:41.568584 54999 solver.cpp:340] Iteration 12000, Testing net (#0)
I1008 11:09:41.568823 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:09:41.568850 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:09:41.568859 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:09:41.568898 54999 net.cpp:693] Ignoring source layer data
I1008 11:09:41.569032 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:09:41.569051 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:09:41.569061 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:09:41.569068 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:09:41.569078 54999 net.cpp:693] Ignoring source layer silence
I1008 11:09:41.569085 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:09:41.569093 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:09:41.569102 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:09:41.569110 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:09:41.569118 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:09:41.569125 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:09:41.569133 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:09:41.569144 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:09:41.569151 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:09:41.569159 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:09:41.676758 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:09:45.947196 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:09:46.130823 54999 solver.cpp:231] Iteration 12000, loss = 0.0485989
I1008 11:09:46.130888 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:09:46.130899 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:09:46.130908 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0485989 (* 1 = 0.0485989 loss)
I1008 11:09:46.130925 54999 sgd_solver.cpp:106] Iteration 12000, lr = 0.000146064
I1008 11:11:33.373353 54999 solver.cpp:340] Iteration 12500, Testing net (#0)
I1008 11:11:33.373692 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:11:33.373719 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:11:33.373728 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:11:33.373749 54999 net.cpp:693] Ignoring source layer data
I1008 11:11:33.373818 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:11:33.373838 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:11:33.373847 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:11:33.373854 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:11:33.373862 54999 net.cpp:693] Ignoring source layer silence
I1008 11:11:33.373872 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:11:33.373880 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:11:33.373888 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:11:33.373895 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:11:33.373904 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:11:33.373913 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:11:33.373920 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:11:33.373927 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:11:33.373937 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:11:33.373945 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:11:34.911605 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:11:37.874907 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 11:11:38.046774 54999 solver.cpp:231] Iteration 12500, loss = 0.0366274
I1008 11:11:38.046839 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:11:38.046850 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:11:38.046912 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0366273 (* 1 = 0.0366273 loss)
I1008 11:11:38.046929 54999 sgd_solver.cpp:106] Iteration 12500, lr = 0.000141987
I1008 11:13:25.430863 54999 solver.cpp:340] Iteration 13000, Testing net (#0)
I1008 11:13:25.431207 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:13:25.431236 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:13:25.431246 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:13:25.431254 54999 net.cpp:693] Ignoring source layer data
I1008 11:13:25.431310 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:13:25.431325 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:13:25.431335 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:13:25.431344 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:13:25.431351 54999 net.cpp:693] Ignoring source layer silence
I1008 11:13:25.431360 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:13:25.431371 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:13:25.431380 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:13:25.431397 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:13:25.431406 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:13:25.431416 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:13:25.431423 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:13:25.431432 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:13:25.431439 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:13:25.431449 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:13:27.852277 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:13:29.825896 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:13:30.007055 54999 solver.cpp:231] Iteration 13000, loss = 0.00590212
I1008 11:13:30.007120 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:13:30.007133 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:13:30.007139 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00590209 (* 1 = 0.00590209 loss)
I1008 11:13:30.007170 54999 sgd_solver.cpp:106] Iteration 13000, lr = 0.000138167
I1008 11:15:17.399683 54999 solver.cpp:340] Iteration 13500, Testing net (#0)
I1008 11:15:17.399839 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:15:17.399847 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:15:17.399850 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:15:17.399853 54999 net.cpp:693] Ignoring source layer data
I1008 11:15:17.399894 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:15:17.399902 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:15:17.399905 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:15:17.399909 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:15:17.399912 54999 net.cpp:693] Ignoring source layer silence
I1008 11:15:17.399915 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:15:17.399919 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:15:17.399922 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:15:17.399925 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:15:17.399929 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:15:17.399931 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:15:17.399935 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:15:17.399937 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:15:17.399940 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:15:17.399968 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:15:20.603799 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:15:21.357985 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:15:21.540248 54999 solver.cpp:231] Iteration 13500, loss = 0.0237253
I1008 11:15:21.540324 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:15:21.540338 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:15:21.540344 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0237252 (* 1 = 0.0237252 loss)
I1008 11:15:21.540355 54999 sgd_solver.cpp:106] Iteration 13500, lr = 0.000134578
I1008 11:17:09.958253 54999 solver.cpp:340] Iteration 14000, Testing net (#0)
I1008 11:17:09.958513 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:17:09.958536 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:17:09.958545 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:17:09.958554 54999 net.cpp:693] Ignoring source layer data
I1008 11:17:09.958619 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:17:09.958636 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:17:09.958645 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:17:09.958653 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:17:09.958663 54999 net.cpp:693] Ignoring source layer silence
I1008 11:17:09.958673 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:17:09.958681 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:17:09.958689 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:17:09.958708 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:17:09.958715 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:17:09.958724 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:17:09.958731 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:17:09.958741 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:17:09.958748 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:17:09.958756 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:17:14.048638 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 11:17:14.231722 54999 solver.cpp:231] Iteration 14000, loss = 0.0219089
I1008 11:17:14.231791 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:17:14.231806 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:17:14.231818 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0219089 (* 1 = 0.0219089 loss)
I1008 11:17:14.231840 54999 sgd_solver.cpp:106] Iteration 14000, lr = 0.000131199
I1008 11:19:01.951933 54999 solver.cpp:340] Iteration 14500, Testing net (#0)
I1008 11:19:01.952191 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:19:01.952219 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:19:01.952229 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:19:01.952236 54999 net.cpp:693] Ignoring source layer data
I1008 11:19:01.952303 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:19:01.952320 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:19:01.952332 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:19:01.952345 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:19:01.952353 54999 net.cpp:693] Ignoring source layer silence
I1008 11:19:01.952369 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:19:01.952379 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:19:01.952388 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:19:01.952426 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:19:01.952436 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:19:01.952446 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:19:01.952455 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:19:01.952462 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:19:01.952471 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:19:01.952481 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:19:02.130648 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:19:05.922576 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 11:19:06.106588 54999 solver.cpp:231] Iteration 14500, loss = 0.0627173
I1008 11:19:06.106654 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:19:06.106667 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:19:06.106674 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0627172 (* 1 = 0.0627172 loss)
I1008 11:19:06.106690 54999 sgd_solver.cpp:106] Iteration 14500, lr = 0.000128012
I1008 11:20:54.131108 54999 solver.cpp:340] Iteration 15000, Testing net (#0)
I1008 11:20:54.131404 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:20:54.131428 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:20:54.131436 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:20:54.131446 54999 net.cpp:693] Ignoring source layer data
I1008 11:20:54.131500 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:20:54.131516 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:20:54.131526 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:20:54.131536 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:20:54.131544 54999 net.cpp:693] Ignoring source layer silence
I1008 11:20:54.131552 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:20:54.131561 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:20:54.131572 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:20:54.131579 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:20:54.131587 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:20:54.131605 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:20:54.131625 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:20:54.131640 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:20:54.131649 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:20:54.131657 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:20:55.521574 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:20:58.097224 54999 solver.cpp:407]     Test net output #0: accuracy = 0.750943
I1008 11:20:58.280745 54999 solver.cpp:231] Iteration 15000, loss = 0.0110252
I1008 11:20:58.280822 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:20:58.280833 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:20:58.280841 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0110251 (* 1 = 0.0110251 loss)
I1008 11:20:58.280853 54999 sgd_solver.cpp:106] Iteration 15000, lr = 0.000125
I1008 11:22:46.380198 54999 solver.cpp:340] Iteration 15500, Testing net (#0)
I1008 11:22:46.380421 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:22:46.380448 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:22:46.380458 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:22:46.380466 54999 net.cpp:693] Ignoring source layer data
I1008 11:22:46.380565 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:22:46.380584 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:22:46.380609 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:22:46.380617 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:22:46.380627 54999 net.cpp:693] Ignoring source layer silence
I1008 11:22:46.380635 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:22:46.380642 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:22:46.380650 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:22:46.380659 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:22:46.380667 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:22:46.380674 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:22:46.380682 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:22:46.380692 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:22:46.380699 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:22:46.380707 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:22:48.768038 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:22:50.417058 54999 solver.cpp:407]     Test net output #0: accuracy = 0.748428
I1008 11:22:50.594928 54999 solver.cpp:231] Iteration 15500, loss = 0.007471
I1008 11:22:50.594964 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:22:50.594974 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:22:50.594983 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00747096 (* 1 = 0.00747096 loss)
I1008 11:22:50.594990 54999 sgd_solver.cpp:106] Iteration 15500, lr = 0.000122148
I1008 11:24:38.755491 54999 solver.cpp:340] Iteration 16000, Testing net (#0)
I1008 11:24:38.755771 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:24:38.755803 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:24:38.755812 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:24:38.755821 54999 net.cpp:693] Ignoring source layer data
I1008 11:24:38.756048 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:24:38.756081 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:24:38.756093 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:24:38.756103 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:24:38.756110 54999 net.cpp:693] Ignoring source layer silence
I1008 11:24:38.756119 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:24:38.756127 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:24:38.756135 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:24:38.756144 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:24:38.756152 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:24:38.756160 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:24:38.756168 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:24:38.756175 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:24:38.756186 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:24:38.756193 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:24:42.010213 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:24:42.717603 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 11:24:42.900369 54999 solver.cpp:231] Iteration 16000, loss = 0.0130087
I1008 11:24:42.900436 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:24:42.900447 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:24:42.900498 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0130087 (* 1 = 0.0130087 loss)
I1008 11:24:42.900511 54999 sgd_solver.cpp:106] Iteration 16000, lr = 0.000119444
I1008 11:26:29.895050 54999 solver.cpp:340] Iteration 16500, Testing net (#0)
I1008 11:26:29.895342 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:26:29.895370 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:26:29.895380 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:26:29.895388 54999 net.cpp:693] Ignoring source layer data
I1008 11:26:29.895444 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:26:29.895462 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:26:29.895473 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:26:29.895480 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:26:29.895488 54999 net.cpp:693] Ignoring source layer silence
I1008 11:26:29.895495 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:26:29.895505 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:26:29.895525 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:26:29.895532 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:26:29.895540 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:26:29.895550 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:26:29.895557 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:26:29.895567 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:26:29.895576 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:26:29.895584 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:26:33.860589 54999 solver.cpp:407]     Test net output #0: accuracy = 0.745912
I1008 11:26:34.042630 54999 solver.cpp:231] Iteration 16500, loss = 0.0132934
I1008 11:26:34.042711 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:26:34.042729 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:26:34.042743 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0132934 (* 1 = 0.0132934 loss)
I1008 11:26:34.042759 54999 sgd_solver.cpp:106] Iteration 16500, lr = 0.000116875
I1008 11:28:22.120862 54999 solver.cpp:340] Iteration 17000, Testing net (#0)
I1008 11:28:22.121003 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:28:22.121011 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:28:22.121013 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:28:22.121016 54999 net.cpp:693] Ignoring source layer data
I1008 11:28:22.121043 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:28:22.121050 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:28:22.121053 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:28:22.121057 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:28:22.121062 54999 net.cpp:693] Ignoring source layer silence
I1008 11:28:22.121067 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:28:22.121073 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:28:22.121076 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:28:22.121080 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:28:22.121083 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:28:22.121086 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:28:22.121089 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:28:22.121093 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:28:22.121096 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:28:22.121099 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:28:22.585743 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:28:26.076058 54999 solver.cpp:407]     Test net output #0: accuracy = 0.750943
I1008 11:28:26.257834 54999 solver.cpp:231] Iteration 17000, loss = 0.00868411
I1008 11:28:26.257910 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:28:26.257921 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:28:26.257930 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00868406 (* 1 = 0.00868406 loss)
I1008 11:28:26.257941 54999 sgd_solver.cpp:106] Iteration 17000, lr = 0.000114432
I1008 11:30:13.448130 54999 solver.cpp:340] Iteration 17500, Testing net (#0)
I1008 11:30:13.448390 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:30:13.448428 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:30:13.448437 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:30:13.448446 54999 net.cpp:693] Ignoring source layer data
I1008 11:30:13.448506 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:30:13.448523 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:30:13.448532 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:30:13.448540 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:30:13.448547 54999 net.cpp:693] Ignoring source layer silence
I1008 11:30:13.448568 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:30:13.448576 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:30:13.448585 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:30:13.448592 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:30:13.448601 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:30:13.448609 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:30:13.448617 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:30:13.448626 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:30:13.448634 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:30:13.448642 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:30:14.975018 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:30:17.410851 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:30:17.588793 54999 solver.cpp:231] Iteration 17500, loss = 0.0151544
I1008 11:30:17.588827 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:30:17.588838 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:30:17.588848 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0151543 (* 1 = 0.0151543 loss)
I1008 11:30:17.588856 54999 sgd_solver.cpp:106] Iteration 17500, lr = 0.000112104
I1008 11:32:04.869874 54999 solver.cpp:340] Iteration 18000, Testing net (#0)
I1008 11:32:04.869976 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:32:04.869982 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:32:04.869987 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:32:04.869989 54999 net.cpp:693] Ignoring source layer data
I1008 11:32:04.870015 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:32:04.870024 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:32:04.870030 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:32:04.870033 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:32:04.870036 54999 net.cpp:693] Ignoring source layer silence
I1008 11:32:04.870039 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:32:04.870043 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:32:04.870046 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:32:04.870084 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:32:04.870088 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:32:04.870092 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:32:04.870095 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:32:04.870098 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:32:04.870101 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:32:04.870105 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:32:07.586354 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:32:09.076436 54999 solver.cpp:407]     Test net output #0: accuracy = 0.753459
I1008 11:32:09.260362 54999 solver.cpp:231] Iteration 18000, loss = 0.0175745
I1008 11:32:09.260440 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:32:09.260452 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:32:09.260460 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0175745 (* 1 = 0.0175745 loss)
I1008 11:32:09.260471 54999 sgd_solver.cpp:106] Iteration 18000, lr = 0.000109884
I1008 11:33:57.683212 54999 solver.cpp:340] Iteration 18500, Testing net (#0)
I1008 11:33:57.683470 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:33:57.683493 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:33:57.683503 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:33:57.683513 54999 net.cpp:693] Ignoring source layer data
I1008 11:33:57.683759 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:33:57.683797 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:33:57.683809 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:33:57.683820 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:33:57.683828 54999 net.cpp:693] Ignoring source layer silence
I1008 11:33:57.683836 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:33:57.683843 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:33:57.683853 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:33:57.683861 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:33:57.683869 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:33:57.683877 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:33:57.683887 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:33:57.683894 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:33:57.683902 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:33:57.683910 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:34:01.254240 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:34:01.754299 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:34:01.932627 54999 solver.cpp:231] Iteration 18500, loss = 0.00612563
I1008 11:34:01.932706 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:34:01.932718 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:34:01.932724 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00612562 (* 1 = 0.00612562 loss)
I1008 11:34:01.932734 54999 sgd_solver.cpp:106] Iteration 18500, lr = 0.000107764
I1008 11:35:50.090852 54999 solver.cpp:340] Iteration 19000, Testing net (#0)
I1008 11:35:50.091053 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:35:50.091080 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:35:50.091090 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:35:50.091097 54999 net.cpp:693] Ignoring source layer data
I1008 11:35:50.091217 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:35:50.091235 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:35:50.091245 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:35:50.091253 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:35:50.091262 54999 net.cpp:693] Ignoring source layer silence
I1008 11:35:50.091270 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:35:50.091277 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:35:50.091285 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:35:50.091295 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:35:50.091302 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:35:50.091310 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:35:50.091317 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:35:50.091327 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:35:50.091334 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:35:50.091342 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:35:54.181820 54999 solver.cpp:407]     Test net output #0: accuracy = 0.74717
I1008 11:35:54.364369 54999 solver.cpp:231] Iteration 19000, loss = 0.0105655
I1008 11:35:54.364434 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:35:54.364446 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:35:54.364454 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0105655 (* 1 = 0.0105655 loss)
I1008 11:35:54.364483 54999 sgd_solver.cpp:106] Iteration 19000, lr = 0.000105737
I1008 11:37:42.703505 54999 solver.cpp:340] Iteration 19500, Testing net (#0)
I1008 11:37:42.703791 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:37:42.703827 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:37:42.703838 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:37:42.703845 54999 net.cpp:693] Ignoring source layer data
I1008 11:37:42.703912 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:37:42.703925 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:37:42.703933 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:37:42.703939 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:37:42.703945 54999 net.cpp:693] Ignoring source layer silence
I1008 11:37:42.703950 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:37:42.703958 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:37:42.703975 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:37:42.703981 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:37:42.703987 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:37:42.703994 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:37:42.704000 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:37:42.704006 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:37:42.704012 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:37:42.704020 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:37:43.516085 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:37:46.773365 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:37:46.955368 54999 solver.cpp:231] Iteration 19500, loss = 0.0111962
I1008 11:37:46.955442 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:37:46.955454 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:37:46.955462 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0111962 (* 1 = 0.0111962 loss)
I1008 11:37:46.955503 54999 sgd_solver.cpp:106] Iteration 19500, lr = 0.000103797
I1008 11:39:35.156275 54999 solver.cpp:340] Iteration 20000, Testing net (#0)
I1008 11:39:35.156563 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:39:35.156594 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:39:35.156607 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:39:35.156621 54999 net.cpp:693] Ignoring source layer data
I1008 11:39:35.156687 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:39:35.156704 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:39:35.156716 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:39:35.156728 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:39:35.156740 54999 net.cpp:693] Ignoring source layer silence
I1008 11:39:35.156756 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:39:35.156769 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:39:35.156781 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:39:35.156793 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:39:35.156805 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:39:35.156816 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:39:35.156829 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:39:35.156841 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:39:35.156852 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:39:35.156863 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:39:37.043781 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:39:39.536392 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 11:39:39.715171 54999 solver.cpp:231] Iteration 20000, loss = 0.00544209
I1008 11:39:39.715241 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:39:39.715253 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:39:39.715260 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00544212 (* 1 = 0.00544212 loss)
I1008 11:39:39.715270 54999 sgd_solver.cpp:106] Iteration 20000, lr = 0.000101938
I1008 11:41:27.166226 54999 solver.cpp:340] Iteration 20500, Testing net (#0)
I1008 11:41:27.166458 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:41:27.166486 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:41:27.166496 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:41:27.166503 54999 net.cpp:693] Ignoring source layer data
I1008 11:41:27.166568 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:41:27.166584 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:41:27.166592 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:41:27.166600 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:41:27.166610 54999 net.cpp:693] Ignoring source layer silence
I1008 11:41:27.166621 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:41:27.166630 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:41:27.166646 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:41:27.166656 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:41:27.166663 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:41:27.166671 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:41:27.166678 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:41:27.166688 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:41:27.166695 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:41:27.166703 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:41:30.073626 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:41:31.471017 54999 solver.cpp:407]     Test net output #0: accuracy = 0.758491
I1008 11:41:31.655087 54999 solver.cpp:231] Iteration 20500, loss = 0.010926
I1008 11:41:31.655177 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:41:31.655197 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:41:31.655218 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.010926 (* 1 = 0.010926 loss)
I1008 11:41:31.655238 54999 sgd_solver.cpp:106] Iteration 20500, lr = 0.000100155
I1008 11:43:19.179808 54999 solver.cpp:340] Iteration 21000, Testing net (#0)
I1008 11:43:19.180083 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:43:19.180111 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:43:19.180125 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:43:19.180133 54999 net.cpp:693] Ignoring source layer data
I1008 11:43:19.180193 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:43:19.180213 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:43:19.180222 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:43:19.180232 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:43:19.180239 54999 net.cpp:693] Ignoring source layer silence
I1008 11:43:19.180249 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:43:19.180258 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:43:19.180265 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:43:19.180274 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:43:19.180284 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:43:19.180290 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:43:19.180299 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:43:19.180306 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:43:19.180315 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:43:19.180325 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:43:22.861353 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:43:23.175384 54999 solver.cpp:407]     Test net output #0: accuracy = 0.758491
I1008 11:43:23.358566 54999 solver.cpp:231] Iteration 21000, loss = 0.0376768
I1008 11:43:23.358635 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:43:23.358646 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:43:23.358654 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0376768 (* 1 = 0.0376768 loss)
I1008 11:43:23.358664 54999 sgd_solver.cpp:106] Iteration 21000, lr = 9.84426e-05
I1008 11:45:10.617367 54999 solver.cpp:340] Iteration 21500, Testing net (#0)
I1008 11:45:10.617534 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:45:10.617543 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:45:10.617547 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:45:10.617552 54999 net.cpp:693] Ignoring source layer data
I1008 11:45:10.617709 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:45:10.617733 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:45:10.617738 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:45:10.617741 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:45:10.617744 54999 net.cpp:693] Ignoring source layer silence
I1008 11:45:10.617748 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:45:10.617750 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:45:10.617753 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:45:10.617756 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:45:10.617796 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:45:10.617800 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:45:10.617804 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:45:10.617806 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:45:10.617810 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:45:10.617812 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:45:14.560871 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 11:45:14.743335 54999 solver.cpp:231] Iteration 21500, loss = 0.0204528
I1008 11:45:14.743410 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:45:14.743422 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:45:14.743430 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0204528 (* 1 = 0.0204528 loss)
I1008 11:45:14.743440 54999 sgd_solver.cpp:106] Iteration 21500, lr = 9.67973e-05
I1008 11:47:02.572046 54999 solver.cpp:340] Iteration 22000, Testing net (#0)
I1008 11:47:02.572270 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:47:02.572299 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:47:02.572309 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:47:02.572315 54999 net.cpp:693] Ignoring source layer data
I1008 11:47:02.572422 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:47:02.572440 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:47:02.572459 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:47:02.572468 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:47:02.572486 54999 net.cpp:693] Ignoring source layer silence
I1008 11:47:02.572494 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:47:02.572501 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:47:02.572510 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:47:02.572520 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:47:02.572527 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:47:02.572535 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:47:02.572542 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:47:02.572552 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:47:02.572561 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:47:02.572568 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:47:03.576118 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:47:06.504931 54999 solver.cpp:407]     Test net output #0: accuracy = 0.757233
I1008 11:47:06.686265 54999 solver.cpp:231] Iteration 22000, loss = 0.0325942
I1008 11:47:06.686333 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:47:06.686344 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:47:06.686353 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0325942 (* 1 = 0.0325942 loss)
I1008 11:47:06.686363 54999 sgd_solver.cpp:106] Iteration 22000, lr = 9.52147e-05
I1008 11:48:54.981798 54999 solver.cpp:340] Iteration 22500, Testing net (#0)
I1008 11:48:54.982048 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:48:54.982077 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:48:54.982086 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:48:54.982095 54999 net.cpp:693] Ignoring source layer data
I1008 11:48:54.982331 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:48:54.982367 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:48:54.982403 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:48:54.982412 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:48:54.982420 54999 net.cpp:693] Ignoring source layer silence
I1008 11:48:54.982430 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:48:54.982437 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:48:54.982445 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:48:54.982453 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:48:54.982462 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:48:54.982470 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:48:54.982478 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:48:54.982486 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:48:54.982496 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:48:54.982504 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:48:56.862834 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:48:58.915411 54999 solver.cpp:407]     Test net output #0: accuracy = 0.761006
I1008 11:48:59.097637 54999 solver.cpp:231] Iteration 22500, loss = 0.0141047
I1008 11:48:59.097707 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:48:59.097718 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:48:59.097725 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0141047 (* 1 = 0.0141047 loss)
I1008 11:48:59.097736 54999 sgd_solver.cpp:106] Iteration 22500, lr = 9.36913e-05
I1008 11:50:46.981871 54999 solver.cpp:340] Iteration 23000, Testing net (#0)
I1008 11:50:46.982079 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:50:46.982112 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:50:46.982131 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:50:46.982144 54999 net.cpp:693] Ignoring source layer data
I1008 11:50:46.982216 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:50:46.982236 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:50:46.982251 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:50:46.982264 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:50:46.982276 54999 net.cpp:693] Ignoring source layer silence
I1008 11:50:46.982290 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:50:46.982306 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:50:46.982318 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:50:46.982331 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:50:46.982344 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:50:46.982359 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:50:46.982372 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:50:46.982386 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:50:46.982399 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:50:46.982415 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:50:50.071940 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:50:51.224054 54999 solver.cpp:407]     Test net output #0: accuracy = 0.755975
I1008 11:50:51.403206 54999 solver.cpp:231] Iteration 23000, loss = 0.00392876
I1008 11:50:51.403249 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:50:51.403259 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:50:51.403267 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00392872 (* 1 = 0.00392872 loss)
I1008 11:50:51.403291 54999 sgd_solver.cpp:106] Iteration 23000, lr = 9.22235e-05
I1008 11:52:39.301839 54999 solver.cpp:340] Iteration 23500, Testing net (#0)
I1008 11:52:39.302019 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:52:39.302026 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:52:39.302029 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:52:39.302033 54999 net.cpp:693] Ignoring source layer data
I1008 11:52:39.302063 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:52:39.302069 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:52:39.302074 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:52:39.302080 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:52:39.302084 54999 net.cpp:693] Ignoring source layer silence
I1008 11:52:39.302088 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:52:39.302090 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:52:39.302093 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:52:39.302098 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:52:39.302100 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:52:39.302103 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:52:39.302106 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:52:39.302110 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:52:39.302114 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:52:39.302116 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:52:43.326038 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:52:43.396189 54999 solver.cpp:407]     Test net output #0: accuracy = 0.758491
I1008 11:52:43.573001 54999 solver.cpp:231] Iteration 23500, loss = 0.0049673
I1008 11:52:43.573053 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:52:43.573065 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:52:43.573074 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00496724 (* 1 = 0.00496724 loss)
I1008 11:52:43.573082 54999 sgd_solver.cpp:106] Iteration 23500, lr = 9.08083e-05
I1008 11:54:31.120446 54999 solver.cpp:340] Iteration 24000, Testing net (#0)
I1008 11:54:31.120581 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:54:31.120591 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:54:31.120596 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:54:31.120600 54999 net.cpp:693] Ignoring source layer data
I1008 11:54:31.120762 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:54:31.120784 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:54:31.120788 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:54:31.120791 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:54:31.120795 54999 net.cpp:693] Ignoring source layer silence
I1008 11:54:31.120798 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:54:31.120801 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:54:31.120805 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:54:31.120807 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:54:31.120826 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:54:31.120829 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:54:31.120832 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:54:31.120851 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:54:31.120854 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:54:31.120857 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:54:35.086176 54999 solver.cpp:407]     Test net output #0: accuracy = 0.754717
I1008 11:54:35.265818 54999 solver.cpp:231] Iteration 24000, loss = 0.0112945
I1008 11:54:35.265890 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:54:35.265902 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:54:35.265909 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0112945 (* 1 = 0.0112945 loss)
I1008 11:54:35.265919 54999 sgd_solver.cpp:106] Iteration 24000, lr = 8.94427e-05
I1008 11:55:17.425773 54999 solver.cpp:457] Snapshotting to binary proto file models/JAN/alexnet/trained_model_iter_24197.caffemodel
I1008 11:55:18.652797 54999 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/JAN/alexnet/trained_model_iter_24197.solverstate
I1008 11:56:24.405773 54999 solver.cpp:340] Iteration 24500, Testing net (#0)
I1008 11:56:24.406005 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:56:24.406033 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:56:24.406040 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:56:24.406047 54999 net.cpp:693] Ignoring source layer data
I1008 11:56:24.406224 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:56:24.406249 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:56:24.406256 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:56:24.406263 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:56:24.406271 54999 net.cpp:693] Ignoring source layer silence
I1008 11:56:24.406280 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:56:24.406287 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:56:24.406294 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:56:24.406302 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:56:24.406311 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:56:24.406318 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:56:24.406325 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:56:24.406333 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:56:24.406342 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:56:24.406349 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:56:25.602622 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:56:28.436241 54999 solver.cpp:407]     Test net output #0: accuracy = 0.753459
I1008 11:56:28.612447 54999 solver.cpp:231] Iteration 24500, loss = 0.0184852
I1008 11:56:28.612527 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:56:28.612537 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:56:28.612545 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0184851 (* 1 = 0.0184851 loss)
I1008 11:56:28.612556 54999 sgd_solver.cpp:106] Iteration 24500, lr = 8.81241e-05
I1008 11:58:15.735188 54999 solver.cpp:340] Iteration 25000, Testing net (#0)
I1008 11:58:15.735394 54999 net.cpp:693] Ignoring source layer source_data
I1008 11:58:15.735416 54999 net.cpp:693] Ignoring source layer target_data
I1008 11:58:15.735426 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 11:58:15.735433 54999 net.cpp:693] Ignoring source layer data
I1008 11:58:15.735489 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 11:58:15.735502 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 11:58:15.735512 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 11:58:15.735520 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 11:58:15.735528 54999 net.cpp:693] Ignoring source layer silence
I1008 11:58:15.735536 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 11:58:15.735548 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 11:58:15.735587 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 11:58:15.735596 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 11:58:15.735615 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 11:58:15.735623 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 11:58:15.735642 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 11:58:15.735649 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 11:58:15.735657 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 11:58:15.735666 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 11:58:17.848070 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 11:58:19.761521 54999 solver.cpp:407]     Test net output #0: accuracy = 0.757233
I1008 11:58:19.939671 54999 solver.cpp:231] Iteration 25000, loss = 0.00406482
I1008 11:58:19.939731 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:58:19.939740 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 11:58:19.939749 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00406475 (* 1 = 0.00406475 loss)
I1008 11:58:19.939759 54999 sgd_solver.cpp:106] Iteration 25000, lr = 8.685e-05
I1008 12:00:06.742964 54999 solver.cpp:340] Iteration 25500, Testing net (#0)
I1008 12:00:06.743235 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:00:06.743261 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:00:06.743269 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:00:06.743279 54999 net.cpp:693] Ignoring source layer data
I1008 12:00:06.743337 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:00:06.743353 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:00:06.743362 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:00:06.743373 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:00:06.743381 54999 net.cpp:693] Ignoring source layer silence
I1008 12:00:06.743388 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:00:06.743396 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:00:06.743405 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:00:06.743412 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:00:06.743420 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:00:06.743427 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:00:06.743436 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:00:06.743444 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:00:06.743451 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:00:06.743459 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:00:09.898241 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:00:10.790693 54999 solver.cpp:407]     Test net output #0: accuracy = 0.758491
I1008 12:00:10.969265 54999 solver.cpp:231] Iteration 25500, loss = 0.00152209
I1008 12:00:10.969328 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:00:10.969338 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:00:10.969347 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00152201 (* 1 = 0.00152201 loss)
I1008 12:00:10.969357 54999 sgd_solver.cpp:106] Iteration 25500, lr = 8.56181e-05
I1008 12:01:58.484571 54999 solver.cpp:340] Iteration 26000, Testing net (#0)
I1008 12:01:58.484805 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:01:58.484830 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:01:58.484838 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:01:58.484872 54999 net.cpp:693] Ignoring source layer data
I1008 12:01:58.485018 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:01:58.485039 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:01:58.485047 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:01:58.485054 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:01:58.485064 54999 net.cpp:693] Ignoring source layer silence
I1008 12:01:58.485071 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:01:58.485079 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:01:58.485086 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:01:58.485095 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:01:58.485103 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:01:58.485110 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:01:58.485117 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:01:58.485126 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:01:58.485134 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:01:58.485142 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:02:02.772204 54999 solver.cpp:407]     Test net output #0: accuracy = 0.754717
I1008 12:02:02.948487 54999 solver.cpp:231] Iteration 26000, loss = 0.0239982
I1008 12:02:02.948520 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:02:02.948530 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:02:02.948539 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0239981 (* 1 = 0.0239981 loss)
I1008 12:02:02.948550 54999 sgd_solver.cpp:106] Iteration 26000, lr = 8.44262e-05
I1008 12:03:50.637781 54999 solver.cpp:340] Iteration 26500, Testing net (#0)
I1008 12:03:50.637997 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:03:50.638022 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:03:50.638032 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:03:50.638039 54999 net.cpp:693] Ignoring source layer data
I1008 12:03:50.638099 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:03:50.638111 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:03:50.638121 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:03:50.638128 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:03:50.638139 54999 net.cpp:693] Ignoring source layer silence
I1008 12:03:50.638170 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:03:50.638180 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:03:50.638188 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:03:50.638195 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:03:50.638203 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:03:50.638212 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:03:50.638219 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:03:50.638227 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:03:50.638236 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:03:50.638244 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:03:50.803611 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:03:54.653499 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 12:03:54.829510 54999 solver.cpp:231] Iteration 26500, loss = 0.0279245
I1008 12:03:54.829576 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:03:54.829586 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:03:54.829618 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0279244 (* 1 = 0.0279244 loss)
I1008 12:03:54.829630 54999 sgd_solver.cpp:106] Iteration 26500, lr = 8.32723e-05
I1008 12:05:42.028324 54999 solver.cpp:340] Iteration 27000, Testing net (#0)
I1008 12:05:42.028568 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:05:42.028594 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:05:42.028601 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:05:42.028611 54999 net.cpp:693] Ignoring source layer data
I1008 12:05:42.028671 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:05:42.028682 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:05:42.028690 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:05:42.028699 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:05:42.028707 54999 net.cpp:693] Ignoring source layer silence
I1008 12:05:42.028714 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:05:42.028723 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:05:42.028731 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:05:42.028739 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:05:42.028746 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:05:42.028754 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:05:42.028764 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:05:42.028770 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:05:42.028779 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:05:42.028785 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:05:43.507266 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:05:46.271536 54999 solver.cpp:407]     Test net output #0: accuracy = 0.755975
I1008 12:05:46.454380 54999 solver.cpp:231] Iteration 27000, loss = 0.0158666
I1008 12:05:46.454440 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:05:46.454450 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:05:46.454457 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0158665 (* 1 = 0.0158665 loss)
I1008 12:05:46.454471 54999 sgd_solver.cpp:106] Iteration 27000, lr = 8.21545e-05
I1008 12:07:33.449237 54999 solver.cpp:340] Iteration 27500, Testing net (#0)
I1008 12:07:33.449473 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:07:33.449497 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:07:33.449506 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:07:33.449513 54999 net.cpp:693] Ignoring source layer data
I1008 12:07:33.449594 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:07:33.449607 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:07:33.449615 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:07:33.449622 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:07:33.449631 54999 net.cpp:693] Ignoring source layer silence
I1008 12:07:33.449640 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:07:33.449646 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:07:33.449654 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:07:33.449663 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:07:33.449673 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:07:33.449681 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:07:33.449697 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:07:33.449707 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:07:33.449713 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:07:33.449749 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:07:35.818714 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:07:37.551769 54999 solver.cpp:407]     Test net output #0: accuracy = 0.748428
I1008 12:07:37.727921 54999 solver.cpp:231] Iteration 27500, loss = 0.00827323
I1008 12:07:37.727988 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:07:37.727999 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:07:37.728006 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00827312 (* 1 = 0.00827312 loss)
I1008 12:07:37.728018 54999 sgd_solver.cpp:106] Iteration 27500, lr = 8.10712e-05
I1008 12:09:25.057152 54999 solver.cpp:340] Iteration 28000, Testing net (#0)
I1008 12:09:25.057276 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:09:25.057283 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:09:25.057286 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:09:25.057288 54999 net.cpp:693] Ignoring source layer data
I1008 12:09:25.057313 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:09:25.057319 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:09:25.057322 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:09:25.057325 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:09:25.057328 54999 net.cpp:693] Ignoring source layer silence
I1008 12:09:25.057332 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:09:25.057334 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:09:25.057337 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:09:25.057339 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:09:25.057343 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:09:25.057345 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:09:25.057348 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:09:25.057350 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:09:25.057354 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:09:25.057356 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:09:28.356992 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:09:29.089749 54999 solver.cpp:407]     Test net output #0: accuracy = 0.750943
I1008 12:09:29.265887 54999 solver.cpp:231] Iteration 28000, loss = 0.0161683
I1008 12:09:29.265950 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:09:29.265960 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:09:29.265967 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0161682 (* 1 = 0.0161682 loss)
I1008 12:09:29.265980 54999 sgd_solver.cpp:106] Iteration 28000, lr = 8.00205e-05
I1008 12:11:16.570860 54999 solver.cpp:340] Iteration 28500, Testing net (#0)
I1008 12:11:16.571092 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:11:16.571117 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:11:16.571127 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:11:16.571135 54999 net.cpp:693] Ignoring source layer data
I1008 12:11:16.571216 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:11:16.571231 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:11:16.571244 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:11:16.571252 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:11:16.571260 54999 net.cpp:693] Ignoring source layer silence
I1008 12:11:16.571267 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:11:16.571276 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:11:16.571311 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:11:16.571321 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:11:16.571333 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:11:16.571342 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:11:16.571349 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:11:16.571357 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:11:16.571364 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:11:16.571373 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:11:20.669433 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 12:11:20.848084 54999 solver.cpp:231] Iteration 28500, loss = 0.0258044
I1008 12:11:20.848152 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:11:20.848163 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:11:20.848170 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0258043 (* 1 = 0.0258043 loss)
I1008 12:11:20.848179 54999 sgd_solver.cpp:106] Iteration 28500, lr = 7.90012e-05
I1008 12:13:07.832962 54999 solver.cpp:340] Iteration 29000, Testing net (#0)
I1008 12:13:07.833250 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:13:07.833276 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:13:07.833284 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:13:07.833292 54999 net.cpp:693] Ignoring source layer data
I1008 12:13:07.833557 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:13:07.833593 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:13:07.833601 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:13:07.833609 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:13:07.833618 54999 net.cpp:693] Ignoring source layer silence
I1008 12:13:07.833626 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:13:07.833633 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:13:07.833642 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:13:07.833650 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:13:07.833657 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:13:07.833665 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:13:07.833673 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:13:07.833681 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:13:07.833688 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:13:07.833696 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:13:08.293475 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:13:11.945283 54999 solver.cpp:407]     Test net output #0: accuracy = 0.752201
I1008 12:13:12.122572 54999 solver.cpp:231] Iteration 29000, loss = 0.0159888
I1008 12:13:12.122659 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:13:12.122669 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:13:12.122676 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.0159886 (* 1 = 0.0159886 loss)
I1008 12:13:12.122687 54999 sgd_solver.cpp:106] Iteration 29000, lr = 7.80116e-05
I1008 12:14:59.132194 54999 solver.cpp:340] Iteration 29500, Testing net (#0)
I1008 12:14:59.132470 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:14:59.132498 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:14:59.132505 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:14:59.132513 54999 net.cpp:693] Ignoring source layer data
I1008 12:14:59.132591 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:14:59.132606 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:14:59.132614 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:14:59.132622 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:14:59.132628 54999 net.cpp:693] Ignoring source layer silence
I1008 12:14:59.132637 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:14:59.132645 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:14:59.132652 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:14:59.132668 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:14:59.132676 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:14:59.132684 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:14:59.132691 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:14:59.132699 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:14:59.132707 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:14:59.132715 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:15:00.689471 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:15:03.378808 54999 solver.cpp:407]     Test net output #0: accuracy = 0.749686
I1008 12:15:03.555701 54999 solver.cpp:231] Iteration 29500, loss = 0.00445088
I1008 12:15:03.555732 54999 solver.cpp:247]     Train net output #0: jmmd_loss_fc7_jmmd_loss_fc7_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:15:03.555742 54999 solver.cpp:247]     Train net output #1: jmmd_loss_softmax_jmmd_loss_softmax_0_split_0 = 0 (* 0.3 = 0 loss)
I1008 12:15:03.555748 54999 solver.cpp:247]     Train net output #2: softmax_loss = 0.00445072 (* 1 = 0.00445072 loss)
I1008 12:15:03.555760 54999 sgd_solver.cpp:106] Iteration 29500, lr = 7.70504e-05
I1008 12:16:51.189230 54999 solver.cpp:320] Iteration 30000, loss = 0.0141512
I1008 12:16:51.189549 54999 solver.cpp:340] Iteration 30000, Testing net (#0)
I1008 12:16:51.189602 54999 net.cpp:693] Ignoring source layer source_data
I1008 12:16:51.189615 54999 net.cpp:693] Ignoring source layer target_data
I1008 12:16:51.189621 54999 net.cpp:693] Ignoring source layer target_label_silence
I1008 12:16:51.189630 54999 net.cpp:693] Ignoring source layer data
I1008 12:16:51.189689 54999 net.cpp:693] Ignoring source layer fc7_drop7_0_split
I1008 12:16:51.189705 54999 net.cpp:693] Ignoring source layer fc8_fc8_new_0_split
I1008 12:16:51.189713 54999 net.cpp:693] Ignoring source layer slice_fc7
I1008 12:16:51.189720 54999 net.cpp:693] Ignoring source layer slice_fc8
I1008 12:16:51.189734 54999 net.cpp:693] Ignoring source layer silence
I1008 12:16:51.189743 54999 net.cpp:693] Ignoring source layer softmax_loss
I1008 12:16:51.189750 54999 net.cpp:693] Ignoring source layer fc8_softmax
I1008 12:16:51.189759 54999 net.cpp:693] Ignoring source layer slice_softmax
I1008 12:16:51.189765 54999 net.cpp:693] Ignoring source layer source_softmax_slice_softmax_0_split
I1008 12:16:51.189775 54999 net.cpp:693] Ignoring source layer target_softmax_slice_softmax_1_split
I1008 12:16:51.189782 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7
I1008 12:16:51.189790 54999 net.cpp:693] Ignoring source layer jmmd_loss_fc7_jmmd_loss_fc7_0_split
I1008 12:16:51.189797 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax
I1008 12:16:51.189806 54999 net.cpp:693] Ignoring source layer jmmd_loss_softmax_jmmd_loss_softmax_0_split
I1008 12:16:51.189815 54999 net.cpp:693] Ignoring source layer silence_loss_value
I1008 12:16:53.658623 54999 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 12:16:55.198304 54999 solver.cpp:407]     Test net output #0: accuracy = 0.753459
I1008 12:16:55.198357 54999 solver.cpp:325] Optimization Done.
I1008 12:16:55.198364 54999 caffe.cpp:254] Optimization Done.
